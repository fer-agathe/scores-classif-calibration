[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Probabilistic Scores of Classifiers: Calibration is not Enough",
    "section": "",
    "text": "1 Introduction\nThis notebook is the online appendix of the article titled Probabilistic Scores of Classifiers: Calibration is not Enough.” It provides supplementary materials to the main part of the paper.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#abstract-of-the-paper",
    "href": "index.html#abstract-of-the-paper",
    "title": "Probabilistic Scores of Classifiers: Calibration is not Enough",
    "section": "1.1 Abstract of the Paper",
    "text": "1.1 Abstract of the Paper\nWhen it comes to quantifying the risks associated with decisions made using a classifier, it is essential that the scores returned by the classifier accurately reflect the underlying probability of the event in question. The model must then be well-calibrated. This is particularly relevant in contexts such as assessing the risks of payment defaults or accidents, for example. Tree-based machine learning techniques like random forests and XGBoost are increasingly popular for risk estimation in the industry, though these models are not inherently well-calibrated. Adjusting hyperparameters to optimize calibration metrics, such as the Integrated Calibration Index (ICI), does not ensure score distribution aligns with actual probabilities. Through a series of simulations where we know the underlying probability, we demonstrate that selecting a model by optimizing Kullback-Leibler (KL) divergence should be a preferred approach. The performance loss incurred by using this model remains limited compared to that of the best model chosen by AUC. Furthermore, the model selected by optimizing KL divergence does not necessarily correspond to the one that minimizes the ICI, confirming the idea that calibration is not a sufficient goal. In a real-world context where the distribution of underlying probabilities is no longer directly observable, we adopt an approach where a Beta distribution a priori is estimated by maximum likelihood over 10 UCI datasets. We show, similarly to the simulated data case, that optimizing the hyperparameters of models such as random forests or XGBoost based on KL divergence rather than on AUC allows for a better alignment between the distributions without significant performance loss. Conversely, minimizing the ICI leads to substantial performance loss and suboptimal KL values.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#outline",
    "href": "index.html#outline",
    "title": "Probabilistic Scores of Classifiers: Calibration is not Enough",
    "section": "1.2 Outline",
    "text": "1.2 Outline\nThe first part of this ebook, ‘Subsampling’, presents the subsampling algorithm (Chapter 2).\nThe second part, ‘Metrics’, introduces the functions used to assess performance, calibration, and divergence between discrete distributions (Chapter 3).\nThe third part, ‘Simulated Data’, firsts shows the data generating processes (Chapter 4). Then, it presents the estimations made on synthetic dataset for the different models: decision trees (Chapter 5), random forests (Chapters 6), XGBoost (Chapter 8), generalized linear models (Chapter 9), general additive models (Chapter 10), and general additive models with selection (Chapter 11).\nThe fourth part, ‘Real-world Data’, complements the analysis using real-world datasets from UCI Machine Learning repository. The methodology used to establish a prior assumption on the distribution of the underlying probability of the binary events using a Beta distribution is first presented (Chapter 13). Then, the estimation of the parameters of the prior Beta distribution of each dataset is shown (Chapter 14). The different machine learning models (random forests, XGBoost) and statistical learning models (GLM, GAM, GAMSEL) are then estimated (Chapter 15). Lastly, the results are shown. (Chapter 16).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "index.html#replication-codes",
    "href": "index.html#replication-codes",
    "title": "Probabilistic Scores of Classifiers: Calibration is not Enough",
    "section": "1.3 Replication Codes",
    "text": "1.3 Replication Codes\nThe codes to replicate the results displayed in the paper are presented in this ebook. We also provide the codes in an archive file with the following structure:\nSupplementary-materials\n├ ── replication_book\n├ ── replication_codes\n│   └── functions\n|   |   └── data-ojeda.R\n|   |   └── data-setup-dgp-scenarios.R\n|   |   └── metrics.R\n|   |   └── real-data.R\n|   |   └── subsample_target_distribution.R\n|   |   └── utils.R\n│   └── 01_data_targeted_distrib.R\n│   └── 02_data-simulated.R\n│   └── 03_simul-trees.R\n│   └── 04_simul-random-forests.R\n│   └── 05_simul-random-forests-ntrees.R\n│   └── 06_simul-xgb.R\n│   └── 07_simul-glm.R\n│   └── 08_simul-gam.R\n│   └── 09_simul-gamsel.R\n│   └── 10_simul-comparison.R\n│   └── 11_real-priors-illustration.R\n│   └── 12_real-datasets-priors.R\n│   └── 13_real-estimations.R\n│   └── 14_real_results.R\n│   └── proj.Rproj\n Download the Replication Codes (Zip archive)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "book_target_distribution.html",
    "href": "book_target_distribution.html",
    "title": "2  Targeted Distribution",
    "section": "",
    "text": "2.1 Algorithm\nIn our generated sample, \\(\\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i,{s}_i),i\\in\\{1,\\cdots,n\\}\\}\\), let \\(\\widehat{f}\\) denote the (empirical) density of scores. For the various scenarios, suppose that we want a specific distribution for the scores, denoted \\(g\\) (uniform, Beta, etc.). A classical idea is to use ‘’rejection sampling’’ techniques to create a subsample of the dataset. Set \\[\nc = \\sup_{s\\in(0,1)} \\frac{\\widehat{f}(s)}{g(s)} \\leq \\infty.\n\\] If \\(c\\) is finite, and not too large, we can use the standard rejection technique, described in Algorithm 2.1. In a nutshell, point \\(i\\) is kept with probability \\((cg(s_i))^{-1}\\widehat{f}(s_i)\\).\nNote: the reference mentioned: Chen (1999)\nIf \\(c\\) is too large, we use an iterative algorithm, described in Algorithm 2.2, inspired by Rumbell et al. (2023) (alternative options could be the ‘’Empirical Supremum Rejection Sampling’’ introduced in Caffo, Booth, and Davison (2002), for instance)\nTo implement this, we define the subset_target() function.\n#' @param data dataset\n#' @param score_name name of the column in data that contains the scores\n#' @param target_fun target distribution function.\n#' @param iter number of iterations.\n#' @param draw if TRUE (default) the distribution of scores (gray bars) and the\n#'  target distribution (in red) are plotted at each iteration.\n#' @seed if not `NULL`, seed to use\n#' @param data dataset\n#' @param probs_name name of the column in data that contains the observed\n#'  probabilities\n#' @param target_fun target distribution function.\n#' @param iter number of iterations.\n#' @param draw if TRUE (default) the distribution of scores (gray bars) and the\n#'  target distribution (in red) are plotted at each iteration.\n#' @seed if not `NULL`, seed to use\n#' @param verbose if `FALSE`, size of subsamplings at each iteration and KS test\n#'  results are hiddent\nsubset_target &lt;- function(data,\n                          probs_name,\n                          target_fun = function(x) dbeta(x,2,2),\n                          iter = 1,\n                          draw = TRUE,\n                          seed = NULL,\n                          verbose = TRUE){\n  select &lt;- rep(nrow(data),iter + 1)\n  if (!is.null(seed)) set.seed(seed)\n\n  # Get the scores from the dataset\n  probs_01 &lt;- data |&gt; pull(!!probs_name)\n  if (verbose == TRUE) cat(\"1) Size ...... \", nrow(data), \"\\n\", sep = \"\")\n\n  # Kolmogorov-Smirnov Test\n  fun &lt;- Vectorize(function(x) integrate(target_fun, 0, x)$value)\n  K &lt;- ks.test(probs_01, fun)\n\n  if (verbose) {\n    cat(\"1)  ks ............ \", K$statistic, \"\\n\", sep = \"\")\n    cat(\"1)  (pvalue) ...... \", K$p.value, \"\\n\", sep = \"\")\n  }\n\n  if (draw) {\n    # Histogram of scores (gray) and target distribution (red)\n    hist(probs_01,probability = TRUE, xlab = \"\", ylab = \"\", main = \"Initial\")\n    val_x &lt;- seq(0,1,length = 601)\n    lines(val_x,target_fun(val_x), col = \"red\")\n  }\n\n  data_subset &lt;- data\n\n  for (k in 1:iter) {\n    n &lt;- nrow(data_subset)\n    initial_density &lt;- kde(x = probs_01, eval.points = probs_01)\n    # Probability to include each observation in the current subset\n    prob_acceptation &lt;- target_fun(probs_01) / initial_density$estimate\n    prob_acceptation &lt;- pmin(prob_acceptation / max(prob_acceptation), 1)\n    # For each scores from the current data subset, decide whether or not to\n    # include it based on a random draw from a Ber(prob_acceptation)\n    index_acceptation &lt;- rbinom(n, size = 1, prob = prob_acceptation)\n    # Use this index to keep only the selected data\n    data_subset &lt;- data_subset[which(index_acceptation ==1 ), ]\n    select[k + 1] &lt;- nrow(data_subset)\n    probs_01 &lt;- data_subset |&gt; pull(!!probs_name)\n    if (verbose == TRUE)\n      cat(k + 1, \") Size ...... \", nrow(data_subset), \"\\n\", sep = \"\")\n    # Kolmogorov-Smirnov Test\n    K &lt;- ks.test(probs_01, fun)\n    if (verbose) {\n      cat(k + 1, \")   ks ............ \", K$statistic, \"\\n\", sep = \"\")\n      cat(k + 1, \")   (pvalue) ...... \", K$p.value, \"\\n\", sep = \"\")\n    }\n    if (draw) {\n      hist(\n        probs_01, probability = TRUE, xlab = \"\", ylab = \"\",\n        main = paste(\"Iteration \", k)\n      )\n      val_x &lt;- seq(0, 1, length = 601)\n      lines(val_x, target_fun(val_x), col = \"red\")\n    }\n  }\n  data_subset\n}",
    "crumbs": [
      "Subsampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Targeted Distribution</span>"
    ]
  },
  {
    "objectID": "book_target_distribution.html#algorithm",
    "href": "book_target_distribution.html#algorithm",
    "title": "2  Targeted Distribution",
    "section": "",
    "text": "\\begin{algorithm} \\caption{Subsample a dataset so that the distribution of scores has density $g$ (Rejection, $c$ small)} \\begin{algorithmic} \\Require $\\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i,{s}_i),i\\in\\{1,\\cdots,n\\}\\}$ and $g$ (target density) \\State $\\mathcal{I} \\gets ,i\\in\\{1,\\cdots,n\\}$ \\State $\\widehat{f} \\gets$ density of $\\{({s}_i),i\\in\\mathcal{I}\\}$, using Chen (1999) \\State $c = \\displaystyle\\sup_{s\\in(0,1)} \\frac{\\widehat{f}(s)}{g(s)} \\gets \\max_{i=1,\\cdots,n}\\displaystyle\\frac{\\widehat{f}(s_i)}{g(s_i)} $ \\For{$i\\in\\{1,\\cdots,n\\}$} \\State $U \\gets \\mathcal{U}([0,1])$ \\If{$\\displaystyle U &gt; \\frac{\\widehat{f}(s_i)}{c\\,g(s_i)}$} \\State $\\mathcal{I} \\gets \\mathcal{I}\\backslash\\{i\\}$ , i.e. ``reject\" \\EndIf \\EndFor \\State $s\\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i,{s}_i),i\\in\\mathcal{I}\\}$ \\end{algorithmic} \\end{algorithm}\n\n\n\n\n\n\n\\begin{algorithm} \\caption{Subsample a dataset so that the distribution of scores has density $g$ (Iterative Rejection, $c$ large)} \\begin{algorithmic} \\Require $\\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i,{s}_i),i\\in\\{1,\\cdots,n\\}\\}$, $\\epsilon&gt;0$ and $g$ (target density) \\State $\\mathcal{I} \\gets \\{1,\\cdots,n\\}$ \\State $\\widehat{f} \\gets$ density of $\\{({s}_i),i\\in\\mathcal{I}\\}$, using Chen (1999) \\State $d \\gets \\|\\widehat{F}-G\\|_{\\infty}$ (Kolmogorov-Smirnov distance) \\While{$d&gt;\\epsilon$} \\State $\\mathcal{J} \\gets \\mathcal{I}$ \\For{$i\\in\\mathcal{I}$} \\State $U \\gets \\mathcal{U}([0,1])$ \\If{$\\displaystyle U&gt;\\frac{\\widehat{f}(s_i)}{g(s_i)}$} \\State $\\mathcal{J} \\gets \\mathcal{J}\\backslash\\{i\\}$ , i.e. 'reject' observation $i$ \\EndIf \\EndFor \\State $\\mathcal{I} \\gets \\mathcal{J}$ \\State $\\widehat{f} \\gets$ density of $\\{({s}_i),i\\in\\mathcal{I}\\}$ \\State $d \\gets \\|\\widehat{F}-G\\|_{\\infty}$ \\EndWhile \\State $s\\mathcal{D}=\\{(\\boldsymbol{x}_i,y_i,{s}_i),i\\in\\mathcal{I}\\}$ \\end{algorithmic} \\end{algorithm}",
    "crumbs": [
      "Subsampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Targeted Distribution</span>"
    ]
  },
  {
    "objectID": "book_target_distribution.html#first-example",
    "href": "book_target_distribution.html#first-example",
    "title": "2  Targeted Distribution",
    "section": "2.2 First Example",
    "text": "2.2 First Example\nLet us begin with generating some binary data, using a linear predictor for the true probability.\n\nn &lt;- 1e5 # Number of obs.\n# Covariates\nx1 &lt;- rnorm(n)\nx2 &lt;- rnorm(n)\n# True probabilities\np &lt;- function(x1, x2) .4 * x1 - .2*x2\n# Observed event\ny &lt;- rnorm(n,p(x1, x2), .4)\ntb &lt;- tibble(y = y, x1 = x1, x2 = x2)\n\nLet us consider a linear model to predict the observed event:\n\nreg &lt;- lm(y ~ x1 + x2, data = tb)\nscores &lt;- predict(reg)\ntb$scores &lt;- scores\n\nKeeping only scores between 0 and 1 (would not need to do so for glm)\n\ntb_01 &lt;- tb[(scores &gt; 0) & (scores &lt; 1), ]\ndata &lt;- tb_01\n\n\nB &lt;- subset_target(data = data, probs_name = \"scores\", iter = 4)\n\n1) Size ...... 49043\n1)  ks ............ 0.2984887\n1)  (pvalue) ...... 0\n\n\n\n\n\n\n\n\n\n2) Size ...... 18636\n2)   ks ............ 0.004883\n2)   (pvalue) ...... 0.7658753\n\n\n\n\n\n\n\n\n\n3) Size ...... 17806\n3)   ks ............ 0.002569351\n3)   (pvalue) ...... 0.9997977\n\n\n\n\n\n\n\n\n\n4) Size ...... 17523\n4)   ks ............ 0.002801151\n4)   (pvalue) ...... 0.9991427\n\n\n\n\n\n\n\n\n\n5) Size ...... 17345\n5)   ks ............ 0.002138985\n5)   (pvalue) ...... 0.9999984\n\n\n\n\n\n\n\n\n\nLet us consider another example.\n\nlibrary(splines)",
    "crumbs": [
      "Subsampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Targeted Distribution</span>"
    ]
  },
  {
    "objectID": "book_target_distribution.html#second-examplle",
    "href": "book_target_distribution.html#second-examplle",
    "title": "2  Targeted Distribution",
    "section": "2.3 Second Examplle",
    "text": "2.3 Second Examplle\nWe generate another dataset.\n\nn &lt;- 1e6\nx &lt;- rbeta(n, 1, 2)\ny &lt;- rbinom(n, size = 1, prob = x)\nbase &lt;- tibble(\n  x = x,\n  y = y,\n  id = 1:n\n)\n\nLet us assume that the scores are estimated using a logistic model.\n\nreg &lt;- glm(y ~ bs(x), data = base, family = binomial)\nbase$scores &lt;- predict(reg, type = \"response\")\n\nLet us further assume that we want the scores to be distributed according to a Beta(2,1).\n\nB &lt;- subset_target(\n  data = base, \n  probs_name = \"scores\", \n  iter = 1, \n  target_fun = function(x) dbeta(x,2,1)\n)\n\n1) Size ...... 1000000\n\n\nWarning in ks.test.default(probs_01, fun): ties should not be present for the\none-sample Kolmogorov-Smirnov test\n\n\n1)  ks ............ 0.5045229\n1)  (pvalue) ...... 0\n\n\n\n\n\n\n\n\n\n2) Size ...... 6807\n2)   ks ............ 0.0558179\n2)   (pvalue) ...... 7.583483e-19\n\n\n\n\n\n\n\n\n\nWe check the new observations:\n\nreg2 &lt;- glm(y ~ bs(x), data = B, family = binomial)\n\n\nval_x &lt;- seq(0, 1, length = 601)\nplot(\n  val_x,\n  predict(reg, type = \"response\", newdata = data.frame(x = val_x)),\n  type = \"l\", lwd = 2\n)\n\nWarning in bs(x, degree = 3L, knots = numeric(0), Boundary.knots =\nc(3.63914428464661e-07, : some 'x' values beyond boundary knots may cause\nill-conditioned bases\n\nlines(\n  val_x,\n  predict(reg2, type = \"response\", newdata = data.frame(x = val_x)),\n  type = \"l\", lwd = 2, col = \"red\"\n)\n\nWarning in bs(x, degree = 3L, knots = numeric(0), Boundary.knots =\nc(0.00353202315537561, : some 'x' values beyond boundary knots may cause\nill-conditioned bases\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaffo, Brian S, James G Booth, and AC Davison. 2002. “Empirical Supremum Rejection Sampling.” Biometrika 89 (4): 745–54.\n\n\nChen, Song Xi. 1999. “Beta Kernel Estimators for Density Functions.” Computational Statistics & Data Analysis 31 (2): 131–45.\n\n\nRumbell, Timothy, Jaimit Parikh, James Kozloski, and Viatcheslav Gurev. 2023. “Novel and Flexible Parameter Estimation Methods for Data-Consistent Inversion in Mechanistic Modelling.” Royal Society Open Science 10 (11): 230668.",
    "crumbs": [
      "Subsampling",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Targeted Distribution</span>"
    ]
  },
  {
    "objectID": "book_metrics.html",
    "href": "book_metrics.html",
    "title": "3  Metrics",
    "section": "",
    "text": "3.1 Performance and Calibration Metrics\nTo measure performance, we chose to compute:\nTo measure calibration, we compute two metrics:\nAll these metrics are computed in a function we name compute_metrics() which takes three arguments:\n#' Brier Score\n#'\n#' The Brier Score \\citep{brier_1950}, is expressed as: \\deqn{\\text{BS} =\n#' \\frac{1}{n}\\sum_{i=1}^{n} \\big(\\hat{s}(\\mathbf{x}_i) - d_i\\big)^{2}} where\n#' \\eqn{d_i \\in \\{0,1\\}} is the observed event for observation \\eqn{i}.\n#'\n#' @param scores vector of scores\n#' @param obs vector of observed binary events\n#'\n#' @references Brier, G. W. (1950). Verification of forecasts expressed in terms\n#' of probability. Monthly Weather Review 78: 1–3.\n#'\n#' @export\nbrier_score &lt;- function(obs, scores) mean((scores - obs)^2)\n#' Computes the calibration metrics for a set of observed and predicted\n#' probabilities\n#'\n#' @returns\n#' \\itemize{\n#'   \\item \\code{mse}: True Mean Squared Error based on true probability.\n#'   \\item \\code{acc}: accuracy with a .5 probability threshold.\n#'   \\item \\code{AUC}: Area Under the ROC Curve.\n#'   \\item \\code{brier}: Brier score.\n#'   \\item \\code{ici}: Integrated Calibration Index.\n#' }\n#'\n#' @param obs observed events\n#' @param scores predicted scores\n#' @param true_probas true probabilities from the PGD (to compute MSE)\n#'\n#' @importFrom purrr map\n#' @importFrom tibble tibble\n#' @importFrom dplyr bind_rows\n#'\n#' @export\ncompute_metrics &lt;- function(obs,\n                            scores,\n                            true_probas = NULL) {\n\n  # True MSE\n  if (!is.null(true_probas)) {\n    mse &lt;- mean((true_probas - scores)^2)\n  } else {\n    mse &lt;- NA\n  }\n\n  # True MAE\n  if (!is.null(true_probas)) {\n    mae &lt;- mean(abs(true_probas - scores))\n  } else {\n    mae &lt;- NA\n  }\n\n  # AUC\n  AUC &lt;- pROC::auc(obs, scores, levels = c(\"0\", \"1\"), quiet = TRUE) |&gt;\n    as.numeric()\n\n  # Brier Score\n  brier &lt;- brier_score(obs = as.numeric(as.character(obs)), scores = scores)\n  # gmish::brier(pred = scores, obs = obs) #same results\n\n  # ICI\n  ici_quiet &lt;- purrr::quietly(gmish::ici)\n  ici &lt;- ici_quiet(pred = scores, obs = as.numeric(as.character(obs)))\n  ici &lt;- ici$result\n\n  # Accuracy\n  pred_class &lt;- ifelse(scores &gt; .5, yes = 1, no = 0)\n  acc &lt;- sum(diag(table(obs = obs, pred = pred_class))) / length(scores)\n\n  tibble(\n    mse = mse,\n    mae = mae,\n    acc = acc,\n    AUC = AUC,\n    brier = brier,\n    ici = ici\n  )\n}",
    "crumbs": [
      "Metrics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Metrics</span>"
    ]
  },
  {
    "objectID": "book_metrics.html#performance-and-calibration-metrics",
    "href": "book_metrics.html#performance-and-calibration-metrics",
    "title": "3  Metrics",
    "section": "",
    "text": "the true Mean Squared Error (MSE): the average of the quadratic difference between predicted scores and true probabilities (only if the true probabilities are available thanks to the knowledge of the PGD)\nthe accuracy, which gives the proportion of correctly predicted instances; we use a probability threshold of 0.5)\nthe AUC.\n\n\n\nthe Brier score (Brier (1950))\nthe Integrated Calibration Index (Austin and Steyerberg (2019)).\n\n\n\n\n\n\n\nBrier Score\n\n\n\nGiven a sample size \\(n\\), the Brier Score Brier (1950), is expressed as: \\[\n\\begin{equation}\n\\text{BS} = \\frac{1}{n}\\sum_{i=1}^{n} \\big(\\hat{s}(\\mathbf{x}_i) - d_i\\big)^{2}\\enspace ,\n\\end{equation}\n\\tag{3.1}\\]\nwhere \\(\\hat{s}(\\mathbf{x}_i)\\) and \\(d_i \\in \\{0,1\\}\\) are the predicted score and observed event, respectively, for observation \\(i\\).\n\n\n\n\n\n\n\n\nIntegrated Calibration Index\n\n\n\nInstead of defining bins, the Integrated Calibration Index or ICI (Austin and Steyerberg (2019)) measures calibration using a local estimation (loess if the number of observation is lower than 1000 ; using a GAM otherwise).\nThe occurrence of the binary event is regressed on the predicted scores, employing either locally estimated scatterplot smoothing (LOESS) when the number of observations is small (\\(n &lt; 1000\\)) or cubic regression splines for larger datasets. The ICI is defined as \\[\n\\begin{equation}\n    \\text{ICI} = \\int_{0}^{1} f(p)  \\phi(p)\\, dp\n\\end{equation}\n\\tag{3.2}\\] where \\(f(p) = | p - \\g(p) |\\) is the absolute difference between the calibration curve and the bisector where \\(p\\) denotes a predicted score (i.e., \\(p=\\hat{s}(\\mathbf{x})\\)) and \\(\\g(p)\\) is the value of the calibration curve at this predicted score. The density function of the distribution of predicted scores is denoted \\(\\phi(p)\\).\n\n\n\n\nobs: a vector of observed binary events\nscores: a vector of predicted scores\ntrue_probas: if available, a vector of true probabilities from the PGD (to compute MSE).",
    "crumbs": [
      "Metrics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Metrics</span>"
    ]
  },
  {
    "objectID": "book_metrics.html#dispersion-metrics",
    "href": "book_metrics.html#dispersion-metrics",
    "title": "3  Metrics",
    "section": "3.2 Dispersion Metrics",
    "text": "3.2 Dispersion Metrics\nWe compute the Kullback-Leibler divergence Kullback and Leibler (1951) between the distribution of the estimated scores and the distribution of the true probabilities. Denoting (Q) the distribution of the scores and (P) the distribution of the true probabilities, the Kullback Leibler divergence of \\(Q\\) with respect to \\(P\\) is :% \\[\\begin{equation}\nD_{KL}(Q || P) = \\sum_{i} Q(i) \\log \\frac{Q(i)}{P(i)}.\n\\end{equation}\\]\nThe distributions both need to be discretized. We divide the segment ([0,1]) into (m) bins.\nIn the dispersion_metrics() that we define to that end, we consider two values for the number of bins: \\(m\\in \\{10,20\\}\\). We also consider switching the reference distribution (where \\(Q\\) denotes the distribution of the true probabilities and \\(P\\) denotes the distribution of scores).\n\n#' Computes the dispersion metrics for a set of observed and predicted\n#' probabilities\n#'\n#' @returns\n#' \\itemize{\n#'   \\item \\code{inter_quantile_25_75}: Difference of inter-quantile between 25% and 75%\n#'   \\item \\code{inter_quantile_10_90}: Difference of inter-quantile between 10% and 90%\n#'   \\item \\code{KL_10_true_probas}: KL of of predicted probabilities w.r. to true probabilities with 10 bins\n#'   \\item \\code{KL_10_scores}: KL of of true probabilities w.r. to predicted probabilities with 10 bins\n#'   \\item \\code{KL_20_true_probas}: KL of of predicted probabilities w.r. to true probabilities with 20 bins\n#'   \\item \\code{KL_20_scores}: KL of of true probabilities w.r. to predicted probabilities with 20 bins\n#'   \\item \\code{ind_cov}: Difference between the variance of true probabilities and the covariance between true probabilities and predicted scores\n#' }\n#'\n#' @param true_probas true probabilities from simulations\n#' @param scores predicted scores\n#'\ndispersion_metrics &lt;- function(true_probas, scores){\n\n  # Inter-quantiles\n  inter_q_80 &lt;- diff(quantile(scores, c(.9, .1))) /\n    diff(quantile(true_probas, c(.9, .1)))\n  inter_q_50 &lt;- diff(quantile(scores, c(.75,.25))) /\n    diff(quantile(true_probas, c(.75, .25)))\n\n  # KL divergences\n  m &lt;- 10 # Number of bins\n  h_p &lt;- hist(true_probas, breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  h_phat &lt;- hist(scores, breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  # Densities\n  h1 &lt;- rbind(h_phat$density / m, h_p$density / m) # Reference : true probabilities\n  h2 &lt;- rbind(h_p$density / m, h_phat$density / m) # Reference : predicted scores\n  KL_10_true_probas &lt;- distance(\n    h1, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n  KL_10_scores &lt;- distance(\n    h2, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n\n\n  m &lt;- 20 # Number of bins\n  h_p &lt;- hist(true_probas,breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  h_phat &lt;- hist(scores, breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  # Densities\n  h1 &lt;- rbind(h_phat$density / m,h_p$density / m) # Reference : true probabilities\n  h2 &lt;- rbind(h_p$density / m, h_phat$density / m) # Reference : predicted scores\n  KL_20_true_probas &lt;- distance(\n    h1, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n  KL_20_scores &lt;- distance(\n    h2, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n\n  # Indicator of the difference between variance and covariance\n  var_p &lt;- var(true_probas)\n  cov_p_phat &lt;- cov(true_probas, scores)\n  ind_cov &lt;- abs(cov_p_phat - var_p)\n\n  # Collection\n  dispersion_metrics &lt;- tibble(\n    \"inter_quantile_25_75\" = as.numeric(inter_q_50),\n    \"inter_quantile_10_90\" = as.numeric(inter_q_80),\n    \"KL_10_true_probas\" = as.numeric(KL_10_true_probas),\n    \"KL_10_scores\" = as.numeric(KL_10_scores),\n    \"KL_20_true_probas\" = as.numeric(KL_20_true_probas),\n    \"KL_20_scores\" = as.numeric(KL_20_scores),\n    \"ind_cov\" = ind_cov\n    )\n\n  dispersion_metrics\n}\n\nLastly, we estimate \\(\\mathbb{P}(q_1 &lt; \\hat{s}(\\mathbf{x}) &lt; q_2)\\), with \\(q_2 = 1-q_1\\), for different values of \\(q_1\\) and \\(q_2\\). To do so, we simply calculate the sample proportion of scores between \\(q_1\\) and \\(q_2\\). The prop_btw_quantiles() does it.\n\n#' Computes \\hat{P}(q_1 &lt; s &lt; q_2)\n#'\n#' @param s scores\n#' @param q1 lower quantile\n#' @param q2 upper quantile (default to 1-q2)\nprop_btw_quantiles &lt;- function(s, q1, q2 = 1 - q1) {\n  tibble(q1 = q1, q2 = q2, freq = mean(s &lt; q2 & s &gt; q1))\n}\n\n\n\n\n\nAustin, Peter C., and Ewout W. Steyerberg. 2019. “The Integrated Calibration Index (ICI) and Related Metrics for Quantifying the Calibration of Logistic Regression Models.” Statistics in Medicine 38 (21): 4051–65. https://doi.org/10.1002/sim.8281.\n\n\nBrier, Glenn W. 1950. “Verification of Forecasts Expressed in Terms of Probability.” Monthly Weather Review 78 (1): 1–3.\n\n\nKullback, S., and R. A. Leibler. 1951. “On Information and Sufficiency.” The Annals of Mathematical Statistics 22 (1): 79–86. https://doi.org/10.1214/aoms/1177729694.",
    "crumbs": [
      "Metrics",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Metrics</span>"
    ]
  },
  {
    "objectID": "book_ojeda.html",
    "href": "book_ojeda.html",
    "title": "4  Simulated Data",
    "section": "",
    "text": "4.1 Functions\nWe load the functions from Chapter 2 to subsample from a dataset so that the true probability follows a beta distribution.\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nThe simulate_data() function generates data for one of the 12 first scenarios described in the article or one of our additional 4 scenarios. This is a helper function that is called in the second one, simulate_data_wrapper() which generates datasets.\nCode\n#' Simulates train/test\n#'\n#' @details\n#' This function is a modified version of the function 'simulateData' in the\n#' R script 'functions-for-calibrating-random-forests.R' provided in the\n#' supplementary material of  Dankowski, T., & Ziegler, A. (2016). Calibrating\n#' random forests for probability estimation. Statistics in medicine, 35(22),\n#' 3949-3960.\n#'\n#' @param n_num number of numerical covariates\n#' @param add_categ if `TRUE`, add 5 categorical variables\n#' @param coeff vector of coefficients (of length n_num + 5)\n#' @param n_noise number of noise variables (drawn from N(0,1))\n#' @param mean_num vector of mean for the numerical variables\n#' @param sd_num vector of standard deviations for the numerical variables\n#' @param size_train size for the train set\n#' @param size_valid size for the validation set\n#' @param size_test size for the test set\n#' @param transform_probs if `TRUE`, the true probability is taken to the power of 3\n#' @param linear_predictor if `TRUE`, the predictor of the true probability is a\n#'  linear combination of the covariates. Otherwise, the squared term for x1 is\n#'  added, as well as an interaction term between x2 and x3 (`n_num` thus need\n#'  to be at least 3).\n#' @param seed desired seed (default to `NULL`)\n#' @param linear_predictor_factor if `transform_probs = TRUE`, scalar used to\n#'  draw more observation before subsampling. Default to 3 (a sample 3 times\n#'  larger than `size_train` and `size_test` will first be generated before\n#'  subsampling so that the true probability follows a Beta(2,2).\n#'\n#' @returns A list with the following components:\n#'  - train: train set\n#'  - valid: validation set\n#'  - test: test set\n#'  - probs_train: true probabilities for binary event in train set\n#'  - probs_valid: true probabilities for binary event in validation set\n#'  - probs_test: true probabilities for binary event in test set\nsimulate_data &lt;- function(n_num = 2,\n                          add_categ = FALSE,\n                          coeff,\n                          n_noise = 0,\n                          mean_num,\n                          sd_num,\n                          size_train,\n                          size_valid,\n                          size_test,\n                          transform_probs = FALSE,\n                          linear_predictor = TRUE,\n                          linear_predictor_factor = 3,\n                          seed = NULL) {\n\n  if (linear_predictor == TRUE) {\n    n_obs &lt;- size_train + size_test + size_valid\n  } else {\n    n_obs &lt;- (size_train + size_test + size_valid) * linear_predictor_factor\n  }\n\n  if (!is.null(seed)) {\n    set.seed(seed)\n  }\n\n  # Numerical covariates\n  covariates &lt;- map2(\n    .x = mean_num,\n    .y = sd_num,\n    .f = ~rnorm(n = n_obs, mean = .x, sd = .y)\n  )\n  names(covariates) &lt;- str_c(\"x\", 1:n_num)\n  covariates &lt;- as_tibble(covariates)\n\n  # Categorical covariates\n  if (add_categ == TRUE) {\n    x_c1 &lt;- base::sample(c(0, 1), n_obs, replace = TRUE)\n    x_c2 &lt;- base::sample(c(0, 1), n_obs, replace = TRUE)\n    x_c3 &lt;- base::sample(c(1, 2, 3), n_obs, replace = TRUE)\n    x_c4 &lt;- base::sample(c(1, 2, 3, 4), n_obs, replace = TRUE)\n    x_c5 &lt;- base::sample(c(1, 2, 3, 4, 5), n_obs, replace = TRUE)\n\n    categ_covariates &lt;- tibble(x_c1, x_c2, x_c3, x_c4, x_c5)\n    colnames(categ_covariates) &lt;- str_c(\"x\", (n_num + 1):(n_num + 5))\n    covariates &lt;- bind_cols(covariates, categ_covariates)\n  }\n\n  if (linear_predictor == TRUE) {\n    # Linear predictor\n    eta &lt;- as.matrix(covariates) %*% coeff\n  } else {\n    if (n_num &lt; 3) stop(\"If linear_predictor=TRUE, n_num must be greater than 2\")\n    eta &lt;- as.matrix(covariates) %*% coeff +\n      covariates$x1^2 + covariates$x2^2 * covariates$x3\n  }\n\n  # True probability\n  true_prob &lt;- as.numeric(1 / (1 + exp(-eta)))\n  if (transform_probs) true_prob &lt;- true_prob^3\n\n  # Observed event\n  y &lt;- rbinom(n_obs, size = 1, prob = true_prob)\n\n  # Create dataset with observed event and covariates\n  tb &lt;- tibble(y, covariates)\n\n  if (linear_predictor == FALSE) {\n    # We would like the probabilities to be distributed as a Beta(2,2)\n    tb &lt;- tb |&gt; mutate(p = true_prob)\n    tb &lt;- subset_target(\n      data = tb,\n      probs_name = \"p\",\n      target_fun = function(x) dbeta(x,2,2),\n      iter = 1, draw = FALSE,\n      seed = seed,\n      verbose = FALSE\n    )\n    n_obs &lt;- size_train + size_test + size_valid\n    if (nrow(tb) &lt; n_obs) {\n      stop(\n        str_c(\"The number of observation generated is lower than the \",\n              \"desired number. Increase `linear_predictor_factor`.\")\n      )\n    }\n    true_prob &lt;- tb$p[1:n_obs]\n    tb &lt;- tb |&gt; select(-p) |&gt; dplyr::slice_head(n = n_obs)\n  }\n\n\n  # Noise variables\n  if (n_noise &gt; 0) {\n    noise &lt;- matrix(\n      rnorm(n_noise * n_obs, mean = 0, sd = 1),\n      ncol = n_noise,\n      nrow = n_obs,\n      byrow = FALSE\n    ) |&gt;\n      as_tibble()\n    colnames(noise) &lt;- str_c(\"noise_\", 1:n_noise)\n    tb &lt;- bind_cols(tb, noise)\n  }\n\n  # Split data into train/valid/test\n  tb_train &lt;- tb |&gt; dplyr::slice(1:size_train)\n  true_prob_train = true_prob[1:size_train]\n  if (size_valid &gt; 0) {\n    ind_valid &lt;- (size_train + 1):(size_train+size_valid)\n    tb_valid &lt;- tb |&gt; dplyr::slice(ind_valid)\n    true_prob_valid = true_prob[ind_valid]\n  } else {\n    tb_valid &lt;- NULL\n    true_prob_valid &lt;- NULL\n  }\n  if (size_test &gt; 0) {\n    ind_test &lt;- (size_train + ifelse(is.null(size_valid), 0, size_valid) + 1):n_obs\n    tb_test &lt;- tb |&gt; dplyr::slice(ind_test)\n    true_prob_test = true_prob[ind_test]\n  } else {\n    tb_test &lt;- NULL\n    true_prob_test &lt;- NULL\n  }\n\n  list(\n    train = tb_train,\n    valid = tb_valid,\n    test = tb_test,\n    probs_train = true_prob_train,\n    probs_valid = true_prob_valid,\n    probs_test = true_prob_test\n  )\n}\nThe simulate_data_wrapper() is the one we call to generate a dataset, given a scenario and a seed.\nCode\n#' Generates data for a given simulation scenario.\n#'\n#' @details\n#' Wrapper of 'simulate_data' function that generates the data for a given\n#' simulation scenario.\n#'\n#' @param scenario simulation scenario number.\n#' @param params_df data frame containing the parameters to be passed to the\n#'  `simulate_data` for each simulation scenario.\n#' @param repn Number of current replication to be generated for the given\n#'  simulation scenario.\n#'\n#' @returns A list with the following components:\n#'  - scenario: the scenario ID\n#'  - params_df: the parameters used for the data generation for the given\n#'               scenario.\n#'  - repn: Number of current replication that was generated for the given\n#'          simulation scenario.\n#'  - data: list with the simulated data (train, valid, test, probs_train,\n#'          probs_valid and probs_test)\n#'          see result of `simulate_data()`.\nsimulate_data_wrapper &lt;- function(scenario, params_df, repn) {\n  params &lt;- params_df[params_df[[\"scenario\"]] == scenario, ]\n  if(nrow(params) != 1) stop(\"More than one row from params_df chosen\")\n\n  seed_for_repn &lt;- pull(params, \"seed\") + repn\n\n  args &lt;- list(\n    coeff = params |&gt; pull(\"coefficients\") |&gt; pluck(1),\n    n_num = params |&gt; pull(\"n_num\"),\n    add_categ = params |&gt; pull(\"add_categ\"),\n    n_noise = params |&gt; pull(\"n_noise\"),\n    mean_num = params |&gt; pull(\"mean_num\") |&gt; pluck(1),\n    sd_num = params |&gt; pull(\"sd_num\") |&gt; pluck(1),\n    size_train = params |&gt; pull(\"size_train\"),\n    size_valid = params |&gt; pull(\"size_valid\"),\n    size_test = params |&gt; pull(\"size_test\"),\n    transform_probs = params |&gt; pull(\"transform_probs\"),\n    linear_predictor = params |&gt; pull(\"linear_predictor\"),\n    seed = seed_for_repn\n  )\n  sim_data &lt;- do.call(\"simulate_data\", args)\n\n  list(\n    scenario = scenario,\n    params_df = params,\n    repn = repn,\n    data = sim_data\n  )\n\n}",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "book_ojeda.html#scenarios",
    "href": "book_ojeda.html#scenarios",
    "title": "4  Simulated Data",
    "section": "4.2 Scenarios",
    "text": "4.2 Scenarios\nLet us define the 12 first scenarios, using the code provided in Ojeda et al. (2023).\n\nDGP 1:\n\nScenario 1: basic scenario with two continuous predictors, without noise variable\nScenarios 2, 3, 4: same as 1 but with noise variables (10, 50, 100)\n\nDGP 2:\n\nScenarios 5 to 8: similar to 1 to 4 but with right-skewed true probability distribution (true probability taken to the power of 3)\n\nDGP 3:\n\nScenarios 9 to 12: similar to 1 to 4 but with ten predictors instead of two (5 numerical and 5 categorical)\n\n\nWe add four other scenarios, in which the predictor is nonlinear:\n\nDGP 4:\n\nScenarios 13 to 16: similar to 1 to 4 but with 3 covariates instead of 2 and with a nonlinear predictor which also contains an interaction term (\\(\\eta = \\alpha _1x_1 + \\alpha_2 x_2 + \\alpha_3 x_3 + \\beta x_1^2 + \\gamma x_2 \\times x_3\\)). In addition, the distribution of the true probabilities of the observed data follows a Beta(2,2) distribution.\n\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100\n\nWe set the different parameters for each scenario.\n\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(10000, 16),\n  size_valid = rep(10000, 16),\n  size_test = rep(10000, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "book_ojeda.html#example",
    "href": "book_ojeda.html#example",
    "title": "4  Simulated Data",
    "section": "4.3 Example",
    "text": "4.3 Example\nLet us draw a sample of 10,000 observation in the train and the test set, for each scenario. We can then plot the histogram of the true probabilities in each sample (Figure 4.1).\n\n\nCode\npar(mfrow = c(8, 6), mar = c(2, 2, 2, 2))\nfor (scenario in 1:16) {\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repns_vector[1] # only one replication here\n  )\n  colour_samples &lt;- c(\n    \"Train\" = \"#0072B2\",\n    \"Valid\" = \"#009E73\",\n    \"Test\" = \"#D55E00\"\n  )\n  for (sample in c(\"train\", \"valid\", \"test\")) {\n    if (sample == \"train\") {\n      true_prob &lt;- simu_data$data$probs_train\n      i_scores &lt;- 1\n    } else if (sample == \"valid\") {\n      true_prob &lt;- simu_data$data$probs_valid\n      i_scores &lt;- 2\n    }else {\n      true_prob &lt;- simu_data$data$probs_test\n      i_scores &lt;- 3\n    }\n    hist(\n      true_prob,\n      breaks = seq(0, 1, by = .05),\n      col = colour_samples[i_scores],\n      border = \"white\",\n      xlab = \"p\", ylab = \"\",\n      main = str_c(\"Scen. \", scenario, \", \", c(\"Train\", \"Valid\", \"Test\")[i_scores]),\n      xlim = c(0, 1)\n    )\n  }\n}\n\n\n\n\n\nFigure 4.1: Histogram of true probabilities for each scenario\n\n\n\n\n\n\n\n\nFor each group of scenarios, the only thing that varies is the number of noise variables. This has no impact on the distribution of the true probability. Hence, we can create a simple figure with the distribution of the true probability for each group of scenario.\n\n\nOnly on Train test, for each category of scenarios.\nsave_graph &lt;- FALSE\n\nif (save_graph) {\n  cairo_pdf(\n    \"figures/sim-data-ojeda-hist-categories.pdf\", \n    width = 8, height = 2\n  )\n}\n\npar(mfrow = c(1, 4), mar = c(4.1, 3.1, 2.1, 1.1))\nfor (i_dgp in 1:4) {\n  scenario &lt;- c(1, 5, 9, 13)[i_dgp]\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repns_vector[1] # only one replication here\n  )\n  \n  true_prob &lt;- simu_data$data$probs_test\n  title &lt;- str_c(\"DGP \", i_dgp)\n  \n  hist(\n    true_prob,\n    breaks = seq(0, 1, by = .05),\n    # col = ,\n    # border = \"white\",\n    xlab = \"p\", ylab = \"\",\n    main = title,\n    xlim = c(0, 1)\n  )\n}\nif (save_graph) dev.off()\n\n\n\n\n\nFigure 4.2: Distribution of the underlying probabilities in the different categories of scenarios.\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Simulated Data</span>"
    ]
  },
  {
    "objectID": "book_ojeda_trees.html",
    "href": "book_ojeda_trees.html",
    "title": "5  Decision Trees",
    "section": "",
    "text": "5.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_valid = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Decision Trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_trees.html#metrics",
    "href": "book_ojeda_trees.html#metrics",
    "title": "5  Decision Trees",
    "section": "5.2 Metrics",
    "text": "5.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Decision Trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_trees.html#simulations-setup",
    "href": "book_ojeda_trees.html#simulations-setup",
    "title": "5  Decision Trees",
    "section": "5.3 Simulations Setup",
    "text": "5.3 Simulations Setup\nFor each scenario, we will grow a tree to predict the binary outcome using all the available variables in the simulated dataset. We train regression trees here, as we are interested in the resulting scores, not by the class given by a majority vote.\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100\n\nTo obtain trees with varying number of leaves, we make the min_bucket parameter vary. This parameter defines the minimal number of observation in a terminal leaf node. A split is not performed if at least one of the resulting children leaves do not contain at least min_bucket observations. In addition, a split will not be attempted if the number of observation in the current node is lower than three times min_bucket.\nFor each scenario (i.e., different data generating process), we consider 100 replications: we draw 100 samples from the data generating process associated with the scenario.\n\n5.3.1 Estimation Function\nWe define the simul_tree() function to make a single replication of the simulations.\n\n\nFunction simul_tree()\n#' Train a tree and compute performance, calibration, and dispersion metrics.\n#' \n#' @param prune should the tree be pruned?\n#' @param min_bucket minimal number of observations in terminal nodes\n#' @param type either `\"regression\"` for regression tree or `\"classification\"`\n#'  for classification tree\n#' @param simu_data simulated data obtained with `simulate_data_wrapper()`\n#' @param ind numerical ID of the simulation in the grid: different from the \n#'  seed ID)\nsimul_tree &lt;- function(prune = c(TRUE, FALSE),\n                       min_bucket,\n                       type = c(\"regression\", \"classification\"),\n                       simu_data,\n                       ind) {\n\n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_valid &lt;- simu_data$data$valid |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n\n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      valid = simu_data$data$probs_valid,\n      test = simu_data$data$probs_test\n    )\n\n  # Estimation----\n  if (type == \"regression\") {\n    estim_tree &lt;- rpart(\n      d ~ x1 + x2, data = tb_train,\n      method = \"anova\",\n      minsplit = min_bucket * 3,\n      minbucket = min_bucket,\n      cp = 0\n    )\n  } else {\n    estim_tree &lt;- rpart(\n      d ~ x1 + x2, data = tb_train,\n      method = \"class\",\n      minsplit = min_bucket * 3,\n      minbucket = min_bucket,\n      cp = 0\n    )\n  }\n  if (prune == TRUE) {\n    ind_min_cp &lt;- which.min(estim_tree$cptable[,\"xerror\"])\n    min_cp &lt;- estim_tree$cptable[ind_min_cp, \"CP\"]\n    estim_tree &lt;- prune(estim_tree, cp = min_cp)\n  }\n\n  nb_leaves &lt;- sum(estim_tree$frame$var==\"&lt;leaf&gt;\")\n  depth &lt;- max(rpart:::tree.depth(as.numeric(rownames(estim_tree$frame))))\n\n  # Raw Scores----\n  # Predicted scores\n  if (type == \"regression\") {\n    scores_train &lt;- predict(estim_tree, newdata = tb_train)\n    scores_valid &lt;- predict(estim_tree, newdata = tb_valid)\n    scores_test &lt;- predict(estim_tree, newdata = tb_test)\n  } else {\n    scores_train &lt;- predict(estim_tree, newdata = tb_train)[,\"1\"]\n    scores_valid &lt;- predict(estim_tree, newdata = tb_valid)[,\"1\"]\n    scores_test &lt;- predict(estim_tree, newdata = tb_test)[,\"1\"]\n  }\n\n  # Histogram of scores\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_valid_hist &lt;- hist(scores_valid, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    valid = scores_valid_hist,\n    test = scores_test_hist\n  )\n\n  # Estimation of P(q1 &lt; score &lt; q2)\n  proq_scores_train &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_valid &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_valid, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"valid\")\n  proq_scores_test &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n\n  # Dispersion Metrics\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n\n  disp_valid &lt;- dispersion_metrics(\n    true_probas = true_prob$valid, scores = scores_valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n\n  # Performance and Calibration Metrics\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n\n  scores_valid_noise &lt;- scores_valid +\n    runif(n = length(scores_valid), min = 0, max = 0.01)\n  scores_valid_noise[scores_valid_noise &gt; 1] &lt;- 1\n  metrics_valid &lt;- compute_metrics(\n    obs = tb_valid$d, scores = scores_valid_noise, true_probas = true_prob$valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n\n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_valid) |&gt;\n    bind_rows(metrics_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      prune = prune,\n      min_bucket = min_bucket,\n      type = !!type,\n      nb_leaves = nb_leaves,\n      depth = depth,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  tb_prop_scores &lt;- proq_scores_train |&gt;\n    bind_rows(proq_scores_valid) |&gt;\n    bind_rows(proq_scores_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      prune = prune,\n      min_bucket = min_bucket,\n      type = !!type,\n      nb_leaves = nb_leaves,\n      depth = depth,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  tb_disp_metrics &lt;- disp_train |&gt;\n    bind_rows(disp_valid) |&gt;\n    bind_rows(disp_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      prune = prune,\n      min_bucket = min_bucket,\n      type = !!type,\n      nb_leaves = nb_leaves,\n      depth = depth,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  list(\n    scenario = simu_data$scenario,   # data scenario\n    ind = ind,                       # index for grid\n    repn = simu_data$repn,           # data replication ID\n    prune = prune,                   # pruned tree?\n    min_bucket = min_bucket,         # min number of obs in terminal leaf node\n    type = type,                     # tree type: regression or classification\n    metrics = tb_metrics,            # table with performance/calib metrics\n    disp_metrics = tb_disp_metrics,  # table with divergence metrics\n    tb_prop_scores = tb_prop_scores, # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist,       # histogram of scores\n    nb_leaves = nb_leaves,           # number of terminal leaves\n    depth = depth                    # tree depth\n  )\n}\n\n\n\n\n5.3.2 Grid\nWe define a grid with the different values for the arguments used to call the simul_tree() function. The whole grid can be seen in Table 5.1.\n\ngrid &lt;- expand_grid(\n  prune = FALSE,\n  min_bucket = unique(round(2^seq(1, 10, by = .1))),\n  type = \"regression\"\n) |&gt;\n  mutate(ind = row_number())\n\n\n\n\n\nTable 5.1: Configurations for the estimations\n\n\n\n\n\n\n\n\n\n\n\n\n5.3.3 Wrapper function\nWe define a function, simulate_tree_scenario(), that performs the replications of the estimations for a set of parameters of the grid.\n\n\nFunction simulate_tree_scenario()\n#' Simulations for a scenario (single replication)\n#'\n#' @returns list with the following elements:\n#'  - `metrics_all`: computed metrics for each set of hyperparameters.\n#'    Each row gives the values for unique keys\n#'    (type, prune, sample, min_bucket)\n#'  - `scores_hist`: histograms computed on the train/valid/test samples\n#'  - `prop_scores_simul` P(q1 &lt; s(x) &lt; q2) for various values of q1 and q2\n#'    Each row gives the values for unique keys\n#'    (type, prune, sample, min_bucket, q1, q2)\nsimulate_tree_scenario &lt;- function(scenario, params_df, repn) {\n  # Generate Data\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n  # Simulate Trees\n  progressr::with_progress({\n    p &lt;- progressr::progressor(steps = nrow(grid))\n    res_simul &lt;- furrr::future_map(\n      .x = seq_len(nrow(grid)),\n      .f = ~{\n        p()\n        simul_tree(\n          prune = grid$prune[.x],\n          min_bucket = grid$min_bucket[.x],\n          type = grid$type[.x],\n          simu_data = simu_data,\n          ind = grid$ind[.x]\n        )\n      },\n      .options = furrr::furrr_options(seed = NULL)\n    )\n  })\n  metrics_simul &lt;- map(res_simul, \"metrics\") |&gt; list_rbind()\n  disp_metrics_simul &lt;- map(res_simul, \"disp_metrics\") |&gt; list_rbind()\n  metrics &lt;- suppressMessages(\n    left_join(metrics_simul, disp_metrics_simul)\n  )\n  scores_hist &lt;- map(res_simul, \"scores_hist\")\n  prop_scores_simul &lt;- map(res_simul, \"tb_prop_scores\") |&gt; list_rbind()\n\n  list(\n    metrics_all = metrics,\n    scores_hist = scores_hist,\n    prop_scores_simul = prop_scores_simul\n  )\n}",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Decision Trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_trees.html#simulations",
    "href": "book_ojeda_trees.html#simulations",
    "title": "5  Decision Trees",
    "section": "5.4 Simulations",
    "text": "5.4 Simulations\nThe simulations are run in parallel.\n\n\nSimulation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(philentropy)\n  library(rpart)\n  library(ks)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl, c(\n    # Functions\n    \"brier_score\",\n    \"compute_metrics\",\n    \"dispersion_metrics\",\n    \"prop_btw_quantiles\",\n    \"subset_target\",\n    \"simulate_data\",\n    \"simulate_data_wrapper\",\n    \"simul_tree\",\n    \"simulate_tree_scenario\",\n    # Objects\n    \"grid\",\n    \"params_df\",\n    \"repns_vector\"\n  )\n)\n\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  clusterExport(cl, c(\"scenario\"))\n  resul_trees_scenario &lt;-\n    pblapply(\n      1:length(repns_vector), function(i) simulate_tree_scenario(\n        scenario = scenario, params_df = params_df, repn = repns_vector[i]\n      ),\n      cl = cl\n    )\n  save(\n    resul_trees_scenario,\n    file = str_c(\"output/simul/dgp-ojeda/resul_trees_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results will be stored in resul_trees. Each element will correspond to a replication\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_trees_scenario_\", 1:16, \".rda\"\n)\nresul_trees &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_trees_scenario})",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Decision Trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_trees.html#results",
    "href": "book_ojeda_trees.html#results",
    "title": "5  Decision Trees",
    "section": "5.5 Results",
    "text": "5.5 Results\n\n5.5.1 Tables\nWe can merge the metrics tables computed for each scenario and replications for these scenarios into a single tibble.\n\nmetrics_trees_all &lt;- map(\n  resul_trees,\n  function(resul_trees_sc) map(resul_trees_sc, \"metrics_all\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"valid\", \"test\"),\n      labels = c(\"Train\", \"Validation\", \"Test\")\n    )\n  )\n\nWe extract the metrics from the trees of interest, where the tree of interest are identified based on results obtained in the validation sample:\n\nsmallest: tree with the smallest average number of leaves\nlargest: tree with the highest average number of leaves\nlargest_auc: tree with the highest AUC on validation set\nlowest_mse: tree with the lowest MSE on validation set\nlowest_ici: tree with the lowest ICI on validation set\nlowest_kl: tree with the lowest KL Divergence on validation set\n\n\n\nCode to identify trees of interest\n# Identify the smallest tree\nsmallest_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(nb_leaves) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Identify the largest tree\nlargest_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(nb_leaves)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest\") |&gt;\n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest_auc\") |&gt;\n  ungroup()\n\n# Identify tree with lowest MSE\nlowest_mse_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_mse\") |&gt;\n  ungroup()\n\n# Identify tree with lowest ICI\nlowest_ici_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(ici) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_ici\") |&gt;\n  ungroup()\n\n# Identify tree with lowest Brier's score\nlowest_brier_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(brier) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_brier\") |&gt;\n  ungroup()\n\n# Identify tree with lowest KL\nlowest_kl_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_kl\") |&gt;\n  ungroup()\n\n# Merge these\ntrees_of_interest_tree &lt;-\n  smallest_tree |&gt;\n  bind_rows(largest_tree) |&gt;\n  bind_rows(highest_auc_tree) |&gt;\n  bind_rows(lowest_mse_tree) |&gt;\n  bind_rows(lowest_ici_tree) |&gt;\n  bind_rows(lowest_brier_tree) |&gt;\n  bind_rows(lowest_kl_tree)\n\n# Add metrics now\ntrees_of_interest_metrics_tree &lt;-\n  trees_of_interest_tree |&gt;\n  left_join(\n    metrics_trees_all, \n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_leaves\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  ) |&gt; \n  mutate(\n    result_type = factor(\n      result_type,\n      levels = c(\n        \"smallest\", \"largest\", \"lowest_mse\", \"largest_auc\",\n        \"lowest_brier\", \"lowest_ici\", \"lowest_kl\"),\n      labels = c(\n        \"Smallest\", \"Largest\", \"MSE*\", \"AUC*\", \n        \"Brier*\", \"ICI*\", \"KL*\"\n      )\n    )\n  )\n\n\n# Sanity check\n# trees_of_interest_metrics_tree |&gt; count(scenario, sample, result_type)\n\n\nThe metrics relative to the dispersion of the scores (i.e., \\(P(q_1 &lt; \\hat{s}(\\mathbf{x}) &lt; q_2)\\)).\n\ntrees_prop_scores_simul &lt;- map(\n  resul_trees,\n  function(resul_trees_sc) map(resul_trees_sc, \"prop_scores_simul\") |&gt; list_rbind()\n) |&gt;\n  list_rbind()\n\nLet us keep the metrics only for the trees of interest:\n\ntrees_of_interest_prop_scores_simul &lt;-\n  trees_of_interest_tree |&gt;\n  left_join(\n    trees_prop_scores_simul,\n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_leaves\"),\n    relationship = \"many-to-many\" # (train, validation, test, (q1,q2))\n  )\n\n\n\nCodes to create the table\nn_digits &lt;- 3\ntable_to_print &lt;-\n  trees_of_interest_metrics_tree |&gt;\n  group_by(scenario, sample, result_type) |&gt;\n  summarise(\n    across(\n      all_of(c(\n        \"AUC\", \"ici\", \"KL_20_true_probas\", \"inter_quantile_10_90\")\n      ),\n      ~str_c(round(mean(.x), n_digits), \" (\", round(sd(.x), n_digits), \")\")\n    ), .groups = \"drop\"\n  ) |&gt;\n  arrange(scenario, result_type) |&gt;\n  mutate(scenario = str_c(\"Scenario \", scenario))\n\ntable_to_print |&gt; \n  DT::datatable(rownames = FALSE,\n    colnames = c(\n      \"Scenario\" = \"scenario\",\n      \"Selected Tree\" = \"result_type\",\n      \"Sample\" = \"sample\",\n      \"ICI\" = \"ici\",\n      \"KL Div.\" = \"KL_20_true_probas\",\n      \"Quant. Ratio\" = \"inter_quantile_10_90\"\n      ),\n    filter = \"top\",\n    extensions = 'RowGroup',\n    options = list(\n      rowGroup = list(dataSrc = c(0)),\n      iDisplayLength = 21\n    )\n  ) |&gt; \n  DT::formatStyle(\n    1:ncol(table_to_print),\n    target = 'row',\n    backgroundColor = DT::styleEqual(\n      c(\"Smallest\", \"Largest\", \"AUC*\", \"MSE*\", \"Brier*\", \"ICI*\", \"KL*\"),\n      c(\"#332288\", \"#117733\", \"#AA4499\", \"#882255\",\"#DDCC77\", \"#44AA99\", \"#949698\")\n    ),\n    color = \"white\"\n  )\n\n\n\n\nTable 5.2: Average Performance and Calibration Metrics Computed on Test Set Over 100 Replications Under Scenario 1. Standard errors between round brackets.\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.2 Figures\n\n5.5.2.1 Distribution of Scores\nLet us plot the distributions of scores for the trees of interest (smallest, largest, max AUC, min MSE, min KL) for a single replication for each scenario.\n\n\nCodes to get the barplots\nget_bp &lt;- function(interest, \n                   scenario,\n                   repn) {\n  # Identify the row number of the grid\n  tree_of_interest &lt;- \n    trees_of_interest_metrics_tree |&gt; \n    filter(\n      result_type == !!interest, \n      scenario == !!scenario,\n      repn == !!repn,\n      sample == \"Test\"\n    )\n  \n  ind_grid &lt;- tree_of_interest |&gt; \n    pull(\"ind\")\n  \n  # The corresponding barplot data\n  data_bp &lt;- \n    map(resul_trees[[scenario]], \"scores_hist\")[[repn]] |&gt; \n    pluck(ind_grid)\n  \n  subtitle &lt;- str_c(\n    \"No. Leaves = \", tree_of_interest$nb_leaves, \", \",\n    \"AUC = \", round(tree_of_interest$AUC, 2), \", \\n\",\n    \"Brier = \", round(tree_of_interest$brier, 2), \", \",\n    \"ICI = \", round(tree_of_interest$ici, 2), \", \",\n    \"KL = \", round(tree_of_interest$KL_20_true_probas, 2)\n  )\n  \n  plot(\n    main = interest,\n    data_bp$test, \n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .6)\n}\n\nplot_hist_scenario &lt;- function(scenario, \n                               repn) {\n  par(mfrow = c(2,4), mar = c(4.1, 4.1, 4.1, 2.1))\n  # True probabilities\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn # only one replication here\n  )\n  true_prob &lt;- simu_data$data$probs_train\n  hist(\n    true_prob,\n    breaks = seq(0, 1, by = .05),\n    xlab = \"p\", ylab = \"\",\n    main = \"True Probabilities\",\n    xlim = c(0, 1)\n  )\n  \n  for (interest in c(\"Smallest\", \"Largest\", \"MSE*\" ,\"AUC*\", \"Brier*\", \"ICI*\", \"KL*\")) {\n    get_bp(\n      interest = interest, \n      scenario = scenario, \n      repn = repn\n    )\n  }\n}\n\n\nWe only show the distributions for the first replication.\n\nrepn &lt;- 1\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\nCode\nsave_graph &lt;- FALSE\nif (save_graph) {\n  cairo_pdf(\"figures/tree-scenario1-hist-scores.pdf\", width  = 8, height = 3)\n}\nplot_hist_scenario(scenario = 1, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (0 noise variables).\n\n\n\n\n\nCode\nif (save_graph) dev.off()\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 2, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (10 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 3, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (50 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 4, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (100 noise variables).\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\nCode\nplot_hist_scenario(scenario = 5, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (0 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 6, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (10 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 7, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (50 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 8, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test for trees of interest (100 noise variables).\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\nCode\nplot_hist_scenario(scenario = 9, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (0 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 10, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (10 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 11, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (50 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 12, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (100 noise variables).\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\nCode\nplot_hist_scenario(scenario = 13, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (0 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 14, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (10 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 15, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (50 noise variables).\n\n\n\n\n\n\n\n\n\nCode\nplot_hist_scenario(scenario = 16, repn = repn)\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for trees of interest (100 noise variables).\n\n\n\n\n\n\n\n\n\n\n\n\n\n5.5.2.2 Metrics vs Number of Leaves\nWe can plot some metrics (AUC, ICI, KL) as a function of the average number of leaves in the trees.\n\n\nCodes to get the plots\nplot_metric_leaves &lt;- function(dgp) {\n  data_plot &lt;-\n    metrics_trees_all |&gt;\n    mutate(\n      dgp = case_when(\n        scenario %in% 1:4 ~ 1,\n        scenario %in% 5:8 ~ 2,\n        scenario %in% 9:12 ~ 3,\n        scenario %in% 13:16 ~ 4\n      ),\n      no_noise = c(0, 10, 50, 100)[(scenario-1)%%4 + 1],\n      no_noise = factor(\n        no_noise, levels = c(no_noise),\n        labels = str_c(no_noise, \" noise variables\")\n      )\n    ) |&gt;\n    filter(dgp == !!dgp) |&gt;\n    group_by(\n      sample, dgp, no_noise, scenario, ind, min_bucket\n    ) |&gt;\n    summarise(\n      KL_20_true_probas = mean(KL_20_true_probas),\n      auc = mean(AUC),\n      brier = mean(brier),\n      ici = mean(ici),\n      nb_leaves = mean(nb_leaves),\n      .groups = \"drop\"\n    ) |&gt;\n    pivot_longer(cols = c(auc, brier, ici, KL_20_true_probas), names_to = \"metric\") |&gt;\n    mutate(metric = factor(\n      metric,\n      levels = c(\"auc\", \"brier\" ,\"ici\", \"KL_20_true_probas\"),\n      labels = c(\"AUC\", \"Brier\", \"ICI\", \"KL Divergence\")\n    ))\n\n  ggplot(\n    data = data_plot |&gt; arrange(nb_leaves),\n    mapping = aes(x = nb_leaves, y = value)\n  ) +\n    geom_line(\n      mapping = aes(colour = sample, group = )\n    ) +\n    ggh4x::facet_grid2(metric~no_noise, scales = \"free_y\", independent = \"y\") +\n    scale_colour_manual(\n      \"Sample\", values = colour_samples,\n      labels = c(\"Train\", \"Validation\", \"Test\")\n    ) +\n    theme_paper() +\n    labs(x = \"Average Number of leaves\", y = NULL)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n\nCode\nplot_metric_leaves(dgp = 1)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees (DGP 1)\n\n\n\n\n\n\n\n\n\nCode\nplot_metric_leaves(dgp = 2)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees (DGP 2)\n\n\n\n\n\n\n\n\n\nCode\nplot_metric_leaves(dgp = 3)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees (DGP 3)\n\n\n\n\n\n\n\n\n\nCode\nplot_metric_leaves(dgp = 4)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees (DGP 4)\n\n\n\n\n\n\n\n\n\n\n5.5.2.3 Relationship between calibration, KL divergence and tree complexity\nFor a given scenario, each dot in the figures below is obtained by computing the average metrics on the 100 replications.\n\n\nCodes to get the plots\ndata_plot &lt;- metrics_trees_all |&gt; \n  group_by(\n    sample, scenario, ind\n  ) |&gt; \n  summarise(\n    KL_20_true_probas = mean(KL_20_true_probas),\n    ici = mean(ici),\n    nb_leaves = mean(nb_leaves),\n    AUC = mean(AUC)\n  ) |&gt; \n  filter(sample==\"Test\") |&gt; \n  mutate(\n    scenario_lab = factor(str_c(\"Scenario \", scenario)),\n    scenario_lab = fct_reorder(scenario_lab, scenario)\n  ) |&gt; \n  group_by(\n    sample, scenario\n  ) |&gt; \n  mutate(\n    is_max_auc = AUC == max(AUC),\n    is_max_auc = factor(is_max_auc, levels = c(TRUE, FALSE), labels = c(\"Yes\", \"No\"))\n  ) |&gt; \n  ungroup()\n\nggplot(\n  data = data_plot,\n  mapping = aes(\n    x = ici, y = KL_20_true_probas, group = sample\n  )\n) + \n  geom_point(\n    mapping = aes(\n      size = nb_leaves,\n      colour = is_max_auc, fill = is_max_auc, alpha = is_max_auc)\n    ) +\n  facet_wrap(~scenario_lab, ncol = 4, scales = \"free\") +\n  labs(x = \"Calibration (ICI)\", y = \"KL Divergence\") +\n  scale_size_binned_area(\"Number of Leaves\") +\n  scale_colour_manual(\n    \"Max AUC\", values = c(\"Yes\" = \"red\", \"No\" = \"gray\")\n  ) +\n  scale_fill_manual(\n    \"Max AUC\", values = c(\"Yes\" = \"red\", \"No\" = \"gray\")\n  ) +\n  scale_alpha_manual(\n    \"Max AUC\", values = c(\"Yes\" = 1, \"No\" = .5)\n  ) +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\"))\n\n\n\n\n\nFigure 5.1: Kullback-Leibler divergence between estimated scores and true probabilities vs. calibration, for various tree depths (Test set).\n\n\n\n\n\n\n\n\nLet us also visualize this using ggplot2 instead.\n\n\nCodes to get the plots\nplot_kl_vs_calib &lt;- function(scenario_number, \n                             calib_metric,\n                             log_scale = FALSE) {\n  data_plot &lt;- metrics_trees_all |&gt; \n    filter(scenario == !!scenario_number) |&gt; \n    group_by(sample, scenario, ind) |&gt; \n    summarise(\n      KL_20_true_probas = mean(KL_20_true_probas),\n      ici = mean(ici),\n      brier = mean(brier),\n      nb_leaves = mean(nb_leaves),\n      auc = mean(AUC),\n      .groups = \"drop\"\n    )\n  \n  data_plot_max_auc &lt;- \n    data_plot |&gt; \n    filter(sample == \"Test\") |&gt; \n    group_by(sample, scenario) |&gt;\n    mutate(is_max_auc = auc == max(auc)) |&gt; \n    ungroup() |&gt; \n    filter(is_max_auc == TRUE) |&gt; \n    select(sample, scenario, !!calib_metric, KL_20_true_probas)\n  \n  x_lab &lt;- latex2exp::TeX(\n    str_c(\n    \"Calibration (\", ifelse(calib_metric == \"ici\", \"ICI\", \"Brier Score\"),\n    ifelse(log_scale == TRUE, \", log scale)\", \")\")\n    )\n  )\n  \n  p &lt;- ggplot(\n    data = data_plot |&gt; arrange(nb_leaves),\n    mapping = aes(\n      x = !!sym(calib_metric), y = KL_20_true_probas\n    )\n  ) + \n    geom_path(\n      mapping = aes(colour = sample),\n      arrow = arrow(type = \"closed\", ends = \"last\", \n                    length = unit(0.08, \"inches\"))\n    ) +\n    geom_vline(\n      data = data_plot_max_auc,\n      mapping = aes(xintercept = !!sym(calib_metric)),\n      linetype = \"dashed\"\n    ) +\n    geom_hline(\n      data = data_plot_max_auc,\n      mapping = aes(yintercept = KL_20_true_probas),\n      linetype = \"dashed\"\n    ) +\n    scale_colour_manual(\"Sample\", values = colour_samples, \n                        labels = c(\"Train\", \"Validation\", \"Test\")) +\n    labs(x = x_lab, y = \"KL Divergence\") +\n    scale_size_binned_area(\"Number of Leaves\") +\n    theme_paper() +\n    theme(legend.key.width = unit(1.5, \"cm\"))\n  \n  if (log_scale) p &lt;- p + scale_x_log10() + scale_y_log10()\n  p\n}\n\n\nThe dashed lines correspond to the values of the KL divergence and the calibration of the forest at which the AUC is the highest among the models of the grid search.\n\nICIICI, log scaleBrierBrier, log scale\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also put all the scenarios in a single graph.\n\n\nCodes to create the figure\ndata_plot &lt;- metrics_trees_all |&gt; \n  group_by(\n    sample, scenario, ind\n  ) |&gt; \n  summarise(\n    KL_20_true_probas = mean(KL_20_true_probas),\n    ici = mean(ici),\n    brier = mean(brier),\n    nb_leaves = mean(nb_leaves),\n    auc = mean(AUC),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    dgp = case_when(\n      scenario %in% 1:4 ~ 1,\n      scenario %in% 5:8 ~ 2,\n      scenario %in% 9:12 ~ 3,\n      scenario %in% 13:16 ~ 4\n    ),\n    dgp = factor(dgp, levels = 1:4, labels = str_c(\"DGP \", 1:4)),\n    no_noise = c(0, 10, 50, 100)[(scenario-1)%%4 + 1],\n    no_noise = factor(\n      no_noise, levels = c(0, 10, 50, 100),\n      labels = str_c(c(0, 10, 50, 100), \" noise variables\")\n    )\n  )\n\n\ndata_plot_max_auc &lt;- \n  data_plot |&gt; \n  filter(sample == \"Test\") |&gt; \n  group_by(sample, scenario) |&gt; \n  mutate(is_max_auc = auc == max(auc)) |&gt; \n  ungroup() |&gt; \n  filter(is_max_auc == TRUE) |&gt; \n  select(sample, scenario, dgp, no_noise, ici, brier, KL_20_true_probas)\n\n\n\nICI, log scaleBrier, log scale\n\n\n\n\nCodes to create the figure\nformatter1000 &lt;- function(x) x*1000\n\np_ici &lt;- ggplot(\n  data = data_plot |&gt; arrange(nb_leaves),\n  mapping = aes(\n    x = ici, y = KL_20_true_probas\n  )\n) + \n  geom_path(\n    mapping = aes(colour = sample),\n    arrow = arrow(type = \"closed\", ends = \"last\", \n                  length = unit(0.08, \"inches\"))\n  ) +\n  geom_vline(\n    data = data_plot_max_auc,\n    mapping = aes(xintercept = ici),\n    linetype = \"dashed\"\n  ) +\n  geom_hline(\n    data = data_plot_max_auc,\n    mapping = aes(yintercept = KL_20_true_probas),\n    linetype = \"dashed\"\n  ) +\n  facet_grid(dgp~no_noise) +\n  # ggh4x::facet_grid2(dgp~no_noise, scales = \"free_y\") +\n  scale_colour_manual(\n    \"Sample\", values = colour_samples,\n    labels = c(\"Train\", \"Validation\", \"Test\")) +\n  labs(\n    x = latex2exp::TeX(\"Calibration (ICI), $\\\\times 10^{3}$, log scale\"), \n    y = \"KL Divergence\"\n  ) +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\")) +\n  scale_x_log10(labels = formatter1000) + scale_y_log10()\n\nggsave(p_ici, file = \"figures/trees-kl-calib-ici-leaves-all.pdf\",\n       width = 10, height = 8)\n\np_ici\n\n\n\n\n\nFigure 5.2: KL Divergence and Calibration (ICI) across increasing average number of leaves in the trees (log scales)\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the figure\nformatter1000 &lt;- function(x) x*1000\n\np_brier &lt;- ggplot(\n  data = data_plot |&gt; arrange(nb_leaves),\n  mapping = aes(\n    x = brier, y = KL_20_true_probas\n  )\n) + \n  geom_path(\n    mapping = aes(colour = sample),\n    arrow = arrow(type = \"closed\", ends = \"last\", \n                  length = unit(0.08, \"inches\"))\n  ) +\n  geom_vline(\n    data = data_plot_max_auc,\n    mapping = aes(xintercept = ici),\n    linetype = \"dashed\"\n  ) +\n  geom_hline(\n    data = data_plot_max_auc,\n    mapping = aes(yintercept = KL_20_true_probas),\n    linetype = \"dashed\"\n  ) +\n  facet_grid(dgp~no_noise) +\n  scale_colour_manual(\n    \"Sample\", values = colour_samples,\n    labels = c(\"Train\", \"Validation\", \"Test\")) +\n  labs(\n    x = latex2exp::TeX(\"Calibration (Brier), $\\\\times 10^{3}$, log scale\"), \n    y = \"KL Divergence\"\n  ) +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\")) +\n  scale_x_log10(labels = formatter1000) + scale_y_log10()\n\nggsave(p_brier, file = \"figures/trees-kl-calib-brier-leaves-all.pdf\",\n       width = 10, height = 8)\n\np_brier\n\n\n\n\n\nFigure 5.3: KL Divergence and Calibration (ICI) across increasing average number of leaves in the trees (log scales)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Decision Trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests.html",
    "href": "book_ojeda_forests.html",
    "title": "6  Random Forests",
    "section": "",
    "text": "6.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_valid = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests.html#metrics",
    "href": "book_ojeda_forests.html#metrics",
    "title": "6  Random Forests",
    "section": "6.2 Metrics",
    "text": "6.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests.html#simulations-setup",
    "href": "book_ojeda_forests.html#simulations-setup",
    "title": "6  Random Forests",
    "section": "6.3 Simulations Setup",
    "text": "6.3 Simulations Setup\nWe train different forests using the {ranger} package.\n\nlibrary(ranger)\n\nFor each scenario, we train regression forests. Each forest is made of 250 trees (smaller forests are considered in Chapter 7). We consider here the following hyperparameters:\n\nmtry: Number of variables to possibly split at in each node: 2, 4 or 10.\nmin_node_size: Minimal node size to split at. Varying values between 2 and 10^{4}.\n\n\nmin_bucket_values &lt;- unique(round(2^seq(1, 14, by = .4)))\nmin_bucket_values &lt;- min_bucket_values[min_bucket_values &lt;=  max(params_df$size_train)]\n\ngrid &lt;- expand_grid(\n  mtry = c(2, 4, 10),\n  num_trees = 250,\n  min_node_size = min_bucket_values\n) |&gt; \n  mutate(ind = row_number())\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100\n\nThe different configurations are reported in Table 7.1.\n\n\n\n\nTable 6.1: Grid Search Values\n\n\n\n\n\n\n\n\n\n\nWe define a function, simul_forest() to train a random forest on a dataset for a type of forest, with given hyperparameters (given to the function through the param argument).\n\n\nFunction simul_forest()\n#' Train a random forest and compute performance, calibration, and dispersion \n#' metrics\n#' \n#' @param params tibble with hyperparameters for the simulation\n#' @param ind index of the grid (numerical ID)\n#' @param simu_data simulated data obtained with `simulate_data_wrapper()`\n#'  for probability trees\nsimul_forest &lt;- function(params,\n                         ind,\n                         simu_data) {\n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_valid &lt;- simu_data$data$valid |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n\n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      valid = simu_data$data$probs_valid,\n      test = simu_data$data$probs_test\n    )\n\n  ## Estimation----\n  fit_rf &lt;- ranger(\n    d ~ .,\n    data = tb_train,\n    min.bucket = params$min_node_size,\n    mtry = params$mtry,\n    num.trees = params$num_trees\n  )\n\n  # Average number of leaves per trees in the forest\n  nb_leaves &lt;- map_dbl(fit_rf$forest$child.nodeIDs, ~sum(pluck(.x, 1) == 0)) |&gt;\n    mean()\n\n\n  ## Raw Scores----\n  # Predicted scores\n  scores_train &lt;- predict(fit_rf, data = tb_train, type = \"response\")$predictions\n  scores_valid &lt;- predict(fit_rf, data = tb_valid, type = \"response\")$predictions\n  scores_test &lt;- predict(fit_rf, data = tb_test, type = \"response\")$predictions\n\n  ## Histogram of scores----\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_valid_hist &lt;- hist(scores_valid, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    valid = scores_valid_hist,\n    test = scores_test_hist\n  )\n\n  ## Estimation of P(q1 &lt; score &lt; q2)----\n  proq_scores_train &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_valid &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_valid, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"valid\")\n  proq_scores_test &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n\n  ## Dispersion Metrics----\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n\n  disp_valid &lt;- dispersion_metrics(\n    true_probas = true_prob$valid, scores = scores_valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n\n  # Performance and Calibration Metrics\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n\n  scores_valid_noise &lt;- scores_valid +\n    runif(n = length(scores_valid), min = 0, max = 0.01)\n  scores_valid_noise[scores_valid_noise &gt; 1] &lt;- 1\n  metrics_valid &lt;- compute_metrics(\n    obs = tb_valid$d, scores = scores_valid_noise, true_probas = true_prob$valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n\n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_valid) |&gt;\n    bind_rows(metrics_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      min_bucket = params$min_node_size,\n      nb_leaves = nb_leaves,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  tb_prop_scores &lt;- proq_scores_train |&gt;\n    bind_rows(proq_scores_valid) |&gt;\n    bind_rows(proq_scores_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      min_bucket = params$min_node_size,\n      nb_leaves = nb_leaves,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  tb_disp_metrics &lt;- disp_train |&gt;\n    bind_rows(disp_test) |&gt;\n    bind_rows(disp_valid) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      min_bucket = params$min_node_size,\n      nb_leaves = nb_leaves,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  list(\n    scenario = simu_data$scenario,     # data scenario\n    ind = ind,                         # index for grid\n    repn = simu_data$repn,             # data replication ID\n    min_bucket = params$min_node_size, # min number of obs in terminal leaf node\n    metrics = tb_metrics,              # table with performance/calib metrics\n    disp_metrics = tb_disp_metrics,    # table with divergence metrics\n    tb_prop_scores = tb_prop_scores,   # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist,         # histogram of scores\n    nb_leaves = nb_leaves              # number of terminal leaves\n  )\n}\n\n\nWe define a wrapper function, simulate_rf_scenario() which performs a single replication of the simulations going over the different values of the grid search, for a given scenario.\n\n\nFunction simulate_rf_scenario()\n#' Simulations for a scenario (single replication)\n#' \n#' @returns list with the following elements:\n#'  - `metrics_all`: computed metrics for each set of hyperparameters. \n#'    Each row gives the values for unique keys \n#'    (sample, min_bucket)\n#'  - `prop_scores_simul` P(q1 &lt; s(x) &lt; q2) for various values of q1 and q2\n#'    Each row gives the values for unique keys \n#'    (sample, min_bucket, q1, q2)\n#'    q1, q2, min_bucket, type, sample)\n#'  - `metrics`: computed metrics for trees of interest \n#'    (smallest, largest, largest AUC, lowest MSE, lowest KL div.).\n#'    Each row gives the values for unique keys \n#'    (sample, type of tree of interest)\nsimulate_rf_scenario &lt;- function(scenario, params_df, repn) {\n  # Generate Data\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n  \n  res_simul &lt;- vector(mode = \"list\", length = nrow(grid))\n  # cli::cli_progress_bar(\"Iteration grid\", total = nrow(grid), type = \"tasks\")\n  for (j in 1:nrow(grid)) {\n    curent_params &lt;- grid |&gt; slice(!!j)\n    n_var &lt;- simu_data$params_df$n_num + simu_data$params_df$add_categ * 5 + \n      simu_data$params_df$n_noise\n    if (curent_params$mtry &gt; n_var) {\n      # cli::cli_progress_update()\n      next()\n    }\n    \n    res_simul[[j]] &lt;- simul_forest(\n      params = curent_params,\n      ind = curent_params$ind,\n      simu_data = simu_data\n    )\n    # cli::cli_progress_update()\n  }\n  \n  metrics_simul &lt;- map(res_simul, \"metrics\") |&gt; list_rbind()\n  disp_metrics_simul &lt;- map(res_simul, \"disp_metrics\") |&gt; list_rbind()\n  metrics &lt;- suppressMessages(\n    left_join(metrics_simul, disp_metrics_simul)\n  )\n  scores_hist &lt;- map(res_simul, \"scores_hist\")\n  prop_scores_simul &lt;- map(res_simul, \"tb_prop_scores\") |&gt; list_rbind()\n  \n  # Metrics for different trees in those estimated\n  # - Smallest number of leaves\n  # - Largest number of leaves\n  # - Max AUC\n  # - Min MSE\n  # - Min KL\n  \n  # Identify the smallest tree\n  smallest &lt;-\n    metrics |&gt;\n    filter(sample == \"test\") |&gt;\n    arrange(nb_leaves) |&gt;\n    slice_head(n = 1) |&gt;\n    select(ind) |&gt;\n    mutate(result_type = \"smallest\")\n  \n  # Identify the largest tree\n  largest &lt;-\n    metrics |&gt;\n    filter(sample == \"test\") |&gt;\n    arrange(desc(nb_leaves)) |&gt;\n    slice_head(n = 1) |&gt;\n    select(ind) |&gt;\n    mutate(result_type = \"largest\")\n  \n  # Identify tree with highest AUC on test set\n  highest_auc &lt;- metrics |&gt;\n    filter(sample == \"test\") |&gt;\n    arrange(desc(AUC)) |&gt;\n    slice_head(n = 1) |&gt;\n    select(ind) |&gt;\n    mutate(result_type = \"largest_auc\")\n  \n  # Identify tree with lowest MSE\n  lowest_mse &lt;- metrics |&gt;\n    filter(sample == \"test\") |&gt;\n    arrange(mse) |&gt;\n    slice_head(n = 1) |&gt;\n    select(ind) |&gt;\n    mutate(result_type = \"lowest_mse\")\n  \n  # Identify tree with lowest KL\n  lowest_kl &lt;- metrics |&gt;\n    filter(sample == \"test\") |&gt;\n    arrange(KL_20_true_probas) |&gt;\n    slice_head(n = 1) |&gt;\n    select(ind) |&gt;\n    mutate(result_type = \"lowest_kl\")\n  \n  trees_of_interest &lt;-\n    smallest |&gt;\n    bind_rows(largest) |&gt;\n    bind_rows(highest_auc) |&gt;\n    bind_rows(lowest_mse) |&gt;\n    bind_rows(lowest_kl)\n  \n  trees_of_interest_metrics &lt;-\n    trees_of_interest |&gt;\n    left_join(\n      metrics, \n      by = c(\"ind\"),\n      relationship = \"many-to-many\" # (train, test)\n    )\n  trees_of_interest_prop_scores_simul &lt;-\n    trees_of_interest |&gt;\n    left_join(\n      prop_scores_simul, \n      by = c(\"ind\"),\n      relationship = \"many-to-many\" # (train, test)\n    )\n  \n  list(\n    metrics_all = metrics,\n    metrics = trees_of_interest_metrics,\n    scores_hist = scores_hist,\n    prop_scores_simul = trees_of_interest_prop_scores_simul\n  )\n}",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests.html#simulations",
    "href": "book_ojeda_forests.html#simulations",
    "title": "6  Random Forests",
    "section": "6.4 Simulations",
    "text": "6.4 Simulations\nWe loop over the scenarios and run the 100 replications in parallel.\n\n\nSimulation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(philentropy)\n  library(ranger)\n  library(ks)\n}) |&gt; \n  invisible()\n\nclusterExport(\n  cl, c(\n    # Functions\n    \"brier_score\",\n    \"compute_metrics\",\n    \"dispersion_metrics\",\n    \"prop_btw_quantiles\",\n    \"subset_target\",\n    \"simulate_data\",\n    \"simulate_data_wrapper\",\n    \"simul_forest\",\n    \"simulate_rf_scenario\",\n    # Objects\n    \"grid\",\n    \"params_df\",\n    \"repns_vector\"\n  )\n)\n\ndir.create(\"output/simul/dgp-ojeda/\", recursive = TRUE)\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  clusterExport(cl, c(\"scenario\"))\n  resul_rf_scenario &lt;-\n    pblapply(\n      1:length(repns_vector), function(i) simulate_rf_scenario(\n        scenario = scenario, params_df = params_df, repn = repns_vector[i]\n      ),\n      cl = cl\n    )\n  save(\n    resul_rf_scenario,\n    file = str_c(\"output/simul/dgp-ojeda/resul_rf_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results can be loaded as follows:\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_rf_scenario_\", 1:16, \".rda\"\n)\nresul_rf &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_rf_scenario})\n\nThe resul_rf object is of length 16: each element contains the simulations for a scenario. For each scenario, the elements are a list of length max(repns_vector), i.e., the number of replications. Each replication gives, in a list, the following elements:\n\nmetrics_all: the metrics (AUC, Calibration, KL Divergence, etc.) for each model from the grid search \nscores_hist: the counts on bins defined on estimated scores (on train, validation, and test sets)\nprop_scores_simul: the estimations of \\(\\mathbb{P}(q_1 &lt; \\hat{\\mathbf{x}}&lt; q_2)\\) for various values of q_1 and q_2.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests.html#results",
    "href": "book_ojeda_forests.html#results",
    "title": "6  Random Forests",
    "section": "6.5 Results",
    "text": "6.5 Results\nWe can now extract some information from the results.\n\n6.5.1 Tables\nWe can merge the metrics tables computed for each scenario and replications for these scenarios into a single tibble.\n\nmetrics_rf_all &lt;- map(\n  resul_rf,\n  function(resul_rf_sc) map(resul_rf_sc, \"metrics_all\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\", \"valid\"),\n      labels = c(\"Train\", \"Test\", \"Validation\")\n    )\n  )\n\nLet us exclude here the random forests with only 1 leaf in the nodes.\n\nmetrics_rf_all &lt;- filter(metrics_rf_all, nb_leaves &gt; 1)\n\nThe metrics relative to the dispersion of the scores (i.e., \\(P(q_1 &lt; \\hat{s}(\\mathbf{x}) &lt; q_2)\\)).\n\nrf_prop_scores_simul &lt;- map(\n  resul_rf, \n  function(resul_rf_sc) map(resul_rf_sc, \"prop_scores_simul\") |&gt; list_rbind()\n) |&gt; \n  list_rbind()\n\nAnd then, let us also get the trees of interest for each replication (smallest, largest, the one that maximizes the AUC, that minimizes the MSE, that minimizes the KL divergence).\n\n\nCode to identify forests of interest.\n# Identify the model with the smallest number of leaves on average on\n# validation set\nsmallest_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(nb_leaves) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Identify the largest tree\nlargest_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(nb_leaves)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest\") |&gt;\n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest_auc\") |&gt;\n  ungroup()\n\n# Identify tree with lowest MSE\nlowest_mse_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_mse\") |&gt;\n  ungroup()\n\n# Identify tree with lowest Brier\nlowest_brier_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(brier) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_brier\") |&gt;\n  ungroup()\n\n# Identify tree with lowest ICI\nlowest_ici_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(ici) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_ici\") |&gt;\n  ungroup()\n\n# Identify tree with lowest KL\nlowest_kl_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_kl\") |&gt;\n  ungroup()\n\n# Merge these\nrf_of_interest &lt;-\n  smallest_rf |&gt;\n  bind_rows(largest_rf) |&gt;\n  bind_rows(highest_auc_rf) |&gt;\n  bind_rows(lowest_mse_rf) |&gt;\n  bind_rows(lowest_brier_rf) |&gt;\n  bind_rows(lowest_ici_rf) |&gt;\n  bind_rows(lowest_kl_rf)\n\n# Add metrics now\nrf_of_interest &lt;-\n  rf_of_interest |&gt;\n  left_join(\n    metrics_rf_all,\n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_leaves\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  ) |&gt;\n  mutate(\n    result_type = factor(\n      result_type,\n      levels = c(\n        \"smallest\", \"largest\", \"lowest_mse\", \"largest_auc\",\n        \"lowest_brier\", \"lowest_ici\", \"lowest_kl\"),\n      labels = c(\n        \"Smallest\", \"Largest\", \"MSE*\", \"AUC*\",\n        \"Brier*\", \"ICI*\", \"KL*\"\n      )\n    )\n  )\n# Sanity check\n# rf_of_interest |&gt; count(scenario, sample, result_type)\n\n\n\n\nCodes to create the table\nn_digits &lt;- 3\ntable_to_print &lt;-\n  rf_of_interest |&gt;\n  group_by(scenario, sample, result_type) |&gt;\n  summarise(\n    across(\n      all_of(c(\n        \"mse\", \"AUC\", \"brier\", \"ici\", \"KL_20_true_probas\",\n        \"inter_quantile_10_90\")),\n      ~str_c(round(mean(.x), n_digits), \" (\", round(sd(.x), n_digits), \")\")\n    ), .groups = \"drop\"\n  ) |&gt;\n  arrange(scenario, result_type) |&gt;\n  mutate(scenario = str_c(\"Scenario \", scenario))\n\ntable_to_print |&gt;\n  DT::datatable(\n    rownames = FALSE,\n    colnames = c(\n      \"Scenario\" = \"scenario\",\n      \"Selected Tree\" = \"result_type\",\n      \"Sample\" = \"sample\",\n      \"ICI\" = \"ici\",\n      \"KL Div.\" = \"KL_20_true_probas\",\n      \"Quant. Ratio\" = \"inter_quantile_10_90\"\n    ),\n    filter = \"top\",\n    extensions = 'RowGroup',\n    options = list(\n      rowGroup = list(dataSrc = c(0)),\n      iDisplayLength = 21\n    )\n  ) |&gt;\n  DT::formatStyle(\n    1:ncol(table_to_print),\n    target = 'row',\n    backgroundColor = DT::styleEqual(\n      c(\"Smallest\", \"Largest\", \"AUC*\", \"MSE*\", \"Brier*\", \"ICI*\", \"KL*\"),\n      c(\"#332288\", \"#117733\", \"#AA4499\", \"#882255\",\"#DDCC77\", \"#44AA99\", \"#949698\")\n    ),\n    color = \"white\"\n  )\n\n\n\n\nTable 6.2: Average Performance and Calibration Metrics Computed on Test Set Over 100 Replications Under Scenario 1. Standard errors between round brackets.\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.2 Figures\n\n6.5.2.1 Scores Distributions\nLet us plot the distributions of scores for the trees of interest (smallest, largest, max AUC, min MSE, min KL) for a single replication (the first replication) for each scenario.\n\n\nCodes to get the barplots\nget_bp &lt;- function(interest,\n                   scenario,\n                   repn) {\n  # Identify the row number of the grid\n  rf_of_interest_plot &lt;-\n    rf_of_interest |&gt;\n    filter(\n      result_type == !!interest,\n      scenario == !!scenario,\n      repn == !!repn,\n      sample == \"Test\"\n    )\n\n  ind_grid &lt;- rf_of_interest_plot |&gt;\n    pull(\"ind\")\n\n  # The corresponding barplots data\n  data_bp &lt;-\n    map(resul_rf[[scenario]], \"scores_hist\")[[repn]] |&gt;\n    pluck(ind_grid)\n\n  subtitle &lt;- str_c(\n    \"No. Leaves = \", rf_of_interest_plot$nb_leaves, \", \",\n    \"AUC = \", round(rf_of_interest_plot$AUC, 2), \", \\n\",\n    \"Brier = \", round(rf_of_interest_plot$brier, 2), \", \",\n    \"ICI = \", round(rf_of_interest_plot$ici, 2), \", \",\n    \"KL = \", round(rf_of_interest_plot$KL_20_true_probas, 2)\n  )\n\n  plot(\n    main = interest,\n    data_bp$test,\n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .6)\n}\n\nplot_hist_scenario &lt;- function(scenario,\n                               repn) {\n  par(mfrow = c(2,4))\n  # True probabilities\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn # only one replication here\n  )\n  true_prob &lt;- simu_data$data$probs_train\n  hist(\n    true_prob,\n    breaks = seq(0, 1, by = .05),\n    xlab = \"p\", ylab = \"\",\n    main = \"True Probabilities\",\n    xlim = c(0, 1)\n  )\n\n  for (interest in c(\"Smallest\", \"Largest\", \"MSE*\" ,\n                     \"AUC*\", \"Brier*\", \"ICI*\", \"KL*\")) {\n    get_bp(\n      interest = interest,\n      scenario = scenario,\n      repn = repn\n    )\n  }\n}\n\n\nShowing plots for the first replication only:\n\nrepn &lt;- 1\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n6.5.2.2 Metrics vs Number of Leaves\nWe can also plot some metrics as a function of the average number of leaves in the trees of the forests.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to get the plots\nplot_metric_leaves &lt;- function(dgp) {\n  data_plot &lt;-\n    metrics_rf_all |&gt;\n    mutate(\n      dgp = case_when(\n        scenario %in% 1:4 ~ 1,\n        scenario %in% 5:8 ~ 2,\n        scenario %in% 9:12 ~ 3,\n        scenario %in% 13:16 ~ 4\n      ),\n      no_noise = c(0, 10, 50, 100)[(scenario-1)%%4 + 1],\n      no_noise = factor(no_noise, levels = c(no_noise), labels = str_c(no_noise, \" noise variables\"))\n    ) |&gt;\n    filter(dgp == !!dgp) |&gt;\n    left_join(grid |&gt; select(ind, mtry, min_node_size, num_trees), by = \"ind\") |&gt;\n    group_by(\n      sample, dgp, no_noise, scenario, ind, mtry\n    ) |&gt;\n    summarise(\n      KL_20_true_probas = mean(KL_20_true_probas),\n      auc = mean(AUC),\n      brier = mean(brier),\n      ici = mean(ici),\n      nb_leaves = mean(nb_leaves),\n      .groups = \"drop\"\n    ) |&gt;\n    mutate(\n      mtry_lab = factor(mtry),\n      mtry_lab = fct_reorder(mtry_lab, mtry),\n    ) |&gt;\n    pivot_longer(cols = c(auc, brier, ici, KL_20_true_probas), names_to = \"metric\") |&gt;\n    mutate(metric = factor(\n      metric,\n      levels = c(\"auc\", \"brier\", \"ici\", \"KL_20_true_probas\"),\n      labels = c(\"AUC\", \"Brier\", \"ICI\", \"KL Divergence\")\n    ))\n\n  ggplot(\n    data = data_plot |&gt; group_by(mtry_lab) |&gt; arrange(nb_leaves),\n    mapping = aes(x = nb_leaves, y = value)\n  ) +\n    geom_line(\n      mapping = aes(colour = sample, linetype = mtry_lab, group = )\n    ) +\n    ggh4x::facet_grid2(metric~no_noise, scales = \"free_y\", independent = \"y\") +\n    scale_colour_manual(\"Sample\", values = colour_samples) +\n    scale_linetype_discrete(\"Mtry\") +\n    theme_paper() +\n    labs(x = \"Average Number of leaves\", y = NULL)\n}\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n\nCode\nplot_metric_leaves(dgp = 1)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees of the forests (DGP 1)\n\n\n\n\n\n\n\n\n\nCode\nplot_metric_leaves(dgp = 2)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees of the forests (DGP 2)\n\n\n\n\n\n\n\n\n\nCode\nplot_metric_leaves(dgp = 3)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees of the forests (DGP 3)\n\n\n\n\n\n\n\n\n\nCode\nplot_metric_leaves(dgp = 4)\n\n\n\n\nMetrics depending on the average number of leaves in the estimated trees of the forests (DGP 4)\n\n\n\n\n\n\n\n\n\n\n6.5.2.3 Relationship between calibration, KL divergence and tree complexity\nFor a given scenario, each dot in the figures below is obtained by computing the average metrics on the 100 replications.\n\n\nCodes to get the plots\nplot_kl_vs_calib &lt;- function(scenario_number,\n                             calib_metric,\n                             log_scale = FALSE) {\n  data_plot &lt;- metrics_rf_all |&gt;\n    left_join(grid |&gt; select(ind, mtry)) |&gt;\n    filter(scenario == !!scenario_number) |&gt;\n    group_by(\n      sample, scenario, ind, mtry\n    ) |&gt;\n    summarise(\n      KL_20_true_probas = mean(KL_20_true_probas),\n      ici = mean(ici),\n      brier = mean(brier),\n      nb_leaves = mean(nb_leaves),\n      auc = mean(AUC),\n      .groups = \"drop\"\n    ) |&gt;\n    mutate(\n      mtry_lab = factor(str_c(\"mtry = \", mtry)),\n      mtry_lab = fct_reorder(mtry_lab, mtry)\n    )\n\n\n  data_plot_max_auc &lt;-\n    data_plot |&gt;\n    filter(sample == \"Test\") |&gt;\n    group_by(sample, scenario) |&gt; # not by mtry here\n    mutate(is_max_auc = auc == max(auc)) |&gt;\n    ungroup() |&gt;\n    filter(is_max_auc == TRUE) |&gt;\n    select(sample, scenario, !!calib_metric, KL_20_true_probas)\n\n  x_lab &lt;- str_c(\n    \"Calibration (\", ifelse(calib_metric == \"ici\", \"ICI\", \"Brier Score\"),\n    ifelse(log_scale == TRUE, \", log scale)\", \")\")\n  )\n\n\n  p &lt;- ggplot(\n    data = data_plot |&gt; group_by(mtry) |&gt; arrange(nb_leaves),\n    mapping = aes(\n      x = !!sym(calib_metric), y = KL_20_true_probas\n    )\n  ) +\n    # geom_point(alpha = .5, mapping = aes(size = nb_leaves, colour = sample)) +\n    geom_path(\n      mapping = aes(colour = sample),\n      arrow = arrow(type = \"closed\", ends = \"last\",\n                    length = unit(0.08, \"inches\"))\n    ) +\n    geom_vline(\n      data = data_plot_max_auc,\n      mapping = aes(xintercept = !!sym(calib_metric)),\n      linetype = \"dashed\"\n    ) +\n    geom_hline(\n      data = data_plot_max_auc,\n      mapping = aes(yintercept = KL_20_true_probas),\n      linetype = \"dashed\"\n    ) +\n    facet_grid(~mtry_lab) +\n    scale_colour_manual(\"Sample\", values = colour_samples) +\n    labs(x = x_lab, y = \"KL Divergence\") +\n    scale_size_binned_area(\"Number of Leaves\") +\n    theme_paper() +\n    theme(legend.key.width = unit(1.5, \"cm\"))\n\n  if (log_scale) p &lt;- p + scale_x_log10() + scale_y_log10()\n  p\n}\n\n\nThe dashed lines correspond to the values of the KL divergence and the calibration of the forest at which the AUC is the highest among the models of the grid search.\n\nICIICI, log scaleBrierBrier, log scale\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 1, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 2, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 3, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 0 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 10 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 50 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\nComplexity of a tree and relationship with calibration and divergence of scores to the true probabilities. (DGP 4, 100 noise variables, log scale)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe can also put all the scenarios in a single graph.\n\n\nCodes to prepare the figure\ndata_plot &lt;- metrics_rf_all |&gt; \n  left_join(grid |&gt; select(ind, mtry), by = \"ind\") |&gt; \n  group_by(\n    sample, scenario, ind, mtry\n  ) |&gt; \n  summarise(\n    KL_20_true_probas = mean(KL_20_true_probas),\n    ici = mean(ici),\n    brier = mean(brier),\n    nb_leaves = mean(nb_leaves),\n    auc = mean(AUC),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    mtry_lab = factor(str_c(\"mtry = \", mtry)),\n    mtry_lab = fct_reorder(mtry_lab, mtry)\n  ) |&gt; \n  mutate(\n    dgp = case_when(\n      scenario %in% 1:4 ~ 1,\n      scenario %in% 5:8 ~ 2,\n      scenario %in% 9:12 ~ 3,\n      scenario %in% 13:16 ~ 4\n    ),\n    dgp = factor(dgp, levels = 1:4, labels = str_c(\"DGP \", 1:4)),\n    no_noise = c(0, 10, 50, 100)[(scenario-1)%%4 + 1],\n    no_noise = factor(\n        no_noise, levels = c(no_noise),\n        labels = str_c(no_noise, \" noise variables\")\n      )\n  )\n\n\ndata_plot_max_auc &lt;- \n  data_plot |&gt; \n  filter(sample == \"Test\") |&gt; \n  group_by(sample, scenario) |&gt; # not by mtry here\n  mutate(is_max_auc = auc == max(auc)) |&gt; \n  ungroup() |&gt; \n  filter(is_max_auc == TRUE) |&gt; \n  select(sample, dgp, no_noise, scenario, brier, ici, KL_20_true_probas)\n\nformatter1000 &lt;- function(x) x*1000\n\n\n\nICIBrier\n\n\n\n\nCodes to create the figure\np_ici &lt;- ggplot(\n  data = data_plot |&gt; group_by(mtry) |&gt; arrange(nb_leaves),\n  mapping = aes(\n    x = ici, y = KL_20_true_probas\n  )\n) + \n  geom_path(\n    mapping = aes(colour = sample, linetype = mtry_lab),\n    arrow = arrow(type = \"closed\", ends = \"last\", \n                  length = unit(0.08, \"inches\"))\n  ) +\n  geom_vline(\n    data = data_plot_max_auc,\n    mapping = aes(xintercept = ici),\n    linetype = \"dashed\"\n  ) +\n  geom_hline(\n    data = data_plot_max_auc,\n    mapping = aes(yintercept = KL_20_true_probas),\n    linetype = \"dashed\"\n  ) +\n  # facet_grid(~mtry_lab) +\n  # ggh4x::facet_wrap2(~scenario, scales = \"free_y\") +\n  ggh4x::facet_grid2(dgp~no_noise, scales = \"free_y\", independent = \"y\") +\n  scale_colour_manual(\"Sample\", values = colour_samples) +\n  scale_linetype_discrete(\"Mtry\") +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\")) +\n  labs(\n    x = latex2exp::TeX(\"Calibration (ICI), $\\\\times 10^{3}$, log scale\"), \n    y = \"KL Divergence\"\n  ) +\n  scale_x_log10(labels = formatter1000) + scale_y_log10()\n\nggsave(p_ici, file = \"figures/rf-kl-calib-ici-leaves-all.pdf\",\n       width = 10, height = 8)\n\np_ici\n\n\n\n\n\nFigure 6.1: KL Divergence and Calibration (ICI) across increasing average number of leaves in the trees (log scales)\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the figure\np_brier &lt;- ggplot(\n  data = data_plot |&gt; group_by(mtry) |&gt; arrange(nb_leaves),\n  mapping = aes(\n    x = brier, y = KL_20_true_probas\n  )\n) + \n  geom_path(\n    mapping = aes(colour = sample, linetype = mtry_lab),\n    arrow = arrow(type = \"closed\", ends = \"last\", \n                  length = unit(0.08, \"inches\"))\n  ) +\n  geom_vline(\n    data = data_plot_max_auc,\n    mapping = aes(xintercept = brier),\n    linetype = \"dashed\"\n  ) +\n  geom_hline(\n    data = data_plot_max_auc,\n    mapping = aes(yintercept = KL_20_true_probas),\n    linetype = \"dashed\"\n  ) +\n  ggh4x::facet_grid2(dgp~no_noise, scales = \"free_y\", independent = \"y\") +\n  # facet_grid(dgp~no_noise) +\n  scale_colour_manual(\"Sample\", values = colour_samples) +\n  scale_linetype_discrete(\"Mtry\") +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\")) +\n  labs(\n    x = latex2exp::TeX(\"Calibration (ICI), $\\\\times 10^{3}$, log scale\"), \n    y = \"KL Divergence\"\n  ) +\n  scale_x_log10(labels = formatter1000) + scale_y_log10()\n\nggsave(p_brier, file = \"figures/rf-kl-calib-brier-leaves-all.pdf\",\n       width = 10, height = 8)\n\np_brier\n\n\n\n\n\nFigure 6.2: KL Divergence and Calibration (ICI) across increasing average number of leaves in the trees (log scales)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Random Forests</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests_ntrees.html",
    "href": "book_ojeda_forests_ntrees.html",
    "title": "7  Random Forests: number of trees",
    "section": "",
    "text": "7.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_valid = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Random Forests: number of trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests_ntrees.html#metrics",
    "href": "book_ojeda_forests_ntrees.html#metrics",
    "title": "7  Random Forests: number of trees",
    "section": "7.2 Metrics",
    "text": "7.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Random Forests: number of trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests_ntrees.html#simulations-setup",
    "href": "book_ojeda_forests_ntrees.html#simulations-setup",
    "title": "7  Random Forests: number of trees",
    "section": "7.3 Simulations Setup",
    "text": "7.3 Simulations Setup\nWe train different forests using the {ranger} package.\n\nlibrary(ranger)\n\nFor each of the 16 scenarios, we will train regression forests. We will consider the following hyperparameters:\n\nnum_trees: the number of trees in the forest: 1, 2, or 5 (was 250 in Chapter 6).\nmtry: Number of variables to possibly split at in each node: 2, 4 or 10.\nmin_node_size: Minimal node size to split at. Varying values between 2 and 10^{4}.\n\n\nmin_bucket_values &lt;- unique(round(2^seq(1, 14, by = .4)))\nmin_bucket_values &lt;- min_bucket_values[min_bucket_values &lt;=  max(params_df$size_train)]\n\ngrid &lt;- expand_grid(\n  mtry = c(2, 4, 10),\n  num_trees = c(1,2,5),\n  min_node_size = min_bucket_values\n) |&gt;\n  mutate(ind = row_number())\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100\n\nThe different configurations are reported in Table 7.1.\n\n\n\n\nTable 7.1: Grid Search Values\n\n\n\n\n\n\n\n\n\n\nWe define a function, simul_forest() to train a random forest on a dataset for a type of forest, with given hyperparameters (given to the function through the param argument).\n\n\nFunction simul_forest()\n#' Train a random forest and compute performance, calibration, and dispersion\n#' metrics\n#'\n#' @param params tibble with hyperparameters for the simulation\n#' @param ind index of the grid (numerical ID)\n#' @param simu_data simulated data obtained with `simulate_data_wrapper()`\n#'  for probability trees\nsimul_forest &lt;- function(params,\n                         ind,\n                         simu_data\n) {\n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_valid &lt;- simu_data$data$valid |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n\n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      valid = simu_data$data$probs_valid,\n      test = simu_data$data$probs_test\n    )\n\n  ## Estimation----\n  fit_rf &lt;- ranger(\n    d ~ .,\n    data = tb_train,\n    min.bucket = params$min_node_size,\n    mtry = params$mtry,\n    num.trees = params$num_trees\n  )\n\n  # Average number of leaves per trees in the forest\n  nb_leaves &lt;- map_dbl(fit_rf$forest$child.nodeIDs, ~sum(pluck(.x, 1) == 0)) |&gt;\n    mean()\n\n\n  ## Raw Scores----\n  # Predicted scores\n  scores_train &lt;- predict(fit_rf, data = tb_train, type = \"response\")$predictions\n  scores_valid &lt;- predict(fit_rf, data = tb_valid, type = \"response\")$predictions\n  scores_test &lt;- predict(fit_rf, data = tb_test, type = \"response\")$predictions\n\n  ## Histogram of scores----\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_valid_hist &lt;- hist(scores_valid, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    valid = scores_valid_hist,\n    test = scores_test_hist\n  )\n\n  ## Estimation of P(q1 &lt; score &lt; q2)----\n  proq_scores_train &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_valid &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_valid, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"valid\")\n  proq_scores_test &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n\n  ## Dispersion Metrics----\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n\n  disp_valid &lt;- dispersion_metrics(\n    true_probas = true_prob$valid, scores = scores_valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n\n  # Performance and Calibration Metrics\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n\n  scores_valid_noise &lt;- scores_valid +\n    runif(n = length(scores_valid), min = 0, max = 0.01)\n  scores_valid_noise[scores_valid_noise &gt; 1] &lt;- 1\n  metrics_valid &lt;- compute_metrics(\n    obs = tb_valid$d, scores = scores_valid_noise, true_probas = true_prob$valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n\n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_valid) |&gt;\n    bind_rows(metrics_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      min_bucket = params$min_node_size,\n      nb_leaves = nb_leaves,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  tb_prop_scores &lt;- proq_scores_train |&gt;\n    bind_rows(proq_scores_valid) |&gt;\n    bind_rows(proq_scores_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      min_bucket = params$min_node_size,\n      nb_leaves = nb_leaves,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  tb_disp_metrics &lt;- disp_train |&gt;\n    bind_rows(disp_valid) |&gt;\n    bind_rows(disp_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      min_bucket = params$min_node_size,\n      nb_leaves = nb_leaves,\n      prop_leaves = nb_leaves / nrow(tb_train)\n    )\n\n  list(\n    scenario = simu_data$scenario,     # data scenario\n    ind = ind,                         # index for grid\n    repn = simu_data$repn,             # data replication ID\n    min_bucket = params$min_node_size, # min number of obs in terminal leaf node\n    metrics = tb_metrics,              # table with performance/calib metrics\n    disp_metrics = tb_disp_metrics,    # table with divergence metrics\n    tb_prop_scores = tb_prop_scores,   # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist,         # histogram of scores\n    nb_leaves = nb_leaves              # number of terminal leaves\n  )\n}\n\n\nWe define a wrapper function, simulate_rf_scenario() which performs a single replication of the simulations going over the different values of the grid search, for a given scenario.\n\n\nFunction simulate_rf_scenario()\n#' Simulations for a scenario (single replication)\n#'\n#' @returns list with the following elements:\n#'  - `metrics_all`: computed metrics for each set of hyperparameters.\n#'    Each row gives the values for unique keys\n#'    (sample, min_bucket)\n#'  - `scores_hist`: histograms of scores computed on train, validation and test\n#'    sets\n#'  - `prop_scores_simul` P(q1 &lt; s(x) &lt; q2) for various values of q1 and q2\n#'    Each row gives the values for unique keys\n#'    (sample, min_bucket, q1, q2)\n#'    q1, q2, min_bucket, type, sample)\nsimulate_rf_scenario &lt;- function(scenario, params_df, repn) {\n  # Generate Data\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n\n  res_simul &lt;- vector(mode = \"list\", length = nrow(grid))\n  # cli::cli_progress_bar(\"Iteration grid\", total = nrow(grid), type = \"tasks\")\n  for (j in 1:nrow(grid)) {\n    curent_params &lt;- grid |&gt; slice(!!j)\n    n_var &lt;- simu_data$params_df$n_num + simu_data$params_df$add_categ * 5 +\n      simu_data$params_df$n_noise\n    if (curent_params$mtry &gt; n_var) {\n      # cli::cli_progress_update()\n      next()\n    }\n\n    res_simul[[j]] &lt;- simul_forest(\n      params = curent_params,\n      ind = curent_params$ind,\n      simu_data = simu_data\n    )\n    # cli::cli_progress_update()\n  }\n\n  metrics_simul &lt;- map(res_simul, \"metrics\") |&gt; list_rbind()\n  disp_metrics_simul &lt;- map(res_simul, \"disp_metrics\") |&gt; list_rbind()\n  metrics &lt;- suppressMessages(\n    left_join(metrics_simul, disp_metrics_simul)\n  )\n  scores_hist &lt;- map(res_simul, \"scores_hist\")\n  prop_scores_simul &lt;- map(res_simul, \"tb_prop_scores\") |&gt; list_rbind()\n\n  list(\n    metrics_all = metrics,\n    scores_hist = scores_hist,\n    prop_scores_simul = prop_scores_simul\n  )\n}",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Random Forests: number of trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests_ntrees.html#simulations",
    "href": "book_ojeda_forests_ntrees.html#simulations",
    "title": "7  Random Forests: number of trees",
    "section": "7.4 Simulations",
    "text": "7.4 Simulations\nWe loop over the scenarios and run the 100 replications in parallel.\n\n\nSimulation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(philentropy)\n  library(ranger)\n  library(ks)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl, c(\n    # Functions\n    \"brier_score\",\n    \"compute_metrics\",\n    \"dispersion_metrics\",\n    \"prop_btw_quantiles\",\n    \"subset_target\",\n    \"simulate_data\",\n    \"simulate_data_wrapper\",\n    \"simul_forest\",\n    \"simulate_rf_scenario\",\n    # Objects\n    \"grid\",\n    \"params_df\",\n    \"repns_vector\"\n  )\n)\n\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  clusterExport(cl, c(\"scenario\"))\n  resul_rf_scenario &lt;-\n    pblapply(\n      1:length(repns_vector), function(i) simulate_rf_scenario(\n        scenario = scenario, params_df = params_df, repn = repns_vector[i]\n      ),\n      cl = cl\n    )\n  save(\n    resul_rf_scenario,\n    file = str_c(\"output/simul/dgp-ojeda/resul_rf_ntrees_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results can be loaded as follows:\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_rf_ntrees_scenario_\", 1:16, \".rda\"\n)\nresul_rf &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_rf_scenario})",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Random Forests: number of trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_forests_ntrees.html#results",
    "href": "book_ojeda_forests_ntrees.html#results",
    "title": "7  Random Forests: number of trees",
    "section": "7.5 Results",
    "text": "7.5 Results\nWe can merge the metrics tables computed for each scenario and replications for these scenarios into a single tibble.\n\n\nCodes to get the metrics tables\nmetrics_rf_all &lt;- map(\n  resul_rf,\n  function(resul_rf_sc) map(resul_rf_sc, \"metrics_all\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"valid\", \"test\"),\n      labels = c(\"Train\", \"Validation\", \"Test\")\n    )\n  ) |&gt;\n  left_join(\n    grid |&gt; select(ind, mtry, min_node_size, num_trees),\n    by = \"ind\"\n  )\n\nrf_prop_scores_simul &lt;- map(\n  resul_rf,\n  function(resul_rf_sc) map(resul_rf_sc, \"prop_scores_simul\") |&gt; list_rbind()\n) |&gt;\n  list_rbind()\n\n\nFor each replication, for a value of the number of trees in the forest (i.e., the hyperparameters that vary are the min bucket size and mtry), let us identify trees of interest.\n\n\nCodes to identify trees of interest\n# Forest with the smallest average number of leaves per tree\nsmallest &lt;- metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, num_trees, repn) |&gt;\n  arrange(nb_leaves) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, num_trees, repn, ind) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Forest with the largest average number of leaves per tree\nlargest &lt;- metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, num_trees, repn) |&gt;\n  arrange(desc(nb_leaves)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, num_trees, repn, ind) |&gt;\n  mutate(result_type = \"largest\") |&gt;\n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc &lt;-  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, num_trees, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, num_trees, repn, ind) |&gt;\n  mutate(result_type = \"largest_auc\")\n\n# Identify tree with lowest MSE\nlowest_mse &lt;- metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, num_trees, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, num_trees, repn, ind) |&gt;\n  mutate(result_type = \"lowest_mse\")\n\n# Identify tree with lowest KL\nlowest_kl &lt;- metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, num_trees, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, num_trees, repn, ind) |&gt;\n  mutate(result_type = \"lowest_kl\")\n\nrf_of_interest &lt;-\n  smallest |&gt;\n  bind_rows(largest) |&gt;\n  bind_rows(highest_auc) |&gt;\n  bind_rows(lowest_mse) |&gt;\n  bind_rows(lowest_kl) |&gt;\n  # Add metrics\n  left_join(\n    metrics_rf_all,\n    by = c(\"scenario\", \"num_trees\", \"repn\", \"ind\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  ) |&gt;\n  left_join(\n    rf_prop_scores_simul\n  ) |&gt;\n  mutate(\n    result_type = factor(\n      result_type,\n      levels = c(\"largest_auc\", \"smallest\", \"largest\", \"lowest_mse\", \"lowest_kl\"),\n      labels = c(\"Max AUC\", \"Smallest\", \"Largest\", \"Min MSE\", \"Min KL\")\n    )\n  )\n\n\n\n7.5.1 Figures\n\n7.5.1.1 Distribution of Scores\nLet us plot the distributions of scores for the trees of interest (smallest, largest, max AUC, min MSE, min KL) for a single replication (the first replication) for each scenario.\n\n\nCodes to create the barplots\nget_bp &lt;- function(interest,\n                   scenario,\n                   repn,\n                   num_tree) {\n  # Identify the row number of the grid\n  rf_of_interest_plot &lt;-\n    rf_of_interest |&gt;\n    filter(\n      result_type == !!interest,\n      scenario == !!scenario,\n      repn == !!repn,\n      num_trees == !!num_tree,\n      sample == \"Test\"\n    )\n\n  ind_grid &lt;- rf_of_interest_plot |&gt;\n    pull(\"ind\")\n\n  # The corresponding boxplot data\n  data_bp &lt;-\n    map(resul_rf[[scenario]], \"scores_hist\")[[repn]] |&gt;\n    pluck(ind_grid)\n\n  subtitle &lt;- str_c(\n    \"No. Leaves = \", rf_of_interest_plot$nb_leaves, \", \",\n    \"AUC = \", round(rf_of_interest_plot$AUC, 2), \", \\n\",\n    \"ICI = \", round(rf_of_interest_plot$ici, 2), \", \",\n    \"KL = \", round(rf_of_interest_plot$KL_20_true_probas, 2)\n  )\n\n  plot(\n    main = interest,\n    data_bp$test,\n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .6)\n}\n\nplot_hist_scenario &lt;- function(scenario,\n                               repn,\n                               num_tree) {\n  par(mfrow = c(1,5))\n  # True probabilities\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn # only one replication here\n  )\n  true_prob &lt;- simu_data$data$probs_train\n  hist(\n    true_prob,\n    breaks = seq(0, 1, by = .05),\n    xlab = \"p\", ylab = \"\",\n    main = \"True Probabilities\",\n    xlim = c(0, 1)\n  )\n\n  for (interest in c(\"Smallest\", \"Largest\", \"Max AUC\", \"Min KL\")) {\n    get_bp(\n      interest = interest,\n      scenario = scenario,\n      repn = repn,\n      num_tree = num_tree\n    )\n  }\n}\n\n\nShowing plots for the first replication only:\n\nrepn &lt;- 1\n\n\nSingle TreeTwo TreesFive Trees\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nDistribution of true probabilities and estimated scores on test set for random forests of interest (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7.5.1.2 Metrics vs. Number of Leaves\n\n\nCodes to create the plots\nplot_metric_leaves &lt;- function(scenario_number) {\n  data_plot &lt;-\n    metrics_rf_all |&gt;\n    filter(scenario %in% scenario_number) |&gt;\n    group_by(\n      sample, scenario, ind, mtry, num_trees\n    ) |&gt;\n    summarise(\n      KL_20_true_probas = mean(KL_20_true_probas),\n      auc = mean(AUC),\n      ici = mean(ici),\n      nb_leaves = mean(nb_leaves),\n      .groups = \"drop\"\n    ) |&gt;\n    mutate(\n      mtry_lab = factor(str_c(\"mtry = \", mtry)),\n      mtry_lab = fct_reorder(mtry_lab, mtry),\n      num_trees_lab = factor(num_trees),\n      num_trees_lab = fct_reorder(num_trees_lab, num_trees),\n      scenario = str_c(\"Scenario \", scenario)\n    ) |&gt;\n    pivot_longer(cols = c(auc, ici, KL_20_true_probas), names_to = \"metric\") |&gt;\n    mutate(metric = factor(\n      metric,\n      levels = c(\"auc\", \"ici\", \"KL_20_true_probas\"),\n      labels = c(\"AUC\", \"ICI\", \"KL Divergence\")\n    ))\n\n\n  ggplot(\n    data = data_plot |&gt; group_by(num_trees_lab) |&gt; arrange(nb_leaves),\n    mapping = aes(x = nb_leaves, y = value)\n  ) +\n    geom_line(\n      mapping = aes(colour = sample, linetype = num_trees_lab, group = )) +\n    ggh4x::facet_grid2(mtry_lab~metric, scales = \"free_y\", independent = \"y\") +\n    scale_colour_manual(\"Sample\", values = colour_samples) +\n    scale_linetype_discrete(\"No. Trees\") +\n    theme_paper() +\n    labs(x = \"Average Number of leaves\", y = NULL)\n}\n\n\nLet us have a look at the evolution of the metrics depending on the average number of leaves in the estimated trees.\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\nMetrics as a function of the average number of leaves in the trees of the trained forests (DGP 4, 100 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Random Forests: number of trees</span>"
    ]
  },
  {
    "objectID": "book_ojeda_boosting.html",
    "href": "book_ojeda_boosting.html",
    "title": "8  Extreme Gradient Boosting",
    "section": "",
    "text": "8.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_valid = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Extreme Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "book_ojeda_boosting.html#metrics",
    "href": "book_ojeda_boosting.html#metrics",
    "title": "8  Extreme Gradient Boosting",
    "section": "8.2 Metrics",
    "text": "8.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Extreme Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "book_ojeda_boosting.html#simulations-setup",
    "href": "book_ojeda_boosting.html#simulations-setup",
    "title": "8  Extreme Gradient Boosting",
    "section": "8.3 Simulations Setup",
    "text": "8.3 Simulations Setup\nTo train the models, we rely on the {xgboost} R package.\n\nlibrary(xgboost)\n\n\nAttaching package: 'xgboost'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\n\nAs explained in the foreword of this page, we compute metrics based on scores obtained at various boosting iterations. To do so, we define a function, get_metrics_nb_iter(), that will be applied to a fitted model. This function will be called for all the boosting iterations (controlled by the nb_iter argument). The function returns a list with the following elements:\n\nscenario: the ID of the scenario\nind: the index of the grid search (so that we can join with the hyperparameters values, if needed)\nrepn: the ID of the replication\nnb_iter: the boosting iteration at which the metrics are computed\ntb_metrics: the tibble with the performance, calibration, and divergence metrics (one row for the train sample, one row for the validation sample, and one row for the test sample)\ntb_prop_scores: additional metrics (\\(\\mathbb{P}(q_1 &lt; \\hat{s}(\\mathbf{x}) &lt; q_2)\\) for multiple values for \\(q_1\\) and \\(q_2 = 1-q_1\\))\nscores_hist: elements to be able to plot an histogram of the scores on both the train set and the test set (using 20 equally-sized bins over \\([0,1]\\)).\n\n\n\nFunction get_metrics_nb_iter()\n#' Computes the performance and calibration metrics for an xgb model,\n#' depending on the number of iterations kept.\n#'\n#' @param nb_iter number of boosting iterations to keep\n#' @param params hyperparameters of the current model\n#' @param fitted_xgb xgb estimated model\n#' @param tb_train_xgb train data (in xgb.DMatrix format)\n#' @param tb_valid_xgb validation data (in xgb.DMatrix format)\n#' @param tb_test_xgb test data (in xgb.DMatrix format)\n#' @param simu_data simulated dataset\n#' @param true_prob list with true probabilities on train, validation and\n#'  test sets\nget_metrics_nb_iter &lt;- function(nb_iter,\n                                params,\n                                fitted_xgb,\n                                tb_train_xgb,\n                                tb_valid_xgb,\n                                tb_test_xgb,\n                                simu_data,\n                                true_prob) {\n\n  ind &lt;- params$ind\n  max_depth &lt;- params$max_depth\n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_valid &lt;- simu_data$data$valid |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n\n  # Predicted scores\n  scores_train &lt;- predict(fitted_xgb, tb_train_xgb, iterationrange = c(1, nb_iter))\n  scores_valid &lt;- predict(fitted_xgb, tb_valid_xgb, iterationrange = c(1, nb_iter))\n  scores_test &lt;- predict(fitted_xgb, tb_test_xgb, iterationrange = c(1, nb_iter))\n\n  ## Histogram of scores----\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_valid_hist &lt;- hist(scores_valid, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    valid = scores_valid_hist,\n    test = scores_test_hist,\n    scenario = simu_data$scenario,\n    ind = ind,\n    repn = simu_data$repn,\n    max_depth = params$max_depth,\n    nb_iter = nb_iter\n  )\n\n  ## Estimation of P(q1 &lt; score &lt; q2)----\n  proq_scores_train &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_valid &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_valid, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"valid\")\n  proq_scores_test &lt;- map(\n    c(.1, .2, .3, .4),\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n\n  ## Dispersion Metrics----\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n\n  disp_valid &lt;- dispersion_metrics(\n    true_probas = true_prob$valid, scores = scores_valid\n  ) |&gt;mutate(sample = \"valid\")\n\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n\n  # Performance and Calibration Metrics\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n\n  scores_valid_noise &lt;- scores_valid +\n    runif(n = length(scores_valid), min = 0, max = 0.01)\n  scores_valid_noise[scores_valid_noise &gt; 1] &lt;- 1\n  metrics_valid &lt;- compute_metrics(\n    obs = tb_valid$d, scores = scores_valid_noise, true_probas = true_prob$valid\n  ) |&gt; mutate(sample = \"valid\")\n\n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n\n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_valid) |&gt;\n    bind_rows(metrics_test) |&gt;\n    left_join(\n      disp_train |&gt;\n        bind_rows(disp_valid) |&gt; \n        bind_rows(disp_test),\n      by = \"sample\"\n    ) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      max_depth = params$max_depth,\n      # type = !!type,\n      nb_iter = nb_iter\n    )\n\n  tb_prop_scores &lt;- proq_scores_train |&gt;\n    bind_rows(proq_scores_valid) |&gt;\n    bind_rows(proq_scores_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      ind = ind,\n      repn = simu_data$repn,\n      max_depth = params$max_depth,\n      nb_iter = nb_iter\n    )\n\n  list(\n    scenario = simu_data$scenario,     # data scenario\n    ind = ind,                         # index for grid\n    repn = simu_data$repn,             # data replication ID\n    nb_iter = nb_iter,                 # number of boosting iterations\n    tb_metrics = tb_metrics,           # table with performance/calib/divergence\n                                       #  metrics\n    tb_prop_scores = tb_prop_scores,   # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist          # histogram of scores\n  )\n}\n\n\nWe define another function, simul_xgb() which trains an extreme gradient boosting model for a single replication. It calls the get_metrics_nb_iter() on each of the boosting iterations of the model from the second to the last (400th), and returns a list of length 400-1 where each element is a list returned by the get_metrics_nb_iter().\n\n\nFunction simul_xgb()\n#' Train an xgboost model and compute performance, calibration, and dispersion\n#' metrics\n#'\n#' @param params tibble with hyperparameters for the simulation\n#' @param ind index of the grid (numerical ID)\n#' @param simu_data simulated data obtained with `simulate_data_wrapper()`\nsimul_xgb &lt;- function(params,\n                      ind,\n                      simu_data) {\n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_valid &lt;- simu_data$data$valid |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      valid = simu_data$data$probs_valid,\n      test = simu_data$data$probs_test\n    )\n\n  ## Format data for xgboost----\n  tb_train_xgb &lt;- xgb.DMatrix(\n    data = model.matrix(d ~ -1 + ., tb_train), label = tb_train$d\n  )\n  tb_valid_xgb &lt;- xgb.DMatrix(\n    data = model.matrix(d ~ -1 + ., tb_valid), label = tb_valid$d\n  )\n  tb_test_xgb &lt;- xgb.DMatrix(\n    data = model.matrix(d ~ -1 + ., tb_test), label = tb_test$d\n  )\n  # Parameters for the algorithm\n  param &lt;- list(\n    max_depth = params$max_depth, #Note: root node is indexed 0\n    eta = params$eta,\n    nthread = 1,\n    objective = \"binary:logistic\",\n    eval_metric = \"auc\"\n  )\n  watchlist &lt;- list(train = tb_train_xgb, eval = tb_valid_xgb)\n\n  ## Estimation----\n  xgb_fit &lt;- xgb.train(\n    param, tb_train_xgb,\n    nrounds = params$nb_iter_total,\n    watchlist,\n    verbose = 0\n  )\n\n  # Number of leaves\n  # dt_tree &lt;- xgb.model.dt.tree(model = xgb_fit)\n  # path_depths &lt;- xgboost:::get.leaf.depth(dt_tree)\n  # path_depths |&gt; count(Tree) |&gt; select(n) |&gt; table()\n\n  # Then, for each boosting iteration number up to params$nb_iter_total\n  # compute the predicted scores and evaluate the metrics\n  resul &lt;- map(\n    seq(2, params$nb_iter_total),\n    ~get_metrics_nb_iter(\n      nb_iter = .x,\n      params = params,\n      fitted_xgb = xgb_fit,\n      tb_train_xgb = tb_train_xgb,\n      tb_valid_xgb = tb_valid_xgb,\n      tb_test_xgb = tb_test_xgb,\n      simu_data = simu_data,\n      true_prob = true_prob\n    ),\n  )\n  resul\n}\n\nsimulate_xgb_scenario &lt;- function(scenario, params_df, repn) {\n  # Generate Data\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n\n  # Looping over the grid hyperparameters for the scenario\n  res_simul &lt;- vector(mode = \"list\", length = nrow(grid))\n  cli::cli_progress_bar(\"Iteration grid\", total = nrow(grid), type = \"tasks\")\n  for (j in 1:nrow(grid)) {\n    curent_params &lt;- grid |&gt; dplyr::slice(!!j)\n    res_simul[[j]] &lt;- simul_xgb(\n      params = curent_params,\n      ind = curent_params$ind,\n      simu_data = simu_data\n    )\n    cli::cli_progress_update()\n  }\n\n\n  # The metrics computed for all set of hyperparameters (identified with `ind`)\n  # and for each number of boosting iterations (`nb_iter`), for the current\n  # scenario (`scenario`) and current replication number (`repn`)\n  metrics_simul &lt;- map(\n    res_simul,\n    function(simul_grid_j) map(simul_grid_j, \"tb_metrics\") |&gt; list_rbind()\n  ) |&gt;\n    list_rbind()\n\n  # Sanity check\n  # metrics_simul |&gt; count(scenario, repn, ind, sample, nb_iter) |&gt;\n  #   filter(n &gt; 1)\n\n  # P(q_1&lt;s(x)&lt;q_2)\n  prop_scores_simul &lt;- map(\n    res_simul,\n    function(simul_grid_j) map(simul_grid_j, \"tb_prop_scores\") |&gt; list_rbind()\n  ) |&gt;\n    list_rbind()\n\n  # Sanity check\n  # prop_scores_simul |&gt; count(scenario, repn, ind, sample, nb_iter)\n\n  # Histogram of estimated scores\n  scores_hist &lt;- map(\n    res_simul,\n    function(simul_grid_j) map(simul_grid_j, \"scores_hist\")\n  )\n\n  list(\n    metrics_simul = metrics_simul,\n    scores_hist = scores_hist,\n    prop_scores_simul = prop_scores_simul\n  )\n}\n\n\n\n8.3.1 Grid\nWe consider the following grid:\n\ngrid &lt;- expand_grid(\n  max_depth = c(2, 4, 6),\n  nb_iter_total = 400,\n  eta = 0.3\n) |&gt;\n  mutate(ind = row_number())\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100\n\nThe different configurations are reported in Table 8.1.\n\nDT::datatable(grid)\n\n\n\nTable 8.1: Grid Search Values\n\n\n\n\n\n\n\n\n\n\nWe define a function, simulate_xgb_scenario() to train the model on a dataset for all different values of the hyperparameters of the grid. This function performs a single replication of the simulations for a single scenario.\n\n\nFunction simulate_xgb_scenario()\nsimulate_xgb_scenario &lt;- function(scenario, params_df, repn) {\n  # Generate Data\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n\n  # Looping over the grid hyperparameters for the scenario\n  res_simul &lt;- vector(mode = \"list\", length = nrow(grid))\n  cli::cli_progress_bar(\"Iteration grid\", total = nrow(grid), type = \"tasks\")\n  for (j in 1:nrow(grid)) {\n    curent_params &lt;- grid |&gt; dplyr::slice(!!j)\n    res_simul[[j]] &lt;- simul_xgb(\n      params = curent_params,\n      ind = curent_params$ind,\n      simu_data = simu_data\n    )\n    cli::cli_progress_update()\n  }\n\n\n  # The metrics computed for all set of hyperparameters (identified with `ind`)\n  # and for each number of boosting iterations (`nb_iter`), for the current\n  # scenario (`scenario`) and current replication number (`repn`)\n  metrics_simul &lt;- map(\n    res_simul,\n    function(simul_grid_j) map(simul_grid_j, \"tb_metrics\") |&gt; list_rbind()\n  ) |&gt;\n    list_rbind()\n\n  # Sanity check\n  # metrics_simul |&gt; count(scenario, repn, ind, sample, nb_iter) |&gt;\n  #   filter(n &gt; 1)\n\n  # P(q_1&lt;s(x)&lt;q_2)\n  prop_scores_simul &lt;- map(\n    res_simul,\n    function(simul_grid_j) map(simul_grid_j, \"tb_prop_scores\") |&gt; list_rbind()\n  ) |&gt;\n    list_rbind()\n\n  # Sanity check\n  # prop_scores_simul |&gt; count(scenario, repn, ind, sample, nb_iter)\n\n  # Histogram of estimated scores\n  scores_hist &lt;- map(\n    res_simul,\n    function(simul_grid_j) map(simul_grid_j, \"scores_hist\")\n  )\n\n  list(\n    metrics_simul = metrics_simul,\n    scores_hist = scores_hist,\n    prop_scores_simul = prop_scores_simul\n  )\n}",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Extreme Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "book_ojeda_boosting.html#estimations",
    "href": "book_ojeda_boosting.html#estimations",
    "title": "8  Extreme Gradient Boosting",
    "section": "8.4 Estimations",
    "text": "8.4 Estimations\nWe loop over the 16 scenarios and run the 100 replications in parallel.\n\n\nEstimation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(locfit)\n  library(philentropy)\n  library(xgboost)\n  library(ks)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl, c(\n    # Functions\n    \"brier_score\",\n    \"compute_metrics\",\n    \"dispersion_metrics\",\n    \"prop_btw_quantiles\",\n    \"subset_target\",\n    \"simulate_data\",\n    \"simulate_data_wrapper\",\n    \"simul_xgb\",\n    \"simulate_xgb_scenario\",\n    \"get_metrics_nb_iter\",\n    # Objects\n    \"grid\",\n    \"params_df\",\n    \"repns_vector\"\n  )\n)\n\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  clusterExport(cl, c(\"scenario\"))\n  resul_xgb_scenario &lt;-\n    pblapply(\n      1:length(repns_vector), function(i) simulate_xgb_scenario(\n        scenario = scenario, params_df = params_df, repn = repns_vector[i]\n      ),\n      cl = cl\n    )\n  save(\n    resul_xgb_scenario,\n    file = str_c(\"output/simul/dgp-ojeda/resul_xgb_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results can be loaded as follows:\n\nscenarios &lt;- 1:16\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_xgb_scenario_\", scenarios, \".rda\"\n)\nresul_xgb &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_xgb_scenario})\n\nThe resul_rf object is of length 16: each element contains the simulations for a scenario. For each scenario, the elements are a list of length max(repns_vector), i.e., the number of replications. Each replication gives, in a list, the following elements:\n\nmetrics_simul: the metrics (AUC, Calibration, KL Divergence, etc.) for each model from the grid search, for all boosting iterations\nscores_hist: the counts on bins defined on estimated scores (on train, validation, and test sets)\nprop_scores_simul: the estimations of \\(\\mathbb{P}(q_1 &lt; \\hat{\\mathbf{x}}&lt; q_2)\\) for various values of q_1 and q_2.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Extreme Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "book_ojeda_boosting.html#results",
    "href": "book_ojeda_boosting.html#results",
    "title": "8  Extreme Gradient Boosting",
    "section": "8.5 Results",
    "text": "8.5 Results\nWe can now extract some information from the results.\nWe first aggregate all the computed metrics performance/calibration/divergence in a single tibble, metrics_xgb_all.\n\n\nCodes to create the metrics table\nmetrics_xgb_all &lt;- map(\n  resul_xgb,\n  function(resul_xgb_sc) map(resul_xgb_sc, \"metrics_simul\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"valid\", \"test\"),\n      labels = c(\"Train\",\"Validation\" ,\"Test\")\n    )\n  )\n\n# Sanity check\n# metrics_xgb_all |&gt; count(scenario, ind, sample, nb_iter) |&gt;\n#   filter(n != max(repns_vector))\n\n\nFor each replication, we made some hyperparameters vary. Let us identify some models of interest:\n\nsmallest: model with the lowest number of boosting iteration\nlargest: model with the highest number of boosting iteration\nlargest_auc: model with the highest AUC on validation set\nlowest_mse: model with the lowest MSE on validation set\nlowest_ici: model with the lowest ICI on validation set\nlowest_kl: model with the lowest KL Divergence on validation set\n\n\n\nCode\n# Identify the model with the smallest number of boosting iterations\nsmallest_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(nb_iter) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Identify the largest tree\nlargest_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(nb_iter)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"largest\") |&gt;\n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"largest_auc\") |&gt;\n  ungroup()\n\n# Identify tree with lowest MSE\nlowest_mse_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_mse\") |&gt;\n  ungroup()\n\n# Identify tree with lowest brier\nlowest_brier_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(brier) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_brier\") |&gt;\n  ungroup()\n\n# Identify tree with lowest ICI\nlowest_ici_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(ici) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_ici\") |&gt;\n  ungroup()\n\n# Identify tree with lowest KL\nlowest_kl_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_kl\") |&gt;\n  ungroup()\n\n# Merge these\nmodels_of_interest_xgb &lt;-\n  smallest_xgb |&gt;\n  bind_rows(largest_xgb) |&gt;\n  bind_rows(highest_auc_xgb) |&gt;\n  bind_rows(lowest_mse_xgb) |&gt;\n  bind_rows(lowest_brier_xgb) |&gt;\n  bind_rows(lowest_ici_xgb) |&gt;\n  bind_rows(lowest_kl_xgb)\n\n# Add metrics now\nmodels_of_interest_metrics &lt;-\n  models_of_interest_xgb |&gt;\n  left_join(\n    metrics_xgb_all,\n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_iter\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  )\n\n# Sanity check\n# models_of_interest_metrics |&gt; count(scenario, sample, result_type)\n\n\n\n8.5.1 Metrics vs Number of Iterations\nWe define a function, plot_metrics() to plot selected metrics (AUC, ICI, and KL Divergence) as a function of the number of boosting iterations. Each curve corresponds to a value of the maximal depth hyperparameter.\n\n\nFunction plot_metrics()\nplot_metrics &lt;- function(dgp) {\n  df_plot &lt;-\n    metrics_xgb_all |&gt;\n    mutate(\n      dgp = case_when(\n        scenario %in% 1:4 ~ 1,\n        scenario %in% 5:8 ~ 2,\n        scenario %in% 9:12 ~ 3,\n        scenario %in% 13:16 ~ 4\n      ),\n      no_noise = c(0, 10, 50, 100)[(scenario-1)%%4 + 1],\n      no_noise = factor(\n        no_noise,\n        levels = c(no_noise),\n        labels = str_c(no_noise, \" noise variables\")\n      )\n    ) |&gt;\n    filter(dgp == !!dgp) |&gt;\n    select(\n      dgp, no_noise, scenario, ind, sample, nb_iter, max_depth,\n      AUC, brier, ici, KL_20_true_probas\n    ) |&gt;\n    pivot_longer(\n      cols = -c(dgp, no_noise, scenario, ind, sample, nb_iter, max_depth),\n      names_to = \"metric\", values_to = \"value\"\n    ) |&gt;\n    group_by(\n      dgp, no_noise, scenario, ind, sample, nb_iter, max_depth, metric\n    ) |&gt;\n    summarise(\n      value_lower = quantile(value, probs = 2.5/100),\n      value_upper = quantile(value, probs = 97.5/100),\n      value = mean(value)\n    ) |&gt;\n    mutate(\n      max_depth = factor(max_depth),\n      metric = factor(\n        metric,\n        levels = c(\"AUC\", \"brier\", \"ici\", \"KL_20_true_probas\"),\n        labels = c(\"AUC\", \"brier\", \"ICI\", \"KL Divergence\")\n      )\n    ) |&gt;\n    filter(max_depth %in% c(2,4,6))\n\n  ggplot(\n    data = df_plot,\n    mapping = aes(x = nb_iter, y = value)\n  ) +\n    geom_ribbon(\n      mapping = aes(\n        ymin = value_lower, ymax = value_upper,\n        fill = sample\n      ),\n      alpha = .1\n    ) +\n    geom_line(mapping = aes(colour = sample, linetype = max_depth)) +\n    geom_text_repel(\n      data = df_plot |&gt; filter(nb_iter == 380),\n      mapping = aes(\n        x = nb_iter, y = value, label = max_depth, colour = sample\n      ),\n      size = 4, # font size in the text labels\n      point.padding = 0, # additional padding around each point\n      min.segment.length = 0, # draw all line segments\n      max.time = 1, max.iter = 1e5, # stop after 1 second, or after 100,000 iterations\n      box.padding = .3, # additional padding around each text label\n      segment.size = .25 # line segment thickness\n    ) +\n    ggh4x::facet_grid2(metric~no_noise, scales = \"free_y\", independent = \"y\") +\n    labs(\n      x = \"Boosting Iterations\", y = NULL\n    ) +\n    scale_colour_manual(\n      \"Sample\", values = colour_samples,\n      guide = guide_legend(\n        override.aes = list(label = \"\")\n      )\n    ) +\n    scale_linetype_discrete(\"Max Depth\") +\n    scale_fill_manual(\"Sample\", values = colour_samples) +\n    theme_paper()\n}\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n\nCode\nplot_metrics(1)\n\n\n\n\n\nFigure 8.1: Metrics for DGP 1\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_metrics(2)\n\n\n\n\n\nFigure 8.2: Metrics for DGP 2\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_metrics(3)\n\n\n\n\n\nFigure 8.3: Metrics for DGP 3\n\n\n\n\n\n\n\n\n\n\n\n\nCode\nplot_metrics(4)\n\n\n\n\n\nFigure 8.4: Metrics for DGP 4\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.2 Distribution of Scores\nLet us extract all the histogram information computed over the simulations and put that in a single object, scores_hist_all.\n\nscores_hist_all &lt;-\n  map(\n    resul_xgb,\n    function(resul_xgb_sc) map(resul_xgb_sc, \"scores_hist\")\n  )\n\nWe then define a function, plot_bp_xgb() which plots the distribution of scores on the test set for a single replication (repn), for a scenario, (scenario), and a given maximal tree depth (max_depth). We also define a helper function, plot_bp_interest(), which plots the histogram of the scores at a specific iteration number. We will then be able to plot the distributions at the beginning of the boosting iterations, at the end, at a point where the AUC was the highest on the validation set, and at a point where the KL divergence between the distribution of scores on the validation set and the distribution of the true probabilities was the lowest.\n\n\nCode to create the barplots\nplot_bp_interest &lt;- function(metrics_interest, scores_hist_interest, label) {\n  subtitle &lt;- str_c(\n    \"Depth = \", metrics_interest$max_depth, \", \",\n    \"MSE = \", round(metrics_interest$mse, 2), \", \",\n    \"AUC = \", round(metrics_interest$AUC, 2), \", \\n\",\n    \"Brier = \", round(metrics_interest$brier, 2), \",\",\n    \"ICI = \", round(metrics_interest$ici, 2), \", \",\n    \"KL = \", round(metrics_interest$KL_20_true_probas, 2)\n  )\n  \n  plot(\n    main = str_c(label, \" (iter = \", metrics_interest$nb_iter,\")\"),\n    scores_hist_interest$test,\n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .5)\n}\n\nplot_bp_xgb &lt;- function(scenario, repn, max_depth) {\n  # Focus on current scenario\n  scores_hist_scenario &lt;- scores_hist_all[[scenario]]\n  # Focus on a particular replication\n  scores_hist_repn &lt;- scores_hist_scenario[[repn]]\n  # Focus on a value for max_depth\n  max_depth_val &lt;- map_dbl(scores_hist_repn, ~.x[[1]]$max_depth)\n  i_max_depth &lt;- which(max_depth_val == max_depth)\n  scores_hist &lt;- scores_hist_repn[[i_max_depth]]\n  \n  # The metrics for the corresponding simulations, on the validation set\n  metrics_xgb_current_valid &lt;-\n    metrics_xgb_all |&gt;\n    filter(\n      scenario == !!scenario,\n      repn == !!repn,\n      max_depth == !!max_depth,\n      sample == \"Validation\"\n    )\n  # and on the test set\n  metrics_xgb_current_test &lt;-\n    metrics_xgb_all |&gt;\n    filter(\n      scenario == !!scenario,\n      repn == !!repn,\n      max_depth == !!max_depth,\n      sample == \"Test\"\n    )\n  \n  # True Probabilities\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn # only one replication here\n  )\n  true_prob &lt;- simu_data$data$probs_train\n  hist(\n    true_prob,\n    breaks = seq(0, 1, by = .05),\n    xlab = \"p\", ylab = \"\",\n    main = \"True Probabilities\",\n    xlim = c(0, 1)\n  )\n  mtext(\n    side = 2, str_c(\"Max Depth = \", max_depth), line = 2.5, cex = 1,\n    font.lab = 2\n  )\n  \n  # Iterations of interest----\n  ## Start of iterations\n  scores_hist_start &lt;- scores_hist[[1]]\n  metrics_start &lt;- metrics_xgb_current_test |&gt;\n    filter(nb_iter == scores_hist_start$nb_iter)\n  plot_bp_interest(\n    metrics_interest = metrics_start,\n    scores_hist_interest = scores_hist_start,\n    label = \"Start\"\n  )\n  \n  ## End of iterations\n  scores_hist_end &lt;- scores_hist[[length(scores_hist)]]\n  metrics_end &lt;- metrics_xgb_current_test |&gt;\n    filter(nb_iter == scores_hist_end$nb_iter)\n  plot_bp_interest(\n    metrics_interest = metrics_end,\n    scores_hist_interest = scores_hist_end,\n    label = \"End\"\n  )\n  \n  ## Iteration with min MSE on validation set\n  nb_iter_mse &lt;-\n    metrics_xgb_current_valid |&gt; arrange(mse) |&gt;\n    dplyr::slice(1) |&gt; \n    pull(\"nb_iter\")\n  # Metrics at the same iteration on the test set\n  metrics_min_mse &lt;- \n    metrics_xgb_current_test |&gt; filter(nb_iter == !!nb_iter_mse)\n  # Note: indexing at 0 here...\n  ind_mse &lt;- which(map_dbl(scores_hist, \"nb_iter\") == nb_iter_mse)\n  scores_hist_min_mse &lt;- scores_hist[[ind_mse]]\n  plot_bp_interest(\n    metrics_interest = metrics_min_mse,\n    scores_hist_interest = scores_hist_min_mse,\n    label = \"MSE*\"\n  )\n  \n  ## Iteration with max AUC on validation set\n  nb_iter_auc &lt;-\n    metrics_xgb_current_valid |&gt; arrange(desc(AUC)) |&gt;\n    dplyr::slice(1) |&gt; \n    pull(\"nb_iter\")\n  metrics_max_auc &lt;- \n    metrics_xgb_current_test |&gt; filter(nb_iter == !!nb_iter_auc)\n  # Note: indexing at 0 here...\n  ind_auc &lt;- which(map_dbl(scores_hist, \"nb_iter\") == nb_iter_auc)\n  scores_hist_max_auc &lt;- scores_hist[[ind_auc]]\n  plot_bp_interest(\n    metrics_interest = metrics_max_auc,\n    scores_hist_interest = scores_hist_max_auc,\n    label = \"AUC*\"\n  )\n  mtext(\n    side = 2, str_c(\"Max Depth = \", max_depth), line = 2.5, cex = 1,\n    font.lab = 2\n  )\n  \n  ## Min Brier on validation set\n  nb_iter_brier &lt;-\n    metrics_xgb_current_valid |&gt; arrange(brier) |&gt;\n    dplyr::slice(1) |&gt; \n    pull(\"nb_iter\")\n  metrics_min_brier &lt;-\n    metrics_xgb_current_test |&gt; filter(nb_iter == !!nb_iter_brier)\n  ind_brier &lt;- which(map_dbl(scores_hist, \"nb_iter\") == nb_iter_brier)\n  scores_hist_min_brier &lt;- scores_hist[[ind_brier]]\n  plot_bp_interest(\n    metrics_interest = metrics_min_brier,\n    scores_hist_interest = scores_hist_min_brier,\n    label = \"Brier*\"\n  )\n  \n  ## Min ICI on validation set\n  nb_iter_ici &lt;-\n    metrics_xgb_current_valid |&gt; arrange(ici) |&gt;\n    dplyr::slice(1) |&gt; \n    pull(\"nb_iter\")\n  metrics_min_ici &lt;-\n    metrics_xgb_current_test |&gt; filter(nb_iter == !!nb_iter_ici)\n  ind_ici &lt;- which(map_dbl(scores_hist, \"nb_iter\") == nb_iter_ici)\n  scores_hist_min_ici &lt;- scores_hist[[ind_ici]]\n  plot_bp_interest(\n    metrics_interest = metrics_min_ici,\n    scores_hist_interest = scores_hist_min_ici,\n    label = \"ICI*\"\n  )\n  \n  ## Min KL on validation set\n  nb_iter_kl &lt;-\n    metrics_xgb_current_valid |&gt; arrange(KL_20_true_probas) |&gt;\n    dplyr::slice(1) |&gt; \n    pull(\"nb_iter\")\n  metrics_min_kl &lt;-\n    metrics_xgb_current_test |&gt; filter(nb_iter == !!nb_iter_kl)\n  ind_kl &lt;- which(map_dbl(scores_hist, \"nb_iter\") == nb_iter_kl)\n  scores_hist_min_kl &lt;- scores_hist[[ind_kl]]\n  plot_bp_interest(\n    metrics_interest = metrics_min_kl,\n    scores_hist_interest = scores_hist_min_kl,\n    label = \"KL*\"\n  )\n}\n\n\nLet us plot the distributions for the first replication of the simulations of each scenario.\n\nrepn &lt;- 1\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 1.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 2.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 3.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 4.\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 5.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 6.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 7.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 8.\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 9.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 10.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 11.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 12.\n\n\n\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 13.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 14.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 15.\n\n\n\n\n\n\n\n\n\n\n\nDistribution of scores on the test set for Scenario 16.\n\n\n\n\n\n\n\n\n\n\n\n\n\n8.5.3 KL Divergence and Calibration along Boosting Iterations\nWe can examine the evolution of the relationship between the divergence of score distributions from true probabilities and model calibration across increasing boosting iterations.\n\n\nCodes to create the figure\ndf_plot &lt;- \n  metrics_xgb_all |&gt; \n  mutate(\n    dgp = case_when(\n      scenario %in% 1:4 ~ 1,\n      scenario %in% 5:8 ~ 2,\n      scenario %in% 9:12 ~ 3,\n      scenario %in% 13:16 ~ 4\n    ),\n    dgp = factor(dgp, levels = 1:4, labels = str_c(\"DGP \", 1:4)),\n    no_noise = c(0, 10, 50, 100)[(scenario-1)%%4 + 1],\n    no_noise = factor(\n        no_noise, levels = c(no_noise),\n        labels = str_c(no_noise, \" noise variables\")\n      )\n  ) |&gt; \n  select(\n    dgp, no_noise, scenario, ind, sample, nb_iter, max_depth, \n    brier, ici, KL_20_true_probas\n  ) |&gt; \n  group_by(dgp, no_noise, scenario, ind, sample, nb_iter, max_depth) |&gt; \n  summarise(\n    brier = mean(brier),\n    ici = mean(ici),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    max_depth = factor(\n      max_depth, \n      levels = c(2, 4, 6)\n    )\n  )\n\nformatter1000 &lt;- function(x) x*1000\n\n\n\nBrierICI\n\n\n\n\nCodes to create the figure\np_brier &lt;- ggplot(\n  data = df_plot |&gt; arrange(nb_iter),\n  mapping = aes(x = brier, y = KL_20_true_probas)\n) +\n  geom_path(\n    mapping = aes(colour = sample, linetype = max_depth), \n    arrow = arrow(type = \"closed\", ends = \"last\", \n                  length = unit(0.08, \"inches\"))\n  ) +\n  # facet_wrap(~scenario) +\n    ggh4x::facet_grid2(dgp~no_noise, scales = \"free_y\", independent = \"y\") +\n  labs(\n    x = latex2exp::TeX(\"Calibration (Brier), $\\\\times 10^{3}$, log scale\"), \n    y = \"KL Divergence\"\n  ) +\n  scale_x_log10(labels = formatter1000) + scale_y_log10() +\n  scale_colour_manual(\"Sample\", values = colour_samples) +\n  scale_linetype_discrete(\"Max Depth\") +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\"))\n\n\nggsave(p_brier, file = \"figures/xgb-kl-calib-brier-leaves-all.pdf\",\n       width = 10, height = 8)\n\np_brier\n\n\n\n\n\nFigure 8.5: KL Divergence and Calibration (Brier) across increasing boosting iterations (log scales)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the figure\np_ici &lt;- ggplot(\n  data = df_plot |&gt; arrange(nb_iter),\n  mapping = aes(x = ici, y = KL_20_true_probas)\n) +\n  geom_path(\n    mapping = aes(colour = sample, linetype = max_depth), \n    arrow = arrow(type = \"closed\", ends = \"last\", \n                  length = unit(0.08, \"inches\"))\n  ) +\n  # facet_wrap(~scenario) +\n    ggh4x::facet_grid2(dgp~no_noise, scales = \"free_y\", independent = \"y\") +\n  labs(\n    x = latex2exp::TeX(\"Calibration (ICI), $\\\\times 10^{3}$, log scale\"), \n    y = \"KL Divergence\"\n  ) +\n  scale_x_log10(labels = formatter1000) + scale_y_log10() +\n  scale_colour_manual(\"Sample\", values = colour_samples) +\n  scale_linetype_discrete(\"Max Depth\") +\n  theme_paper() +\n  theme(legend.key.width = unit(1.5, \"cm\"))\n\n\nggsave(p_ici, file = \"figures/xgb-kl-calib-ici-leaves-all.pdf\",\n       width = 10, height = 8)\n\np_ici\n\n\n\n\n\nFigure 8.6: KL Divergence and Calibration (ICI) across increasing boosting iterations (log scales)\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Extreme Gradient Boosting</span>"
    ]
  },
  {
    "objectID": "book_ojeda_glm.html",
    "href": "book_ojeda_glm.html",
    "title": "9  Generalized Linear Models",
    "section": "",
    "text": "9.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_glm.html#metrics",
    "href": "book_ojeda_glm.html#metrics",
    "title": "9  Generalized Linear Models",
    "section": "9.2 Metrics",
    "text": "9.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_glm.html#simulations-setup",
    "href": "book_ojeda_glm.html#simulations-setup",
    "title": "9  Generalized Linear Models",
    "section": "9.3 Simulations Setup",
    "text": "9.3 Simulations Setup\nAs in previous chapters, we define a function to run replications of the simulations for each scenario. This function is called simul_glm(). It uses multiple helper functions also defined here.\n\n\nHelper Functions\n#' Counts the number of scores in each of the 20 equal-sized bins over [0,1]\n#'\n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\nget_histogram &lt;- function(scores_train, scores_test) {\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    test = scores_test_hist\n  )\n  scores_hist\n}\n\n#' Get KL divergence metrics for estimated scores and true probabilities\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param true_prob list of true probabilities on train and test set\nget_disp_metrics &lt;- function(scores_train, scores_test, true_prob) {\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n  \n  tb_disp_metrics &lt;- disp_train |&gt;\n    bind_rows(disp_test)\n  tb_disp_metrics\n}\n\n#' Get the performance and calibration metrics for estimated scores\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param tb_train train set\n#' @param tb_test test set\n#' @param true_prob list of true probabilities on train and test set\nget_perf_metrics &lt;- function(scores_train, \n                             scores_test,\n                             tb_train,\n                             tb_test,\n                             true_prob) {\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n  \n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n  \n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_test)\n  tb_metrics\n}\n\n#' Estimation of P(q1 &lt; score &lt; q2)\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param q1 vector of desired values for q1 (q2 = 1-q1)\nestim_prop &lt;- function(scores_train, \n                       scores_test, \n                       q1 = c(.1, .2, .3, .4)) {\n  proq_scores_train &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_test &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n  \n  proq_scores_train |&gt; \n    bind_rows(proq_scores_test)\n}\n\n\n\n\nThe simul_glm() function\nsimul_glm &lt;- function(scenario, params_df, repn) {\n  # Generate Data----\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n  \n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n  \n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      test = simu_data$data$probs_test\n    )\n  \n  # Estimation----\n  estim_logit &lt;- glm(d ~ ., data = tb_train, family = \"binomial\")\n  \n  # Predicted scores----\n  scores_train &lt;- predict(estim_logit, newdata = tb_train, type = \"response\")\n  scores_test &lt;- predict(estim_logit, newdata = tb_test, type = \"response\")\n  \n  # Histogram of scores----\n  scores_hist &lt;- get_histogram(scores_train, scores_test)\n  \n  # Performance and Calibration Metrics----\n  tb_metrics &lt;- get_perf_metrics(\n    scores_train = scores_train, \n    scores_test = scores_test, \n    tb_train = tb_train, \n    tb_test = tb_test, \n    true_prob = true_prob) |&gt; \n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n  \n  # Dispersion Metrics----\n  tb_disp_metrics &lt;- get_disp_metrics(\n    scores_train = scores_train, \n    scores_test = scores_test,\n    true_prob = true_prob\n  ) |&gt; \n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n  \n  metrics &lt;- suppressMessages(\n    left_join(tb_metrics, tb_disp_metrics)\n  )\n  \n  # Estimation of P(q1 &lt; score &lt; q2)----\n  tb_prop_scores &lt;- estim_prop(scores_train, scores_test) |&gt; \n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n  \n  list(\n    scenario = simu_data$scenario,   # data scenario\n    repn = simu_data$repn,           # data replication ID\n    metrics = metrics,               # table with performance/calib/divergence\n    tb_prop_scores = tb_prop_scores, # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist        # histogram of scores\n  )\n}\n\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_glm.html#estimations",
    "href": "book_ojeda_glm.html#estimations",
    "title": "9  Generalized Linear Models",
    "section": "9.4 Estimations",
    "text": "9.4 Estimations\nWe loop over the 16 scenarios and run the 100 replications in parallel.\n\n\nSimulation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n}) |&gt; \n  invisible()\n\nclusterExport(cl, c(\"simulate_data\"))\n\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  \n  resul_glm_scenario &lt;- \n    pblapply(\n      1:length(repns_vector), function(i) simul_glm(\n        scenario = scenario, params_df = params_df, repn = repns_vector[i]\n      )\n    )\n  save(\n    resul_glm_scenario, \n    file = str_c(\"output/simul/dgp-ojeda/resul_glm_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results can be loaded as follows:\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_glm_scenario_\", 1:16, \".rda\"\n)\nresul_glm &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_glm_scenario})\n\nThe resul_glm object is of length 16: each element contains the simulations for a scenario. For each scenario, the elements are a list of length max(repns_vector), i.e., the number of replications. Each replication gives, in a list, the following elements:\n\nscenario: the number of the scenario\nrepn: the replication number\nmetrics: the metrics (AUC, Calibration, KL Divergence , etc.) for each model from the grid search, for all boosting iterations.\ntb_prop_scores: the estimations of \\(\\mathbb{P}(q_1 &lt; \\hat{s}(\\mathbb{x})&lt; q_2)\\), for \\(q_1 =\\{ .1, .2, .3, .4\\}\\).\nscores_hist: the counts on bins defined on estimated scores (on both train and test sets).",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_glm.html#results",
    "href": "book_ojeda_glm.html#results",
    "title": "9  Generalized Linear Models",
    "section": "9.5 Results",
    "text": "9.5 Results\nWe can now extract some information from the results. Let us begin with the different metrics computed for each of the replications for each scenario.\n\nmetrics_glm_all &lt;- map(\n  resul_glm, \n  function(resul_glm_sc) map(resul_glm_sc, \"metrics\") |&gt; list_rbind()\n) |&gt; \n  list_rbind()\n\nWe can then show boxplots of the metrics for each scenario.\n\n\nCodes to create the boxplots\ndf_plot &lt;- metrics_glm_all |&gt; \n  select(scenario, sample, AUC, mse, ici, KL_20_true_probas) |&gt; \n  pivot_longer(cols = -c(scenario, sample), names_to = \"metric\") |&gt; \n  mutate(\n    scenario = factor(scenario),\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\"),\n      labels = c(\"Train\", \"Test\")\n    ),\n    metric = factor(\n      metric,\n      levels = c(\"AUC\", \"mse\", \"ici\", \"KL_20_true_probas\"),\n      labels = c(\"AUC\", \"MSE\", \"ICI\", \"KL Divergence\")\n    )\n  )\n\nggplot(\n  data = df_plot,\n  mapping = aes(x = scenario, y = value, fill = sample)\n) +\n  geom_boxplot() +\n  facet_wrap(~metric, scales = \"free\") +\n  scale_fill_manual(\"Sample\", values = colour_samples) +\n  labs(x = \"Scenario\", y = NULL) +\n  theme_paper()\n\n\n\n\n\nFigure 9.1: Metrics for the GLM model computed on 100 replications of the simulations for each scenario.\n\n\n\n\n\n\n\n\n\n9.5.1 Distribution of Scores\nThen, we can have a look at the distribution of scores on the train set and on the test set for each scenario.\n\nscores_hist_all &lt;- \n  map(\n    resul_glm,\n    function(resul_glm_sc) map(resul_glm_sc, \"scores_hist\")\n  )\n\nWe can focus on the first replication of each of the scenarios:\n\nrepn &lt;- 1\n\n\n\nCode to create the barplots\nplot_hist &lt;- function(metrics_interest, scores_hist_interest) {\n  subtitle &lt;- str_c(\n    \"AUC = \", round(metrics_interest$AUC, 2), \", \",\n    \"Brier = \", round(metrics_interest$ici, 2), \", \\n\",\n    \"ICI = \", round(metrics_interest$ici, 2), \", \",\n    \"KL = \", round(metrics_interest$KL_20_true_probas, 2)\n  )\n  plot(\n    # main = \"Test Set\",\n    main = \"\",\n    scores_hist_interest$test,\n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .6)\n}\n\nplot_hist_dgp &lt;- function(repn) {\n  layout(\n    matrix(c(1:5, (1:20)+5), ncol = 5, byrow = TRUE), \n    heights = c(.3, rep(3, 4))\n  )\n  par(mar = c(0, 4.1, 0, 2.1))\n  col_titles &lt;- c(\"True Probabilities\", str_c(c(0, 10, 50, 100), \" noise variables\"))\n  for (i in 1:5) {\n    plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    text(x = 0.5, y = 0.5, col_titles[i], cex = 1.6, col = \"black\")\n  }\n  \n  par(mar = c(4.1, 4.1, 1.6, 2.1))\n  for (dgp in 1:4) {\n    scenarios &lt;- (1:4) + 4*(dgp-1)\n    # True Probabilities\n    simu_data &lt;- simulate_data_wrapper(\n      scenario = scenarios[1],\n      params_df = params_df,\n      repn = repn # only one replication here\n    )\n    true_prob &lt;- simu_data$data$probs_train\n    hist(\n      true_prob,\n      breaks = seq(0, 1, by = .05),\n      xlab = \"p\", ylab = \"\",\n      main = \"\",\n      xlim = c(0, 1)\n    )\n    mtext(\n      side = 2, str_c(\"DGP \", dgp), line = 2.5, cex = 1, \n      font.lab = 2\n    )\n    \n    for (i_scenario in scenarios) {\n      metrics_interest &lt;- metrics_glm_all |&gt; \n        filter(scenario == !!i_scenario, repn == !!repn, sample == \"test\")\n      scores_hist_interest &lt;- scores_hist_all[[i_scenario]][[repn]]\n      plot_hist(\n        metrics_interest = metrics_interest,\n        scores_hist_interest = scores_hist_interest\n      )\n    }\n  }\n}\n\n\n\n\nCode\nplot_hist_dgp(repn = 1)\n\n\n\n\n\nFigure 9.2: Distribution of true probabilities and estimated scores on test set for the logistic regression.\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Generalized Linear Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gam.html",
    "href": "book_ojeda_gam.html",
    "title": "10  Generalized Additive Models",
    "section": "",
    "text": "10.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Generalized Additive Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gam.html#metrics",
    "href": "book_ojeda_gam.html#metrics",
    "title": "10  Generalized Additive Models",
    "section": "10.2 Metrics",
    "text": "10.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Generalized Additive Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gam.html#simulations-setup",
    "href": "book_ojeda_gam.html#simulations-setup",
    "title": "10  Generalized Additive Models",
    "section": "10.3 Simulations Setup",
    "text": "10.3 Simulations Setup\nAs in previous chapters, we define a function to run replications of the simulations for each scenario. This function is called simul_gam(). It uses multiple helper functions alse defined here.\n\n\nHelper Functions\n#' Counts the number of scores in each of the 20 equal-sized bins over [0,1]\n#'\n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\nget_histogram &lt;- function(scores_train, scores_test) {\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    test = scores_test_hist\n  )\n  scores_hist\n}\n\n#' Get KL divergence metrics for estimated scores and true probabilities\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param true_prob list of true probabilities on train and test set\nget_disp_metrics &lt;- function(scores_train, scores_test, true_prob) {\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n  \n  tb_disp_metrics &lt;- disp_train |&gt;\n    bind_rows(disp_test)\n  tb_disp_metrics\n}\n\n#' Get the performance and calibration metrics for estimated scores\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param tb_train train set\n#' @param tb_test test set\n#' @param true_prob list of true probabilities on train and test set\nget_perf_metrics &lt;- function(scores_train, \n                             scores_test,\n                             tb_train,\n                             tb_test,\n                             true_prob) {\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n  \n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n  \n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_test)\n  tb_metrics\n}\n\n#' Estimation of P(q1 &lt; score &lt; q2)\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param q1 vector of desired values for q1 (q2 = 1-q1)\nestim_prop &lt;- function(scores_train, \n                       scores_test, \n                       q1 = c(.1, .2, .3, .4)) {\n  proq_scores_train &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_test &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n  \n  proq_scores_train |&gt; \n    bind_rows(proq_scores_test)\n}\n\n\n\n\nThe simul_gam() function\nsimul_gam &lt;- function(scenario, params_df, repn) {\n  # Generate Data----\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n  \n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n  \n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      test = simu_data$data$probs_test\n    )\n  \n  # Estimation----\n  spline_df &lt;- 6\n  \n  if (scenario %in% 9:12) {\n    # Factor variables\n    tb_train &lt;- tb_train |&gt; mutate(across(x6:x10, as.factor))\n    tb_test &lt;- tb_test |&gt; mutate(across(x6:x10, as.factor))\n  }\n  \n    ## One hot encoding\n  dmy &lt;- caret::dummyVars(\n    \"d ~ -1+.\", data = tb_train, fullRank = TRUE, contrasts = TRUE, sep = \".\"\n  )\n  X_train_dmy &lt;- data.frame(predict(dmy, newdata = tb_train))\n  X_test_dmy &lt;- data.frame(predict(dmy, newdata = tb_test))\n  # Identify categorical variables\n  categ_names &lt;- map2(\n    .x = dmy$facVars, .y = dmy$lvls, .f = ~str_c(.x, \".\", .y)\n  ) |&gt;\n    unlist()\n  covariate_names &lt;- colnames(X_train_dmy)\n  # smoothing spline for all variables except dummies\n  formula_terms &lt;- ifelse(covariate_names %in% categ_names, \n         covariate_names, \n         str_c(\"s(\", covariate_names, \", df = \", spline_df, \")\")\n  )\n  form_gam &lt;- str_c(\"d ~ \", str_c(formula_terms, collapse = \" + \")) |&gt; \n    as.formula()\n  estim_gam &lt;- gam(\n    formula = form_gam, family = binomial, \n    data = cbind(d = tb_train$d, X_train_dmy)\n  )\n  \n  # Predicted scores----\n  scores_train &lt;- predict(estim_gam, newdata = X_train_dmy, type = \"response\")\n  scores_test &lt;- predict(estim_gam, newdata = X_test_dmy, type = \"response\")\n  \n  # Histogram of scores----\n  scores_hist &lt;- get_histogram(scores_train, scores_test)\n  \n  # Performance and Calibration Metrics----\n  tb_metrics &lt;- get_perf_metrics(\n    scores_train = scores_train, \n    scores_test = scores_test, \n    tb_train = tb_train, \n    tb_test = tb_test, \n    true_prob = true_prob) |&gt; \n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n  \n  # Dispersion Metrics----\n  tb_disp_metrics &lt;- get_disp_metrics(\n    scores_train = scores_train, \n    scores_test = scores_test,\n    true_prob = true_prob\n  ) |&gt; \n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n  \n  metrics &lt;- suppressMessages(\n    left_join(tb_metrics, tb_disp_metrics)\n  )\n  \n  # Estimation of P(q1 &lt; score &lt; q2)----\n  tb_prop_scores &lt;- estim_prop(scores_train, scores_test) |&gt; \n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n  \n  list(\n    scenario = simu_data$scenario,   # data scenario\n    repn = simu_data$repn,           # data replication ID\n    metrics = metrics,            # table with performance/calib/divergence\n    tb_prop_scores = tb_prop_scores, # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist       # histogram of scores\n  )\n}\n\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Generalized Additive Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gam.html#estimations",
    "href": "book_ojeda_gam.html#estimations",
    "title": "10  Generalized Additive Models",
    "section": "10.4 Estimations",
    "text": "10.4 Estimations\nWe loop over the 16 scenarios and run the 100 replications in parallel.\n\n\nSimulation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(ks)\n  library(gam)\n  library(philentropy)\n  library(caret)\n}) |&gt; \n  invisible()\n\nclusterExport(\n  cl, c(\n    # Functions\n    \"brier_score\",\n    \"compute_metrics\",\n    \"dispersion_metrics\",\n    \"prop_btw_quantiles\",\n    \"subset_target\",\n    \"simulate_data\",\n    \"simulate_data_wrapper\",\n    \"simul_gam\",\n    \"get_histogram\",\n    \"get_disp_metrics\",\n    \"get_perf_metrics\",\n    \"estim_prop\",\n    # Objects\n    \"grid\",\n    \"params_df\",\n    \"repns_vector\"\n    )\n  )\n\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  clusterExport(cl, c(\"scenario\"))\n  resul_gam_scenario &lt;- \n    pblapply(\n      1:length(repns_vector), function(i) simul_gam(\n        scenario = scenario, params_df = params_df, repn = repns_vector[i]\n      ),\n      cl = cl\n    )\n  save(\n    resul_gam_scenario, \n    file = str_c(\"output/simul/dgp-ojeda/resul_gam_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results can be loaded as follows:\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_gam_scenario_\", 1:16, \".rda\"\n)\nresul_gam &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_gam_scenario})\n\nThe resul_gam object is of length 16: each element contains the simulations for a scenario. For each scenario, the elements are a list of length max(repns_vector), i.e., the number of replications. Each replication gives, in a list, the following elements:\n\nscenario: the number of the scenario\nrepn: the replication number\nmetrics: the metrics (AUC, Calibration, KL Divergence , etc.) for each model from the grid search, for all boosting iterations.\ntb_prop_scores: the estimations of \\(\\mathbb{P}(q_1 &lt; \\hat{s}(\\mathbb{x})&lt; q_2)\\), for \\(q_1 =\\{ .1, .2, .3, .4\\}\\).\nscores_hist: the counts on bins defined on estimated scores (on both train and test sets).",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Generalized Additive Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gam.html#results",
    "href": "book_ojeda_gam.html#results",
    "title": "10  Generalized Additive Models",
    "section": "10.5 Results",
    "text": "10.5 Results\nWe can now extract some information from the results. Let us begin with the different metrics computed for each of the replications for each scenario.\n\nmetrics_gam_all &lt;- map(\n  resul_gam, \n  function(resul_gam_sc) map(resul_gam_sc, \"metrics\") |&gt; list_rbind()\n) |&gt; \n  list_rbind()\n\nWe can then show boxplots of the metrics for each scenario.\n\n\nCodes to create the boxplots\ndf_plot &lt;- metrics_gam_all |&gt; \n  select(scenario, sample, AUC, mse, ici, KL_20_true_probas) |&gt; \n  pivot_longer(cols = -c(scenario, sample), names_to = \"metric\") |&gt; \n  mutate(\n    scenario = factor(scenario),\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\"),\n      labels = c(\"Train\", \"Test\")\n    ),\n    metric = factor(\n      metric,\n      levels = c(\"AUC\", \"mse\", \"ici\", \"KL_20_true_probas\"),\n      labels = c(\"AUC\", \"MSE\", \"ICI\", \"KL Divergence\")\n    )\n  )\n\nggplot(\n  data = df_plot,\n  mapping = aes(x = scenario, y = value, fill = sample)\n) +\n  geom_boxplot() +\n  facet_wrap(~metric, scales = \"free\") +\n  scale_fill_manual(\"Sample\", values = colour_samples) +\n  labs(x = \"Scenario\", y = NULL) +\n  theme_paper()\n\n\n\n\n\nFigure 10.1: Metrics for the GAM model computed on 100 replications of the simulations for each scenario.\n\n\n\n\n\n\n\n\n\n10.5.1 Distribution of Scores\nThen, we can have a look at the distribution of scores on the train set and on the test set for each scenario.\n\nscores_hist_all &lt;- \n  map(\n    resul_gam,\n    function(resul_gam_sc) map(resul_gam_sc, \"scores_hist\")\n  )\n\nWe can focus on the first replication of each of the scenarios:\n\nrepn &lt;- 1\n\nWe define a function, plot_hist() to plot the distribution of scores also showing some metrics (AUC, ICI and KL divergence) for a particular replication of one scenario. We also define a second function, plot_hist_dgp() to plot the distributions of true probabilities and that of a replication, the different scenarios within a DGP.\n\n\nFunctions plot_hist() and plot_hist_dgp()\nplot_hist &lt;- function(metrics_interest, scores_hist_interest) {\n  subtitle &lt;- str_c(\n    \"AUC = \", round(metrics_interest$AUC, 2), \", \",\n    \"Brier = \", round(metrics_interest$ici, 2), \", \\n\",\n    \"ICI = \", round(metrics_interest$ici, 2), \", \",\n    \"KL = \", round(metrics_interest$KL_20_true_probas, 2)\n  )\n  plot(\n    # main = \"Test Set\",\n    main = \"\",\n    scores_hist_interest$test,\n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .6)\n}\n\nplot_hist_dgp &lt;- function(repn) {\n  layout(\n    matrix(c(1:5, (1:20)+5), ncol = 5, byrow = TRUE), \n    heights = c(.3, rep(3, 4))\n  )\n  par(mar = c(0, 4.1, 0, 2.1))\n  col_titles &lt;- c(\"True Probabilities\", str_c(c(0, 10, 50, 100), \" noise variables\"))\n  for (i in 1:5) {\n    plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    text(x = 0.5, y = 0.5, col_titles[i], cex = 1.6, col = \"black\")\n  }\n  \n  par(mar = c(4.1, 4.1, 1.6, 2.1))\n  for (dgp in 1:4) {\n    scenarios &lt;- (1:4) + 4*(dgp-1)\n    # True Probabilities\n    simu_data &lt;- simulate_data_wrapper(\n      scenario = scenarios[1],\n      params_df = params_df,\n      repn = repn # only one replication here\n    )\n    true_prob &lt;- simu_data$data$probs_train\n    hist(\n      true_prob,\n      breaks = seq(0, 1, by = .05),\n      xlab = \"p\", ylab = \"\",\n      main = \"\",\n      xlim = c(0, 1)\n    )\n    mtext(\n      side = 2, str_c(\"DGP \", dgp), line = 2.5, cex = 1, \n      font.lab = 2\n    )\n    \n    for (i_scenario in scenarios) {\n      metrics_interest &lt;- metrics_gam_all |&gt; \n        filter(scenario == !!i_scenario, repn == !!repn, sample == \"test\")\n      scores_hist_interest &lt;- scores_hist_all[[i_scenario]][[repn]]\n      plot_hist(\n        metrics_interest = metrics_interest,\n        scores_hist_interest = scores_hist_interest\n      )\n    }\n  }\n}\n\n\n\n\nCode\nplot_hist_dgp(repn = 1)\n\n\n\n\n\nFigure 10.2: Distribution of true probabilities and estimated scores on test set for the GAM\n\n\n\n\n\n\n\n\n\n\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Generalized Additive Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gamsel.html",
    "href": "book_ojeda_gamsel.html",
    "title": "11  Generalized Additive Model Selection",
    "section": "",
    "text": "11.1 Data\nWe generate data using the first 12 scenarios from Ojeda et al. (2023) and an additional set of 4 scenarios in which the true probability does not depend on the predictors in a linear way (see Chapter 4).\nsource(\"functions/data-ojeda.R\")\nlibrary(ks)\nsource(\"functions/subsample_target_distribution.R\")\nWhen we simulate a dataset, we draw the following number of observations:\nnb_obs &lt;- 10000\nDefinition of the 16 scenarios\n# Coefficients beta\ncoefficients &lt;- list(\n  # First category (baseline, 2 covariates)\n  c(0.5, 1),  # scenario 1, 0 noise variable\n  c(0.5, 1),  # scenario 2, 10 noise variables\n  c(0.5, 1),  # scenario 3, 50 noise variables\n  c(0.5, 1),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  c(0.5, 1),  # scenario 5, 0 noise variable\n  c(0.5, 1),  # scenario 6, 10 noise variables\n  c(0.5, 1),  # scenario 7, 50 noise variables\n  c(0.5, 1),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  c(0.1, 0.2, 0.3, 0.4, 0.5, 0.01, 0.02, 0.03, 0.04, 0.05),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  c(0.5, 1, .3),  # scenario 5, 0 noise variable\n  c(0.5, 1, .3),  # scenario 6, 10 noise variables\n  c(0.5, 1, .3),  # scenario 7, 50 noise variables\n  c(0.5, 1, .3)  # scenario 8, 100 noise variables\n)\n\n# Mean parameter for the normal distribution to draw from to draw num covariates\nmean_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(0, 2),  # scenario 1, 0 noise variable\n  rep(0, 2),  # scenario 2, 10 noise variables\n  rep(0, 2),  # scenario 3, 50 noise variables\n  rep(0, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(0, 2),  # scenario 5, 0 noise variable\n  rep(0, 2),  # scenario 6, 10 noise variables\n  rep(0, 2),  # scenario 7, 50 noise variables\n  rep(0, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  rep(0, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3),\n  rep(0, 3)\n)\n# Sd parameter for the normal distribution to draw from to draw num covariates\nsd_num &lt;- list(\n  # First category (baseline, 2 covariates)\n  rep(1, 2),  # scenario 1, 0 noise variable\n  rep(1, 2),  # scenario 2, 10 noise variables\n  rep(1, 2),  # scenario 3, 50 noise variables\n  rep(1, 2),  # scenario 4, 100 noise variables\n  # Second category (same as baseline, with lower number of 1s)\n  rep(1, 2),  # scenario 5, 0 noise variable\n  rep(1, 2),  # scenario 6, 10 noise variables\n  rep(1, 2),  # scenario 7, 50 noise variables\n  rep(1, 2),  # scenario 8, 100 noise variables\n  # Third category (same as baseline but with 5 num. and 5 categ. covariates)\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  rep(1, 5),\n  # Fourth category (nonlinear predictor, 3 covariates)\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3),\n  rep(1, 3)\n)\n\nparams_df &lt;- tibble(\n  scenario = 1:16,\n  coefficients = coefficients,\n  n_num = c(rep(2, 8), rep(5, 4), rep(3, 4)),\n  add_categ = c(rep(FALSE, 8), rep(TRUE, 4), rep(FALSE, 4)),\n  n_noise = rep(c(0, 10, 50, 100), 4),\n  mean_num = mean_num,\n  sd_num = sd_num,\n  size_train = rep(nb_obs, 16),\n  size_test = rep(nb_obs, 16),\n  transform_probs = c(rep(FALSE, 4), rep(TRUE, 4), rep(FALSE, 4), rep(FALSE, 4)),\n  linear_predictor = c(rep(TRUE, 12), rep(FALSE, 4)),\n  seed = 202105\n)\nrm(coefficients, mean_num, sd_num)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Additive Model Selection</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gamsel.html#metrics",
    "href": "book_ojeda_gamsel.html#metrics",
    "title": "11  Generalized Additive Model Selection",
    "section": "11.2 Metrics",
    "text": "11.2 Metrics\nWe load the functions from Chapter 3 to compute performance, calibration and divergence metrics.\n\nsource(\"functions/metrics.R\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Additive Model Selection</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gamsel.html#simulations-setup",
    "href": "book_ojeda_gamsel.html#simulations-setup",
    "title": "11  Generalized Additive Model Selection",
    "section": "11.3 Simulations Setup",
    "text": "11.3 Simulations Setup\nAs in previous chapters, we define a function to run replications of the simulations for each scenario. This function is called simul_gamsel(). It uses multiple helper functions also defined here.\n\n\nHelper Functions\n#' Counts the number of scores in each of the 20 equal-sized bins over [0,1]\n#'\n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\nget_histogram &lt;- function(scores_train, scores_test) {\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    test = scores_test_hist\n  )\n  scores_hist\n}\n\n#' Get KL divergence metrics for estimated scores and true probabilities\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param true_prob list of true probabilities on train and test set\nget_disp_metrics &lt;- function(scores_train, scores_test, true_prob) {\n  disp_train &lt;- dispersion_metrics(\n    true_probas = true_prob$train, scores = scores_train\n  ) |&gt; mutate(sample = \"train\")\n  disp_test &lt;- dispersion_metrics(\n    true_probas = true_prob$test, scores = scores_test\n  ) |&gt; mutate(sample = \"test\")\n  \n  tb_disp_metrics &lt;- disp_train |&gt;\n    bind_rows(disp_test)\n  tb_disp_metrics\n}\n\n#' Get the performance and calibration metrics for estimated scores\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param tb_train train set\n#' @param tb_test test set\n#' @param true_prob list of true probabilities on train and test set\nget_perf_metrics &lt;- function(scores_train, \n                             scores_test,\n                             tb_train,\n                             tb_test,\n                             true_prob) {\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train$d, scores = scores_train_noise, true_probas = true_prob$train\n  ) |&gt; mutate(sample = \"train\")\n  \n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test$d, scores = scores_test_noise, true_probas = true_prob$test\n  ) |&gt; mutate(sample = \"test\")\n  \n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_test)\n  tb_metrics\n}\n\n#' Estimation of P(q1 &lt; score &lt; q2)\n#' \n#' @param scores_train vector of scores on the train test\n#' @param scores_test vector of scores on the test test\n#' @param q1 vector of desired values for q1 (q2 = 1-q1)\nestim_prop &lt;- function(scores_train, \n                       scores_test, \n                       q1 = c(.1, .2, .3, .4)) {\n  proq_scores_train &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_test &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n  \n  proq_scores_train |&gt; \n    bind_rows(proq_scores_test)\n}\n\n\n\n\nThe simul_gamsel() function\n#' Run a single replication of the simulations of a scenario\n#' Fits a GAMSEL model to the data.\n#' \n#' @param scenario ID of the scenario\n#' @param params_df tibble with the parameters used to generate data\n#' @param repn replication ID number\nsimul_gamsel &lt;- function(scenario, params_df, repn) {\n  # Generate Data----\n  simu_data &lt;- simulate_data_wrapper(\n    scenario = scenario,\n    params_df = params_df,\n    repn = repn\n  )\n\n  tb_train &lt;- simu_data$data$train |&gt; rename(d = y)\n  tb_test &lt;- simu_data$data$test |&gt; rename(d = y)\n\n  true_prob &lt;-\n    list(\n      train = simu_data$data$probs_train,\n      test = simu_data$data$probs_test\n    )\n\n  # Format Data----\n\n  if (scenario %in% 9:12) {\n    # Factor variables\n    tb_train &lt;- tb_train |&gt; mutate(across(x6:x10, as.factor))\n    tb_test &lt;- tb_test |&gt; mutate(across(x6:x10, as.factor))\n  }\n\n  X_train &lt;- tb_train |&gt; select(-d)\n  X_test &lt;- tb_test |&gt; select(-d)\n  y_train &lt;- tb_train |&gt; pull(d)\n  ## One hot encoding\n  dmy_train &lt;- dummyVars(\n    \" ~ -1+.\", data = X_train, fullRank = TRUE, contrasts = TRUE, sep = \".\"\n  )\n  X_dmy_train &lt;- data.frame(predict(dmy_train, newdata = X_train))\n  # using same encoder for test set\n  X_dmy_test &lt;- data.frame(predict(dmy_train, newdata = X_test))\n  categ_names &lt;- map2(\n    .x = dmy_train$facVars, .y = dmy_train$lvls, .f = ~str_c(.x, \".\", .y)\n  ) |&gt;\n    unlist()\n\n  # Estimation----\n  ## Degrees\n  deg &lt;- ifelse(!colnames(X_dmy_train) %in% categ_names, 5, 1)\n  gamsel_cv &lt;- cv.gamsel(\n    x = X_dmy_train, y = y_train, family=\"binomial\", degrees = deg\n  )\n  gamsel_out &lt;- gamsel(\n    x = X_dmy_train, y = y_train, family = \"binomial\", degrees = deg,\n    lambda = gamsel_cv$lambda.min\n  )\n\n  # Predicted scores----\n  scores_train &lt;- predict(\n    gamsel_out, newdata = X_dmy_train, type = \"response\")[, 1]\n  scores_test &lt;- predict(\n    gamsel_out, newdata = X_dmy_test, type = \"response\")[, 1]\n\n  # Histogram of scores----\n  scores_hist &lt;- get_histogram(scores_train, scores_test)\n\n  # Performance and Calibration Metrics----\n  tb_metrics &lt;- get_perf_metrics(\n    scores_train = scores_train,\n    scores_test = scores_test,\n    tb_train = tb_train,\n    tb_test = tb_test,\n    true_prob = true_prob) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n\n  # Dispersion Metrics----\n  tb_disp_metrics &lt;- get_disp_metrics(\n    scores_train = scores_train,\n    scores_test = scores_test,\n    true_prob = true_prob\n  ) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n\n  metrics &lt;- suppressMessages(\n    left_join(tb_metrics, tb_disp_metrics)\n  )\n\n  # Estimation of P(q1 &lt; score &lt; q2)----\n  tb_prop_scores &lt;- estim_prop(scores_train, scores_test) |&gt;\n    mutate(\n      scenario = simu_data$scenario,\n      repn = simu_data$repn\n    )\n\n  list(\n    scenario = simu_data$scenario,   # data scenario\n    repn = simu_data$repn,           # data replication ID\n    metrics = metrics,            # table with performance/calib/divergence\n    tb_prop_scores = tb_prop_scores, # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist       # histogram of scores\n  )\n}\n\n\nThe desired number of replications for each scenario needs to be set:\n\nrepns_vector &lt;- 1:100",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Additive Model Selection</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gamsel.html#estimations",
    "href": "book_ojeda_gamsel.html#estimations",
    "title": "11  Generalized Additive Model Selection",
    "section": "11.4 Estimations",
    "text": "11.4 Estimations\nWe loop over the 16 scenarios and run the 100 replications in parallel.\n\n\nEstimation codes\nlibrary(pbapply)\nlibrary(parallel)\nncl &lt;- detectCores()-1\n(cl &lt;- makeCluster(ncl))\n\nclusterEvalQ(cl, {\n  library(tidyverse)\n  library(ks)\n  library(gamsel)\n  library(philentropy)\n  library(caret)\n}) |&gt;\n  invisible()\n\nclusterExport(\n  cl, c(\n    # Functions\n    \"brier_score\",\n    \"compute_metrics\",\n    \"dispersion_metrics\",\n    \"prop_btw_quantiles\",\n    \"subset_target\",\n    \"simulate_data\",\n    \"simulate_data_wrapper\",\n    \"simul_gamsel\",\n    \"get_histogram\",\n    \"get_disp_metrics\",\n    \"get_perf_metrics\",\n    \"estim_prop\",\n    # Objects\n    \"grid\",\n    \"params_df\",\n    \"repns_vector\"\n    )\n  )\n\nfor (i_scenario in 1:16) {\n  scenario &lt;- i_scenario\n  print(str_c(\"Scenario \", scenario, \"/\", nrow(params_df)))\n  clusterExport(cl, c(\"scenario\"))\n  resul_gamsel_scenario &lt;-\n    pblapply(\n      1:length(repns_vector), function(i) simul_gamsel(\n        scenario = scenario, params_df = params_df, repn = i\n      ),\n      cl = cl\n    )\n  save(\n    resul_gamsel_scenario,\n    file = str_c(\"output/simul/dgp-ojeda/resul_gamsel_scenario_\", scenario, \".rda\")\n  )\n}\nstopCluster(cl)\n\n\nThe results can be loaded as follows:\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_gamsel_scenario_\", 1:16, \".rda\"\n)\nresul_gamsel &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_gamsel_scenario})\n\nThe resul_gamsel object is of length 16: each element contains the simulations for a scenario. For each scenario, the elements are a list of length max(repns_vector), i.e., the number of replications. Each replication gives, in a list, the following elements:\n\nscenario: the number of the scenario\nrepn: the replication number\nmetrics: the metrics (AUC, Calibration, KL Divergence , etc.) for each model from the grid search, for all boosting iterations.\ntb_prop_scores: the estimations of \\(\\mathbb{P}(q_1 &lt; \\hat{s}(\\mathbb{x})&lt; q_2)\\), for \\(q_1 =\\{ .1, .2, .3, .4\\}\\).\nscores_hist: the counts on bins defined on estimated scores (on both train and test sets).",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Additive Model Selection</span>"
    ]
  },
  {
    "objectID": "book_ojeda_gamsel.html#results",
    "href": "book_ojeda_gamsel.html#results",
    "title": "11  Generalized Additive Model Selection",
    "section": "11.5 Results",
    "text": "11.5 Results\nWe can now extract some information from the results. Let us begin with the different metrics computed for each of the replications for each scenario.\n\nmetrics_gamsel_all &lt;- map(\n  resul_gamsel, \n  function(resul_gamsel_sc) map(resul_gamsel_sc, \"metrics\") |&gt; list_rbind()\n) |&gt; \n  list_rbind()\n\nWe can then show boxplots of the metrics for each scenario.\n\n\nCodes to create the boxplots\ndf_plot &lt;- metrics_gamsel_all |&gt; \n  select(scenario, sample, AUC, mse, ici, KL_20_true_probas) |&gt; \n  pivot_longer(cols = -c(scenario, sample), names_to = \"metric\") |&gt; \n  mutate(\n    scenario = factor(scenario),\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\"),\n      labels = c(\"Train\", \"Test\")\n    ),\n    metric = factor(\n      metric,\n      levels = c(\"AUC\", \"mse\", \"ici\", \"KL_20_true_probas\"),\n      labels = c(\"AUC\", \"MSE\", \"ICI\", \"KL Divergence\")\n    )\n  )\n\nggplot(\n  data = df_plot,\n  mapping = aes(x = scenario, y = value, fill = sample)\n) +\n  geom_boxplot() +\n  facet_wrap(~metric, scales = \"free\") +\n  scale_fill_manual(\"Sample\", values = colour_samples) +\n  labs(x = \"Scenario\", y = NULL) +\n  theme_paper()\n\n\n\n\n\nFigure 11.1: Metrics for the GAMSEL model computed on 100 replications of the simulations for each scenario.\n\n\n\n\n\n\n\n\n\n11.5.1 Distribution of Scores\nThen, we can have a look at the distribution of scores on the train set and on the test set for each scenario.\n\nscores_hist_all &lt;- \n  map(\n    resul_gamsel,\n    function(resul_gamsel_sc) map(resul_gamsel_sc, \"scores_hist\")\n  )\n\nWe can focus on the first replication of each of the scenarios:\n\nrepn &lt;- 1\n\nWe define a function, plot_hist() to plot the distribution of scores also showing some metrics (AUC, ICI and KL divergence) for a particular replication of one scenario. We also define a second function, plot_hist_dgp() to plot the distributions of true probabilities and that of a replication, for multiple scenarios within a DGP.\n\n\nFunctions plot_hist() and plot_hist_dgp()\nplot_hist &lt;- function(metrics_interest, scores_hist_interest) {\n  subtitle &lt;- str_c(\n    \"AUC = \", round(metrics_interest$AUC, 2), \", \",\n    \"Brier = \", round(metrics_interest$ici, 2), \", \\n\",\n    \"ICI = \", round(metrics_interest$ici, 2), \", \",\n    \"KL = \", round(metrics_interest$KL_20_true_probas, 2)\n  )\n  plot(\n    # main = \"Test Set\",\n    main = \"\",\n    scores_hist_interest$test,\n    xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylab = \"\"\n  )\n  mtext(side = 3, line = -0.25, adj = .5, subtitle, cex = .6)\n}\n\nplot_hist_dgp &lt;- function(repn) {\n  layout(\n    matrix(c(1:5, (1:20)+5), ncol = 5, byrow = TRUE), \n    heights = c(.3, rep(3, 4))\n  )\n  par(mar = c(0, 4.1, 0, 2.1))\n  col_titles &lt;- c(\"True Probabilities\", str_c(c(0, 10, 50, 100), \" noise variables\"))\n  for (i in 1:5) {\n    plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    text(x = 0.5, y = 0.5, col_titles[i], cex = 1.6, col = \"black\")\n  }\n  \n  par(mar = c(4.1, 4.1, 1.6, 2.1))\n  for (dgp in 1:4) {\n    scenarios &lt;- (1:4) + 4*(dgp-1)\n    # True Probabilities\n    simu_data &lt;- simulate_data_wrapper(\n      scenario = scenarios[1],\n      params_df = params_df,\n      repn = repn # only one replication here\n    )\n    true_prob &lt;- simu_data$data$probs_train\n    hist(\n      true_prob,\n      breaks = seq(0, 1, by = .05),\n      xlab = \"p\", ylab = \"\",\n      main = \"\",\n      xlim = c(0, 1)\n    )\n    mtext(\n      side = 2, str_c(\"DGP \", dgp), line = 2.5, cex = 1, \n      font.lab = 2\n    )\n    \n    for (i_scenario in scenarios) {\n      metrics_interest &lt;- metrics_gamsel_all |&gt; \n        filter(scenario == !!i_scenario, repn == !!repn, sample == \"test\")\n      scores_hist_interest &lt;- scores_hist_all[[i_scenario]][[repn]]\n      plot_hist(\n        metrics_interest = metrics_interest,\n        scores_hist_interest = scores_hist_interest\n      )\n    }\n  }\n}\n\n\n\n\nCode\nplot_hist_dgp(repn = 1)\n\n\n\n\n\nFigure 11.2: Distribution of true probabilities and estimated scores on test set for the GAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\nChouldechova, Alexandra, and Trevor Hastie. 2015. “Generalized Additive Model Selection.” https://arxiv.org/abs/1506.03850.\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan Blankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler. 2023. “Calibrating Machine Learning Approaches for Probability Estimation: A Comprehensive Comparison.” Statistics in Medicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Generalized Additive Model Selection</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html",
    "href": "book_ojeda_comparison.html",
    "title": "12  Comparison of Models",
    "section": "",
    "text": "13 Load Previous Results",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#trees",
    "href": "book_ojeda_comparison.html#trees",
    "title": "12  Comparison of Models",
    "section": "13.1 Trees",
    "text": "13.1 Trees\nThe trees estimated in Chapter 5.\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_trees_scenario_\", 1:16, \".rda\"\n)\nresul_trees &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_trees_scenario})\n\nWe can merge the metrics tables computed for each scenario and replications for these scenarios into a single tibble.\n\nmetrics_trees_all &lt;- map(\n  resul_trees,\n  function(resul_trees_sc) map(resul_trees_sc, \"metrics_all\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"valid\", \"test\"),\n      labels = c(\"Train\", \"Validation\", \"Test\")\n    )\n  )\n\nWe extract the metrics from the trees of interest:\n\nsmallest: tree with the smallest number of leaves\nlargest: tree with the highest number of leaves\nlargest_auc: tree with the highest AUC on validation set\nlowest_mse: tree with the lowest MSE on validation set\nlowest_brier: tree with the lowest Brier on validation set\nlowest_ici: tree with the lowest ICI on validation set\nlowest_kl: tree with the lowest KL Divergence on validation set\n\n\n\nCode to identify trees of interest\n# Identify the smallest tree\nsmallest_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(nb_leaves) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Identify the largest tree\nlargest_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Test\") |&gt;\n  group_by(scenario, repn) |&gt; \n  arrange(desc(nb_leaves)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest\") |&gt; \n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest_auc\") |&gt;\n  ungroup()\n\n# Identify tree with lowest MSE\nlowest_mse_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_mse\") |&gt;\n  ungroup()\n\n# Identify tree with lowest ICI\nlowest_ici_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(ici) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_ici\") |&gt;\n  ungroup()\n\n# Identify tree with lowest Brier's score\nlowest_brier_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(brier) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_brier\") |&gt;\n  ungroup()\n\n# Identify tree with lowest KL\nlowest_kl_tree &lt;-\n  metrics_trees_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_kl\") |&gt;\n  ungroup()\n\n\n# Merge these\ntrees_of_interest_tree &lt;-\n  smallest_tree |&gt;\n  bind_rows(largest_tree) |&gt;\n  bind_rows(highest_auc_tree) |&gt;\n  bind_rows(lowest_mse_tree) |&gt;\n  bind_rows(lowest_ici_tree) |&gt;\n  bind_rows(lowest_brier_tree) |&gt;\n  bind_rows(lowest_kl_tree)\n\n# Add metrics now\ntrees_of_interest_metrics_tree &lt;-\n  trees_of_interest_tree |&gt;\n  left_join(\n    metrics_trees_all, \n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_leaves\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  ) |&gt; \n  mutate(\n    result_type = factor(\n      result_type,\n      levels = c(\n        \"smallest\", \"largest\", \"lowest_mse\", \"largest_auc\",\n        \"lowest_brier\", \"lowest_ici\", \"lowest_kl\"),\n      labels = c(\n        \"Smallest\", \"Largest\", \"MSE*\", \"AUC*\", \n        \"Brier*\", \"ICI*\", \"KL*\"\n      )\n    )\n  )\n\n# Sanity check\n# trees_of_interest_metrics_tree |&gt; count(scenario, sample, result_type)\n\n\nWe ran 100 replications of the simulations for each scenario. Let us compute the average AUC, ICI and KL Divergence over these 100 replications, both on the train and on the validation set.\n\nmodels_interest_trees &lt;- \n  trees_of_interest_metrics_tree |&gt; \n  group_by(scenario, sample, result_type) |&gt; \n  summarise(\n    AUC_lower = quantile(AUC, probs = 2.5/100),\n    AUC_upper = quantile(AUC, probs = 97.5/100),\n    AUC_sd = sd(AUC),\n    AUC = mean(AUC),\n    brier_lower = quantile(brier, probs = 2.5/100),\n    brier_upper = quantile(brier, probs = 97.5/100),\n    brier_sd = sd(brier),\n    brier = mean(brier),\n    ici_lower = quantile(ici, probs = 2.5/100),\n    ici_upper = quantile(ici, probs = 97.5/100),\n    ici_sd = sd(ici),\n    ici = mean(ici),\n    KL_20_true_probas_lower = quantile(KL_20_true_probas, probs = 2.5/100),\n    KL_20_true_probas_upper = quantile(KL_20_true_probas, probs = 97.5/100),\n    KL_20_true_probas_sd = sd(KL_20_true_probas),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    quant_ratio_sd = sd(inter_quantile_10_90),\n    quant_ratio = mean(inter_quantile_10_90),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(model = \"tree\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#random-forests",
    "href": "book_ojeda_comparison.html#random-forests",
    "title": "12  Comparison of Models",
    "section": "13.2 Random Forests",
    "text": "13.2 Random Forests\nWe load the estimated random forests from Chapter 6.\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_rf_scenario_\", 1:16, \".rda\"\n)\nresul_rf &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_rf_scenario})\n\nLet us merge in a single tibble the metrics computed over the replications of the scenarios.\n\nmetrics_rf_all &lt;- map(\n  resul_rf,\n  function(resul_rf_sc) map(resul_rf_sc, \"metrics_all\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\", \"valid\"),\n      labels = c(\"Train\", \"Test\", \"Validation\")\n    )\n  )\n\nWe extract the metrics from the trees of interest:\n\nsmallest: forest with the smallest average number of leaves in the trees\nlargest: forest with the highest average number of leaves in the trees\nlargest_auc: forest with the highest AUC on validation set\nlowest_mse: forest with the lowest MSE on validation set\nlowest_ici: forest with the lowest ICI on validation set\nlowest_brier: forest with the lowest Brier score on validation set\nlowest_kl: forest with the lowest KL Divergence on validation set\n\n\n\nCode\n# Identify the model with the smallest number of leaves on average on\n# validation set\nsmallest_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(nb_leaves) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Identify the largest tree\nlargest_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(nb_leaves)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest\") |&gt;\n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"largest_auc\") |&gt;\n  ungroup()\n\n# Identify tree with lowest MSE\nlowest_mse_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_mse\") |&gt;\n  ungroup()\n\n# Identify tree with lowest Brier\nlowest_brier_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(brier) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_brier\") |&gt;\n  ungroup()\n\n# Identify tree with lowest ICI\nlowest_ici_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(ici) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_ici\") |&gt;\n  ungroup()\n\n# Identify tree with lowest KL\nlowest_kl_rf &lt;-\n  metrics_rf_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_leaves) |&gt;\n  mutate(result_type = \"lowest_kl\") |&gt;\n  ungroup()\n\n# Merge these\nrf_of_interest &lt;-\n  smallest_rf |&gt;\n  bind_rows(largest_rf) |&gt;\n  bind_rows(highest_auc_rf) |&gt;\n  bind_rows(lowest_mse_rf) |&gt;\n  bind_rows(lowest_brier_rf) |&gt;\n  bind_rows(lowest_ici_rf) |&gt;\n  bind_rows(lowest_kl_rf)\n\n# Add metrics now\nrf_of_interest &lt;-\n  rf_of_interest |&gt;\n  left_join(\n    metrics_rf_all,\n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_leaves\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  ) |&gt;\n  mutate(\n    result_type = factor(\n      result_type,\n      levels = c(\n        \"smallest\", \"largest\", \"lowest_mse\", \"largest_auc\",\n        \"lowest_brier\", \"lowest_ici\", \"lowest_kl\"),\n      labels = c(\n        \"Smallest\", \"Largest\", \"MSE*\", \"AUC*\",\n        \"Brier*\", \"ICI*\", \"KL*\"\n      )\n    )\n  )\n\n# Sanity check\n# trees_of_interest_metrics_rf |&gt; count(scenario, sample, result_type)\n\n\nWe ran 100 replications of the simulations for each scenario and each set of hyperparameters. Let us compute the average AUC, ICI and KL Divergence over these replications, both on the train and on the validation set.\n\nmodels_interest_rf &lt;- rf_of_interest |&gt; \n  group_by(scenario, sample, result_type) |&gt; \n  summarise(\n    AUC_lower = quantile(AUC, probs = 2.5/100),\n    AUC_upper = quantile(AUC, probs = 97.5/100),\n    AUC_sd = sd(AUC),\n    AUC = mean(AUC),\n    brier_lower = quantile(brier, probs = 2.5/100),\n    brier_upper = quantile(brier, probs = 97.5/100),\n    brier_sd = sd(brier),\n    brier = mean(brier),\n    ici_lower = quantile(ici, probs = 2.5/100),\n    ici_upper = quantile(ici, probs = 97.5/100),\n    ici_sd = sd(ici),\n    ici = mean(ici),\n    KL_20_true_probas_lower = quantile(KL_20_true_probas, probs = 2.5/100),\n    KL_20_true_probas_upper = quantile(KL_20_true_probas, probs = 97.5/100),\n    KL_20_true_probas_sd = sd(KL_20_true_probas),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    quant_ratio_sd = sd(inter_quantile_10_90),\n    quant_ratio = mean(inter_quantile_10_90),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(model = \"rf\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#extreme-gradient-boosting",
    "href": "book_ojeda_comparison.html#extreme-gradient-boosting",
    "title": "12  Comparison of Models",
    "section": "13.3 Extreme Gradient Boosting",
    "text": "13.3 Extreme Gradient Boosting\n\nscenarios &lt;- 1:16\n\nLet us load the estimated models from ?sec-simul-sgb.\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_xgb_scenario_\", scenarios, \".rda\"\n)\nresul_xgb &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_xgb_scenario})\n\nLet us merge in a single tibble the metrics computed over the replications of the scenarios.\n\nmetrics_xgb_all &lt;- map(\n  resul_xgb,\n  function(resul_xgb_sc) map(resul_xgb_sc, \"metrics_simul\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"valid\", \"test\"),\n      labels = c(\"Train\",\"Validation\" ,\"Test\")\n    )\n  )\n\nFor each replication, we made some hyperparameters vary. Let us identify some models of interest:\n\nsmallest: model with the lowest number of boosting iteration\nlargest: model with the highest number of boosting iteration\nlargest_auc: model with the highest AUC on validation set\nlowest_mse: model with the lowest MSE on validation set\nlowest_brier: model with the lowest Brier score on validation set\nlowest_ici: model with the lowest ICI on validation set\nlowest_kl: model with the lowest KL Divergence on validation set\n\n\n\nCode\n# Identify the model with the smallest number of boosting iterations\nsmallest_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(nb_iter) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"smallest\") |&gt;\n  ungroup()\n\n# Identify the largest tree\nlargest_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(nb_iter)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"largest\") |&gt;\n  ungroup()\n\n# Identify tree with highest AUC on test set\nhighest_auc_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(desc(AUC)) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"largest_auc\") |&gt;\n  ungroup()\n\n# Identify tree with lowest MSE\nlowest_mse_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(mse) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_mse\") |&gt;\n  ungroup()\n\n# Identify tree with lowest brier\nlowest_brier_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(brier) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_brier\") |&gt;\n  ungroup()\n\n# Identify tree with lowest ICI\nlowest_ici_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(ici) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_ici\") |&gt;\n  ungroup()\n\n# Identify tree with lowest KL\nlowest_kl_xgb &lt;-\n  metrics_xgb_all |&gt;\n  filter(sample == \"Validation\") |&gt;\n  group_by(scenario, repn) |&gt;\n  arrange(KL_20_true_probas) |&gt;\n  slice_head(n = 1) |&gt;\n  select(scenario, repn, ind, nb_iter) |&gt;\n  mutate(result_type = \"lowest_kl\") |&gt;\n  ungroup()\n\n# Merge these\nmodels_of_interest_xgb &lt;-\n  smallest_xgb |&gt;\n  bind_rows(largest_xgb) |&gt;\n  bind_rows(highest_auc_xgb) |&gt;\n  bind_rows(lowest_mse_xgb) |&gt;\n  bind_rows(lowest_brier_xgb) |&gt;\n  bind_rows(lowest_ici_xgb) |&gt;\n  bind_rows(lowest_kl_xgb)\n\n# Add metrics now\nmodels_of_interest_metrics &lt;-\n  models_of_interest_xgb |&gt;\n  left_join(\n    metrics_xgb_all,\n    by = c(\"scenario\", \"repn\", \"ind\", \"nb_iter\"),\n    relationship = \"many-to-many\" # (train, valid, test)\n  ) |&gt; \n  mutate(\n    result_type = factor(\n      result_type,\n      levels = c(\n        \"smallest\", \"largest\", \"lowest_mse\", \"largest_auc\",\n        \"lowest_brier\", \"lowest_ici\", \"lowest_kl\"),\n      labels = c(\n        \"Smallest\", \"Largest\", \"MSE*\", \"AUC*\", \n        \"Brier*\", \"ICI*\", \"KL*\"\n      )\n    )\n  )\n\n# Sanity check\n# models_of_interest_metrics |&gt; count(scenario, sample, result_type)\n\n\nThen, we compute the average values of the AUC, the ICI and the KL divergence for these models of interest over the 100 replications, for each scenario, both on the train and the validation set.\n\nmodels_interest_xgb &lt;- models_of_interest_metrics |&gt; \n  group_by(scenario, sample, result_type) |&gt; \n  summarise(\n    AUC_lower = quantile(AUC, probs = 2.5/100),\n    AUC_upper = quantile(AUC, probs = 97.5/100),\n    AUC_sd = sd(AUC),\n    AUC = mean(AUC),\n    brier_lower = quantile(brier, probs = 2.5/100),\n    brier_upper = quantile(brier, probs = 97.5/100),\n    brier_sd = sd(brier),\n    brier = mean(brier),\n    ici_lower = quantile(ici, probs = 2.5/100),\n    ici_upper = quantile(ici, probs = 97.5/100),\n    ici_sd = sd(ici),\n    ici = mean(ici),\n    KL_20_true_probas_lower = quantile(KL_20_true_probas, probs = 2.5/100),\n    KL_20_true_probas_upper = quantile(KL_20_true_probas, probs = 97.5/100),\n    KL_20_true_probas_sd = sd(KL_20_true_probas),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    quant_ratio_sd = sd(inter_quantile_10_90),\n    quant_ratio = mean(inter_quantile_10_90),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    model = \"xgb\",\n    sample = str_to_lower(as.character(sample))\n  )\n\n# Sanity check\n# metrics_xgb_all |&gt; count(scenario, ind, sample, nb_iter) |&gt;\n#   filter(n != max(repns_vector))",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#generalized-linear-models",
    "href": "book_ojeda_comparison.html#generalized-linear-models",
    "title": "12  Comparison of Models",
    "section": "13.4 Generalized Linear Models",
    "text": "13.4 Generalized Linear Models\nLet us load the results from Chapter 9.\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_glm_scenario_\", 1:16, \".rda\"\n)\nresul_glm &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_glm_scenario})\n\nWe extract the computed metrics:\n\nmetrics_glm_all &lt;- map(\n  resul_glm,\n  function(resul_glm_sc) map(resul_glm_sc, \"metrics\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\"), labels = c(\"Train\", \"Test\")\n    )\n  )\n\nThen, for each scenario, we compute the average of the AUC, the ICI and the KL divergence over the 100 replications.\n\nmodels_interest_glm &lt;- \n  metrics_glm_all |&gt; \n  group_by(scenario, sample) |&gt; \n  summarise(\n    AUC_lower = quantile(AUC, probs = 2.5/100),\n    AUC_upper = quantile(AUC, probs = 97.5/100),\n    AUC_sd = sd(AUC),\n    AUC = mean(AUC),\n    brier_lower = quantile(brier, probs = 2.5/100),\n    brier_upper = quantile(brier, probs = 97.5/100),\n    brier_sd = sd(brier),\n    brier = mean(brier),\n    ici_lower = quantile(ici, probs = 2.5/100),\n    ici_upper = quantile(ici, probs = 97.5/100),\n    ici_sd = sd(ici),\n    ici = mean(ici),\n    KL_20_true_probas_lower = quantile(KL_20_true_probas, probs = 2.5/100),\n    KL_20_true_probas_upper = quantile(KL_20_true_probas, probs = 97.5/100),\n    KL_20_true_probas_sd = sd(KL_20_true_probas),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    quant_ratio_sd = sd(inter_quantile_10_90),\n    quant_ratio = mean(inter_quantile_10_90),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    model = \"glm\",\n    sample = str_to_lower(as.character(sample))\n  ) |&gt; \n  mutate(result_type = \"None\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#generalized-additive-models",
    "href": "book_ojeda_comparison.html#generalized-additive-models",
    "title": "12  Comparison of Models",
    "section": "13.5 Generalized Additive Models",
    "text": "13.5 Generalized Additive Models\nLet us load the results from Chapter 10.\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_gam_scenario_\", 1:16, \".rda\"\n)\nresul_gam &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_gam_scenario})\n\nWe extract the computed metrics:\n\nmetrics_gam_all &lt;- map(\n  resul_gam,\n  function(resul_gam_sc) map(resul_gam_sc, \"metrics\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\"), labels = c(\"Train\", \"Test\")\n    )\n  )\n\nThen, for each scenario, we compute the average of the AUC, the ICI and the KL divergence over the 100 replications.\n\nmodels_interest_gam &lt;- \n  metrics_gam_all |&gt; \n  group_by(scenario, sample) |&gt; \n  summarise(\n    AUC_lower = quantile(AUC, probs = 2.5/100),\n    AUC_upper = quantile(AUC, probs = 97.5/100),\n    AUC_sd = sd(AUC),\n    AUC = mean(AUC),\n    brier_lower = quantile(brier, probs = 2.5/100),\n    brier_upper = quantile(brier, probs = 97.5/100),\n    brier_sd = sd(brier),\n    brier = mean(brier),\n    ici_lower = quantile(ici, probs = 2.5/100),\n    ici_upper = quantile(ici, probs = 97.5/100),\n    ici_sd = sd(ici),\n    ici = mean(ici),\n    KL_20_true_probas_lower = quantile(KL_20_true_probas, probs = 2.5/100),\n    KL_20_true_probas_upper = quantile(KL_20_true_probas, probs = 97.5/100),\n    KL_20_true_probas_sd = sd(KL_20_true_probas),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    quant_ratio_sd = sd(inter_quantile_10_90),\n    quant_ratio = mean(inter_quantile_10_90),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    model = \"gam\",\n    sample = str_to_lower(as.character(sample))\n  ) |&gt; \n  mutate(result_type = \"None\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#generalized-additive-models-selection",
    "href": "book_ojeda_comparison.html#generalized-additive-models-selection",
    "title": "12  Comparison of Models",
    "section": "13.6 Generalized Additive Models Selection",
    "text": "13.6 Generalized Additive Models Selection\nLet us load the results from Chapter 11.\n\nfiles &lt;- str_c(\n  \"output/simul/dgp-ojeda/resul_gamsel_scenario_\", 1:16, \".rda\"\n)\nresul_gamsel &lt;- map(files[file.exists(files)], ~{load(.x) ; resul_gamsel_scenario})\n\nWe extract the computed metrics:\n\nmetrics_gamsel_all &lt;- map(\n  resul_gamsel,\n  function(resul_gamsel_sc) map(resul_gamsel_sc, \"metrics\") |&gt; list_rbind()\n) |&gt;\n  list_rbind() |&gt;\n  mutate(\n    sample = factor(\n      sample,\n      levels = c(\"train\", \"test\"), labels = c(\"Train\", \"Test\")\n    )\n  )\n\nThen, for each scenario, we compute the average of the AUC, the ICI and the KL divergence over the 100 replications.\n\nmodels_interest_gamsel &lt;- \n  metrics_gamsel_all |&gt; \n  group_by(scenario, sample) |&gt; \n  summarise(\n    AUC_lower = quantile(AUC, probs = 2.5/100),\n    AUC_upper = quantile(AUC, probs = 97.5/100),\n    AUC_sd = sd(AUC),\n    AUC = mean(AUC),\n    brier_lower = quantile(brier, probs = 2.5/100),\n    brier_upper = quantile(brier, probs = 97.5/100),\n    brier_sd = sd(brier),\n    brier = mean(brier),\n    ici_lower = quantile(ici, probs = 2.5/100),\n    ici_upper = quantile(ici, probs = 97.5/100),\n    ici_sd = sd(ici),\n    ici = mean(ici),\n    KL_20_true_probas_lower = quantile(KL_20_true_probas, probs = 2.5/100),\n    KL_20_true_probas_upper = quantile(KL_20_true_probas, probs = 97.5/100),\n    KL_20_true_probas_sd = sd(KL_20_true_probas),\n    KL_20_true_probas = mean(KL_20_true_probas),\n    quant_ratio_sd = sd(inter_quantile_10_90),\n    quant_ratio = mean(inter_quantile_10_90),\n    .groups = \"drop\"\n  ) |&gt; \n  mutate(\n    model = \"gamsel\",\n    sample = str_to_lower(as.character(sample))\n  ) |&gt; \n  mutate(result_type = \"None\")",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_ojeda_comparison.html#tables",
    "href": "book_ojeda_comparison.html#tables",
    "title": "12  Comparison of Models",
    "section": "14.1 Tables",
    "text": "14.1 Tables\nWe also visualize the results in tables. For each model within a given scenario, we report the average AUC, Brier Score, ICI, and KL divergence over 100 replications for the ‘best’ model. For ensemble tree models, the ‘best’ model is identified either when maximizing the AUC (denoted \\(AUC^*\\)), when minimizing the Brier Score (denoted \\(Brier^*\\)), the ICI (denoted \\(ICI^*\\)), or the KL divergence (denoted \\(KL^*\\)). When the best model is selected based anything but the AUC, we compute the variation in the metric as the difference between the metric obtained when minimizing either the Brier score, the ICI, or the KL divergence and the metric obtained when maximizing AUC. Thus, negative values indicate a decrease in the metric compared to when the best model is selected by optimizing AUC. For general linear models, the only metrics reported are the AUC, Brier, ICI, and KL divergence.\n\n\nDisplay the codes to create the summary table.\ntable_models_interest_mean &lt;- \n  models_interest |&gt; \n  filter(sample == \"Test\") |&gt; \n  select(\n    scenario, sample, model, result_type, \n    AUC, brier, ici, kl = KL_20_true_probas, quant_ratio\n  ) |&gt; \n  filter(\n    result_type %in% c(\"AUC*\", \"Brier*\", \"ICI*\", \"KL*\", \"None\")\n  ) |&gt; \n  mutate(result_type = fct_recode(result_type, \"KL*\" = \"None\")) |&gt; \n  mutate(value_type = \"mean\")\n\ntable_models_interest_sd &lt;- \n  models_interest |&gt; \n  filter(sample == \"Test\") |&gt; \n  select(\n    scenario, sample, model, result_type, \n    AUC = AUC_sd, brier = brier_sd, ici = ici_sd, kl = KL_20_true_probas_sd, quant_ratio = quant_ratio_sd\n  ) |&gt; \n  filter(\n    result_type %in% c(\"AUC*\", \"Brier*\", \"ICI*\", \"KL*\", \"None\")\n  ) |&gt; \n  mutate(result_type = fct_recode(result_type, \"KL*\" = \"None\")) |&gt; \n  mutate(value_type = \"sd\")\n\n\nred_colours &lt;- c(\n  \"#FFD6D6\", \"#FFCCCC\", \"#FFC2C2\", \"#FFB8B8\", \"#FFADAD\", \n  \"#FFA3A3\", \"#FF9999\", \"#FF8F8F\", \"#FF8585\", \"#FF7A7A\"\n)\nred_colours_txt &lt;- c(\n  \"#333333\", \"#333333\", \"#2B2B2B\", \"#2B2B2B\", \"#232323\", \n  \"#1F1F1F\", \"#1A1A1A\", \"#141414\", \"#101010\", \"#0A0A0A\"\n)\ngreen_colours &lt;- c(\n  \"#E9F6E9\", \"#D4F2D4\", \"#BFEFBF\", \"#AADCA9\", \"#96C996\",\n  \"#81B781\", \"#6CA56C\", \"#578252\", \"#426F42\", \"#2F5D2F\"\n)\ngreen_colours_txt &lt;- c(\n  \"#1A1A1A\", \"#1A1A1A\", \"#1A1A1A\", \"#1A1A1A\", \"#1A1A1A\",\n  \"#E6E6E6\", \"#E6E6E6\", \"#E6E6E6\", \"#E6E6E6\", \"#E6E6E6\"\n)\n\naccuracy_digits &lt;- 0.01\n\ntable_kb &lt;- \n  table_models_interest_mean |&gt; \n  bind_rows(table_models_interest_sd) |&gt; \n  pivot_wider(\n    names_from = \"result_type\", \n    values_from = c(\"AUC\", \"brier\", \"ici\", \"kl\", \"quant_ratio\")\n  ) |&gt; \n  mutate(\n    value_type = factor(value_type, levels = c(\"mean\", \"sd\")),\n    scenario = factor(scenario)\n  ) |&gt; \n  select(\n    scenario, model, value_type,\n    # # columns for GLM/GAM/GAMSEL\n    # AUC_None, ici_None, kl_None, \n    # columns for ML models selected based on AUC\n    `AUC_AUC*`, `brier_AUC*`, `ici_AUC*`, `kl_AUC*`, `quant_ratio_AUC*`,\n    # columns for ML models selected based on Brier score\n    `AUC_Brier*`,  `brier_Brier*`, `ici_Brier*`, `kl_Brier*`, `quant_ratio_Brier*`,\n    # columns for ML models selected based on ICI\n    `AUC_ICI*`, `brier_ICI*`, `ici_ICI*`, `kl_ICI*`, `quant_ratio_ICI*`,\n    # columns for ML models selected based on KL dist\n    `AUC_KL*`, `brier_KL*`, `ici_KL*`, `kl_KL*`, `quant_ratio_KL*`\n  ) |&gt; \n  arrange(scenario, model, value_type) |&gt; \n  mutate(\n    # Difference in metrics computed when minnimizing Brier wrt when maximizing AUC\n    diff_AUC_Brier = `AUC_Brier*` - `AUC_AUC*`,\n    diff_brier_Brier = `brier_Brier*` - `brier_AUC*`,\n    diff_ICI_Brier = `ici_Brier*` - `ici_AUC*`,\n    diff_KL_Brier = `kl_Brier*` - `kl_AUC*`,\n    diff_quant_ratio_Brier = `quant_ratio_Brier*` - `quant_ratio_AUC*`,\n    # Difference in metrics computed when minnimizing ICI wrt when maximizing AUC\n    diff_AUC_ICI = `AUC_ICI*` - `AUC_AUC*`,\n    diff_brier_ICI = `brier_ICI*` - `brier_AUC*`,\n    diff_ICI_ICI = `ici_ICI*` - `ici_AUC*`,\n    diff_KL_ICI = `kl_ICI*` - `kl_AUC*`,\n    diff_quant_ratio_ICI = `quant_ratio_ICI*` - `quant_ratio_AUC*`,\n    # Difference in metrics computed when minnimizing KL wrt when maximizing AUC\n    diff_AUC_KL = `AUC_KL*` - `AUC_AUC*`,\n    diff_brier_KL = `brier_KL*` - `brier_AUC*`,\n    diff_ICI_KL = `ici_KL*` - `ici_AUC*`,\n    diff_KL_KL = `kl_KL*` - `kl_AUC*`,\n    diff_quant_ratio_KL = `quant_ratio_KL*` - `quant_ratio_AUC*`\n  ) |&gt; \n  ungroup()\n\nget_range_for_colours &lt;- function(variable_name) {\n  value &lt;- table_kb |&gt; \n    filter(value_type == \"mean\") |&gt; \n    pull(!!variable_name) |&gt; \n    range(na.rm = TRUE) |&gt; abs() |&gt; max()\n  value * c(-1, 1)\n}\n\nget_colour &lt;- function(variable, value_type, min_or_max, colour_type) {\n  if (value_type == \"mean\") {\n    variable_string &lt;- deparse(substitute(variable))\n    if (colour_type == \"bg\") {\n      # background colour\n      if (min_or_max == \"min\") {\n        colours &lt;- rev(c(rev(red_colours), green_colours))\n      } else {\n        colours &lt;- c(rev(red_colours), rev(green_colours))\n      }\n    } else {\n      # text colour\n      if (min_or_max == \"min\") {\n        colours &lt;- rev(c(rev(red_colours_txt), green_colours_txt))\n      } else {\n        colours &lt;- c(rev(red_colours_txt), rev(green_colours_txt))\n      }\n    }\n    res &lt;- kableExtra::spec_color(\n      variable,\n      palette = colours,\n      scale_from = get_range_for_colours(variable_string),\n      na_color = \"white\"\n    )\n  } else {\n    res &lt;- \"white\"\n  }\n  res\n}\n\ntable_kb &lt;- \n  table_kb |&gt; \n  rowwise() |&gt; \n  mutate(\n    # Difference in metrics computed when minnimizing ICI wrt when maximizing AUC\n    diff_AUC_Brier_bgcol = get_colour(diff_AUC_Brier, value_type, \"max\", \"bg\"),\n    diff_AUC_Brier_txtcol = get_colour(diff_AUC_Brier, value_type, \"max\", \"txt\"),\n    diff_brier_Brier_bgcol = get_colour(diff_brier_Brier, value_type, \"min\", \"bg\"),\n    diff_brier_Brier_txtcol = get_colour(diff_brier_Brier, value_type, \"min\", \"txt\"),\n    diff_ICI_Brier_bgcol = get_colour(diff_ICI_Brier, value_type, \"min\", \"bg\"),\n    diff_ICI_Brier_txtcol = get_colour(diff_ICI_Brier, value_type, \"min\", \"txt\"),\n    diff_KL_Brier_bgcol = get_colour(diff_KL_Brier, value_type, \"min\", \"bg\"),\n    diff_KL_Brier_txtcol = get_colour(diff_KL_Brier, value_type, \"min\", \"txt\"),\n    diff_quant_ratio_Brier_bgcol = get_colour(diff_quant_ratio_Brier, value_type, \"min\", \"bg\"),\n    diff_quant_ratio_Brier_txtcol = get_colour(diff_quant_ratio_Brier, value_type, \"min\", \"txt\"),\n    # Difference in metrics computed when minnimizing ICI wrt when maximizing AUC\n    diff_AUC_ICI_bgcol = get_colour(diff_AUC_ICI, value_type, \"max\", \"bg\"),\n    diff_AUC_ICI_txtcol = get_colour(diff_AUC_ICI, value_type, \"max\", \"txt\"),\n    diff_brier_ICI_bgcol = get_colour(diff_brier_ICI, value_type, \"min\", \"bg\"),\n    diff_brier_ICI_txtcol = get_colour(diff_brier_ICI, value_type, \"min\", \"txt\"),\n    diff_ICI_ICI_bgcol = get_colour(diff_ICI_ICI, value_type, \"min\", \"bg\"),\n    diff_ICI_ICI_txtcol = get_colour(diff_ICI_ICI, value_type, \"min\", \"txt\"),\n    diff_KL_ICI_bgcol = get_colour(diff_KL_ICI, value_type, \"min\", \"bg\"),\n    diff_KL_ICI_txtcol = get_colour(diff_KL_ICI, value_type, \"min\", \"txt\"),\n    diff_quant_ratio_ICI_bgcol = get_colour(diff_quant_ratio_ICI, value_type, \"min\", \"bg\"),\n    diff_quant_ratio_ICI_txtcol = get_colour(diff_quant_ratio_ICI, value_type, \"min\", \"txt\"),\n    # Difference in metrics computed when minnimizing KL wrt when maximizing AUC\n    diff_AUC_KL_bgcol = get_colour(diff_AUC_KL, value_type, \"max\", \"bg\"),\n    diff_AUC_KL_txtcol = get_colour(diff_AUC_KL, value_type, \"max\", \"txt\"),\n    diff_brier_KL_bgcol = get_colour(diff_brier_KL, value_type, \"min\", \"bg\"),\n    diff_brier_KL_txtcol = get_colour(diff_brier_KL, value_type, \"min\", \"txt\"),\n    diff_ICI_KL_bgcol = get_colour(diff_ICI_KL, value_type, \"min\", \"bg\"),\n    diff_ICI_KL_txtcol = get_colour(diff_ICI_KL, value_type, \"min\", \"txt\"),\n    diff_KL_KL_bgcol = get_colour(diff_KL_KL, value_type, \"min\", \"bg\"),\n    diff_KL_KL_txtcol = get_colour(diff_KL_KL, value_type, \"min\", \"txt\"),\n    diff_quant_ratio_KL_bgcol = get_colour(diff_quant_ratio_KL, value_type, \"min\", \"bg\"),\n    diff_quant_ratio_KL_txtcol = get_colour(diff_quant_ratio_KL, value_type, \"min\", \"txt\")\n  ) |&gt; \n  mutate(\n    across(\n      where(is.numeric), \n      ~ifelse(value_type == \"mean\", \n              scales::number(.x, accuracy = accuracy_digits),\n              str_c(\"(\", scales::number(.x, accuracy = accuracy_digits), \")\")\n      )\n    )\n  )\n\n\nopts &lt;- options(knitr.kable.NA = \"\")\n\n\nprint_table &lt;- function(scenario) {\n  \n  table_kb &lt;- table_kb |&gt; filter(scenario == !!scenario) |&gt; \n    select(\n      scenario, model,\n      # Max AUC\n      `AUC_AUC*`, `brier_AUC*`, `ici_AUC*`, `kl_AUC*`, `quant_ratio_AUC*`,\n      # Min Brier\n      `AUC_Brier*`, `brier_Brier*`, `ici_Brier*`, `kl_Brier*`, `quant_ratio_Brier*`,\n      diff_AUC_Brier, diff_brier_Brier, diff_ICI_Brier, diff_KL_Brier, diff_quant_ratio_Brier,\n      # Min ICI\n      `AUC_ICI*`, `brier_ICI*`, `ici_ICI*`, `kl_ICI*`, `quant_ratio_ICI*`,\n      diff_AUC_ICI, diff_brier_ICI, diff_ICI_ICI, diff_KL_ICI, diff_quant_ratio_ICI,\n      # Min KL\n      `AUC_KL*`, `brier_KL*`, `ici_KL*`, `kl_KL*`, `quant_ratio_KL*`,\n      diff_AUC_KL, diff_brier_KL, diff_ICI_KL, diff_KL_KL, diff_quant_ratio_KL,\n      # colouring variables\n      diff_AUC_Brier_bgcol, diff_brier_Brier_bgcol, diff_ICI_Brier_bgcol, diff_KL_Brier_bgcol, diff_quant_ratio_Brier_bgcol,\n      #\n      diff_AUC_Brier_txtcol, diff_brier_Brier_txtcol, diff_ICI_Brier_txtcol, diff_KL_Brier_txtcol, diff_quant_ratio_Brier_txtcol,\n      #\n      diff_AUC_ICI_bgcol, diff_brier_ICI_bgcol, diff_ICI_ICI_bgcol, diff_KL_ICI_bgcol, diff_quant_ratio_ICI_bgcol,\n      #\n      diff_AUC_ICI_txtcol, diff_brier_ICI_txtcol, diff_ICI_ICI_txtcol, diff_KL_ICI_txtcol, diff_quant_ratio_ICI_txtcol,\n      #\n      diff_AUC_KL_bgcol, diff_brier_KL_bgcol, diff_ICI_KL_bgcol, diff_KL_KL_bgcol, diff_quant_ratio_KL_bgcol,\n      #\n      diff_AUC_KL_txtcol, diff_brier_KL_txtcol, diff_ICI_KL_txtcol, diff_KL_KL_txtcol, diff_quant_ratio_KL_txtcol\n    )\n  \n  knitr::kable(\n    table_kb |&gt; \n      select(\n        scenario, model,\n        # Max AUC\n        `AUC_AUC*`, `brier_AUC*`, `ici_AUC*`, `kl_AUC*`, `quant_ratio_AUC*`,\n        # Min Brier\n        `AUC_Brier*`, `brier_Brier*`, `ici_Brier*`, `kl_Brier*`, `quant_ratio_Brier*`,\n        diff_AUC_Brier, diff_brier_Brier, diff_ICI_Brier, diff_KL_Brier, diff_quant_ratio_Brier,\n        # Min ICI\n        `AUC_ICI*`, `brier_ICI*`, `ici_ICI*`, `kl_ICI*`, `quant_ratio_ICI*`, \n        diff_AUC_ICI, diff_brier_ICI, diff_ICI_ICI, diff_KL_ICI, diff_quant_ratio_ICI,\n        # Min KL\n        `AUC_KL*`, `brier_KL*`, `ici_KL*`, `kl_KL*`, `quant_ratio_KL*`,\n        diff_AUC_KL, diff_brier_KL, diff_ICI_KL, diff_KL_KL, diff_quant_ratio_KL\n      ),\n    col.names = c(\n      \"Scenario\", \"Model\",\n      # # columns for GLM/GAM/GAMSEL\n      # \"AUC\", \"ICI\", \"KL\", \n      # columns for ML models selected based on AUC\n      \"AUC\", \"Brier\", \"ICI\", \"KL\", \"Quant. Ratio\",\n      # columns for ML models selected based on Brier\n      \"AUC\", \"Brier\", \"ICI\", \"KL\", \"Quant. Ratio\", \"ΔAUC\", \"ΔBrier\", \"ΔICI\", \"ΔKL\", \"ΔQR\",\n      # columns for ML models selected based on ICI\n      \"AUC\", \"Brier\", \"ICI\", \"KL\", \"Quant. Ratio\", \"ΔAUC\", \"ΔBrier\", \"ΔICI\", \"ΔKL\", \"ΔQR\",\n      # columns for ML models selected based on KL dist\n      \"AUC\", \"Brier\", \"ICI\", \"KL\", \"Quant. Ratio\", \"ΔAUC\", \"ΔBrier\",\"ΔICI\", \"ΔKL\", \"ΔQR\"\n    ),\n    align = str_c(\"cl\", str_c(rep(\"c\", 5+10*3), collapse = \"\"), collapse = \"\"),\n    escape = FALSE, booktabs = T, digits = 3, format = \"markdown\") |&gt; \n    # Difference in metrics computed when minnimizing Brier wrt when maximizing AUC\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_AUC_Brier\"),\n      background = table_kb$diff_AUC_Brier_bgcol,\n      color = table_kb$diff_AUC_Brier_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_brier_Brier\"),\n      background = table_kb$diff_brier_Brier_bgcol,\n      color = table_kb$diff_brier_Brier_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_ICI_Brier\"),\n      background = table_kb$diff_ICI_Brier_bgcol,\n      color = table_kb$diff_ICI_Brier_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_KL_Brier\"),\n      background = table_kb$diff_KL_Brier_bgcol,\n      color = table_kb$diff_KL_Brier_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_quant_ratio_Brier\"),\n      background = table_kb$diff_quant_ratio_Brier_bgcol,\n      color = table_kb$diff_quant_ratio_Brier_txtcol\n    ) |&gt;\n    # Difference in metrics computed when minnimizing ICI wrt when maximizing AUC\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_AUC_ICI\"),\n      background = table_kb$diff_AUC_ICI_bgcol,\n      color = table_kb$diff_AUC_ICI_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_brier_ICI\"),\n      background = table_kb$diff_brier_ICI_bgcol,\n      color = table_kb$diff_brier_ICI_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_ICI_ICI\"),\n      background = table_kb$diff_ICI_ICI_bgcol,\n      color = table_kb$diff_ICI_ICI_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_KL_ICI\"),\n      background = table_kb$diff_KL_ICI_bgcol,\n      color = table_kb$diff_KL_ICI_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_quant_ratio_ICI\"),\n      background = table_kb$diff_quant_ratio_ICI_bgcol,\n      color = table_kb$diff_quant_ratio_ICI_txtcol\n    ) |&gt;\n    # Difference in metrics computed when minnimizing KL wrt when maximizing AUC\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_AUC_KL\"),\n      background = table_kb$diff_AUC_KL_bgcol,\n      color = table_kb$diff_AUC_KL_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_brier_KL\"),\n      background = table_kb$diff_brier_KL_bgcol,\n      color = table_kb$diff_brier_KL_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_ICI_KL\"),\n      background = table_kb$diff_ICI_KL_bgcol,\n      color = table_kb$diff_ICI_KL_txtcol\n    ) |&gt;\n    kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_KL_KL\"),\n      background = table_kb$diff_KL_KL_bgcol,\n      color = table_kb$diff_KL_KL_txtcol\n    ) |&gt;\n     kableExtra::column_spec(\n      which(colnames(table_kb) == \"diff_quant_ratio_KL\"),\n      background = table_kb$diff_quant_ratio_KL_bgcol,\n      color = table_kb$diff_quant_ratio_KL_txtcol\n    ) |&gt;\n    kableExtra::collapse_rows(columns = 1:2, valign = \"top\") |&gt;\n    kableExtra::add_header_above(\n      c(\" \" = 2,\n        # \"Generalized Lin. Models\" = 3,\n        \"AUC*\" = 5,\n        \"Brier*\" = 10,\n        \"ICI*\" = 10,\n        \"KL*\" = 10\n      )\n    )\n}\n\n\n\nDGP 1DGP 2DGP 3DGP 4\n\n\n\n01050100\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n1\n\n\nTrees\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.28\n\n\n1.02\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.28\n\n\n1.02\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n1.26\n\n\n0.98\n\n\n-0.02\n\n\n0.00\n\n\n0.00\n\n\n0.98\n\n\n-0.05\n\n\n0.74\n\n\n0.21\n\n\n0.03\n\n\n0.09\n\n\n1.08\n\n\n-0.01\n\n\n0.00\n\n\n0.01\n\n\n-0.20\n\n\n0.06\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.12)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.13)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.54)\n\n\n(0.08)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.43)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.10)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.06\n\n\n1.00\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.05\n\n\n1.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.59\n\n\n0.23\n\n\n0.01\n\n\n2.61\n\n\n0.32\n\n\n-0.17\n\n\n0.03\n\n\n0.00\n\n\n2.55\n\n\n-0.67\n\n\n0.75\n\n\n0.20\n\n\n0.02\n\n\n0.03\n\n\n1.04\n\n\n-0.01\n\n\n0.00\n\n\n0.01\n\n\n-0.03\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.12)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.75)\n\n\n(0.46)\n\n\n(0.11)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.73)\n\n\n(0.43)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n\n\nXGB\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.05\n\n\n0.96\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.04\n\n\n0.97\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.01\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.05\n\n\n0.97\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.01\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.02\n\n\n1.01\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.00\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.00\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 1, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n2\n\n\nTrees\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.27\n\n\n1.02\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.29\n\n\n1.02\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n0.00\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n1.22\n\n\n0.98\n\n\n-0.02\n\n\n0.00\n\n\n0.00\n\n\n0.95\n\n\n-0.04\n\n\n0.74\n\n\n0.21\n\n\n0.03\n\n\n0.09\n\n\n1.08\n\n\n-0.01\n\n\n0.00\n\n\n0.01\n\n\n-0.19\n\n\n0.06\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.12)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.13)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.56)\n\n\n(0.08)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.44)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.10)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.06\n\n\n0.98\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.05\n\n\n0.98\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.00\n\n\n0.61\n\n\n0.23\n\n\n0.01\n\n\n2.26\n\n\n0.40\n\n\n-0.15\n\n\n0.03\n\n\n0.00\n\n\n2.21\n\n\n-0.58\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.05\n\n\n0.02\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.12)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.87)\n\n\n(0.48)\n\n\n(0.12)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.84)\n\n\n(0.45)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n\n\nXGB\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.07\n\n\n0.93\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.05\n\n\n0.95\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.01\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.03\n\n\n0.97\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.03\n\n\n0.75\n\n\n0.20\n\n\n0.02\n\n\n0.01\n\n\n1.02\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.06\n\n\n0.08\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.03)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.04)\n\n\n(-0.02)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.00\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.00\n\n\n1.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 1, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n3\n\n\nTrees\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.27\n\n\n1.02\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.28\n\n\n1.02\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n0.00\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n1.23\n\n\n0.98\n\n\n-0.02\n\n\n0.00\n\n\n0.00\n\n\n0.96\n\n\n-0.05\n\n\n0.74\n\n\n0.21\n\n\n0.03\n\n\n0.09\n\n\n1.08\n\n\n-0.01\n\n\n0.00\n\n\n0.01\n\n\n-0.19\n\n\n0.06\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.12)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.13)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.55)\n\n\n(0.08)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.44)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.10)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.75\n\n\n0.20\n\n\n0.04\n\n\n0.27\n\n\n0.76\n\n\n0.75\n\n\n0.20\n\n\n0.03\n\n\n0.20\n\n\n0.80\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.07\n\n\n0.04\n\n\n0.50\n\n\n0.25\n\n\n0.01\n\n\n3.82\n\n\n0.00\n\n\n-0.25\n\n\n0.05\n\n\n-0.03\n\n\n3.56\n\n\n-0.76\n\n\n0.75\n\n\n0.21\n\n\n0.03\n\n\n0.14\n\n\n0.81\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.12\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.04)\n\n\n(-0.01)\n\n\n\n\nXGB\n\n\n0.76\n\n\n0.20\n\n\n0.02\n\n\n0.09\n\n\n0.91\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.06\n\n\n0.93\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.02\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.04\n\n\n0.96\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.05\n\n\n0.05\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.01\n\n\n1.02\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.08\n\n\n0.10\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.04)\n\n\n(-0.02)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.00\n\n\n1.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.75\n\n\n0.20\n\n\n0.02\n\n\n0.01\n\n\n1.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 1, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n4\n\n\nTrees\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.28\n\n\n1.02\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.29\n\n\n1.02\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n0.00\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n1.22\n\n\n0.98\n\n\n-0.02\n\n\n0.00\n\n\n0.00\n\n\n0.94\n\n\n-0.05\n\n\n0.74\n\n\n0.21\n\n\n0.03\n\n\n0.09\n\n\n1.08\n\n\n-0.01\n\n\n0.00\n\n\n0.01\n\n\n-0.19\n\n\n0.05\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.12)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.13)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.54)\n\n\n(0.08)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.42)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.10)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.75\n\n\n0.21\n\n\n0.07\n\n\n0.59\n\n\n0.57\n\n\n0.74\n\n\n0.21\n\n\n0.06\n\n\n0.47\n\n\n0.61\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.11\n\n\n0.04\n\n\n0.50\n\n\n0.25\n\n\n0.01\n\n\n3.82\n\n\n0.00\n\n\n-0.24\n\n\n0.04\n\n\n-0.06\n\n\n3.23\n\n\n-0.57\n\n\n0.74\n\n\n0.21\n\n\n0.06\n\n\n0.45\n\n\n0.61\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.13\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.08)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.04)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.05)\n\n\n(-0.01)\n\n\n\n\nXGB\n\n\n0.76\n\n\n0.20\n\n\n0.02\n\n\n0.09\n\n\n0.91\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.07\n\n\n0.92\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.01\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.04\n\n\n0.96\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.05\n\n\n0.05\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.01\n\n\n1.02\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.08\n\n\n0.11\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.03)\n\n\n(-0.02)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.00\n\n\n1.02\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.74\n\n\n0.21\n\n\n0.04\n\n\n0.03\n\n\n1.10\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.76\n\n\n0.20\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 1, 100 noise variables)\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n5\n\n\nTrees\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.24\n\n\n1.03\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.23\n\n\n1.03\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.00\n\n\n0.81\n\n\n0.13\n\n\n0.01\n\n\n0.84\n\n\n0.97\n\n\n-0.02\n\n\n0.01\n\n\n0.00\n\n\n0.60\n\n\n-0.06\n\n\n0.82\n\n\n0.13\n\n\n0.03\n\n\n0.06\n\n\n1.07\n\n\n-0.02\n\n\n0.00\n\n\n0.02\n\n\n-0.18\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.39)\n\n\n(0.13)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.29)\n\n\n(0.07)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.08)\n\n\n(-0.02)\n\n\n\n\nRandom Forests\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.04\n\n\n1.01\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.04\n\n\n1.01\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.00\n\n\n0.62\n\n\n0.15\n\n\n0.01\n\n\n2.66\n\n\n0.34\n\n\n-0.22\n\n\n0.03\n\n\n0.00\n\n\n2.62\n\n\n-0.67\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.02\n\n\n1.03\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.02\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.15)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.70)\n\n\n(0.45)\n\n\n(0.15)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.68)\n\n\n(0.42)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n\n\nXGB\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n0.99\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n0.99\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.02\n\n\n1.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n1.01\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.02\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.02\n\n\n0.99\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.02\n\n\n0.04\n\n\n0.92\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 2, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n6\n\n\nTrees\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.24\n\n\n1.03\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.23\n\n\n1.03\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.00\n\n\n0.81\n\n\n0.13\n\n\n0.01\n\n\n0.82\n\n\n0.97\n\n\n-0.02\n\n\n0.01\n\n\n0.00\n\n\n0.58\n\n\n-0.06\n\n\n0.82\n\n\n0.13\n\n\n0.03\n\n\n0.06\n\n\n1.07\n\n\n-0.02\n\n\n0.00\n\n\n0.02\n\n\n-0.18\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.39)\n\n\n(0.13)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.30)\n\n\n(0.07)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.08)\n\n\n(-0.02)\n\n\n\n\nRandom Forests\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.04\n\n\n0.99\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n1.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.00\n\n\n0.61\n\n\n0.15\n\n\n0.01\n\n\n2.65\n\n\n0.32\n\n\n-0.23\n\n\n0.03\n\n\n0.00\n\n\n2.61\n\n\n-0.68\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.01\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.15)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.81)\n\n\n(0.46)\n\n\n(0.15)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.80)\n\n\n(0.44)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n\n\nXGB\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n0.96\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n0.97\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n0.99\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.02\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.02\n\n\n0.99\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.02\n\n\n0.04\n\n\n0.92\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 2, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n7\n\n\nTrees\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.24\n\n\n1.03\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.22\n\n\n1.03\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n-0.01\n\n\n0.81\n\n\n0.13\n\n\n0.01\n\n\n0.83\n\n\n0.97\n\n\n-0.02\n\n\n0.01\n\n\n0.00\n\n\n0.59\n\n\n-0.06\n\n\n0.82\n\n\n0.13\n\n\n0.03\n\n\n0.06\n\n\n1.07\n\n\n-0.02\n\n\n0.00\n\n\n0.02\n\n\n-0.18\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.39)\n\n\n(0.13)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.30)\n\n\n(0.07)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.08)\n\n\n(-0.02)\n\n\n\n\nRandom Forests\n\n\n0.83\n\n\n0.12\n\n\n0.04\n\n\n0.37\n\n\n0.78\n\n\n0.83\n\n\n0.12\n\n\n0.03\n\n\n0.18\n\n\n0.85\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.19\n\n\n0.07\n\n\n0.50\n\n\n0.16\n\n\n0.01\n\n\n3.88\n\n\n0.00\n\n\n-0.33\n\n\n0.04\n\n\n-0.03\n\n\n3.51\n\n\n-0.78\n\n\n0.83\n\n\n0.12\n\n\n0.03\n\n\n0.12\n\n\n0.88\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.26\n\n\n0.10\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.11)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.07)\n\n\n(-0.02)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.14)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(-0.04)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.09)\n\n\n(-0.02)\n\n\n\n\nXGB\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.04\n\n\n0.95\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n0.95\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.01\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n0.98\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.03\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.04\n\n\n0.05\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.06)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.05)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.05)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.06)\n\n\n(-0.01)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.83\n\n\n0.12\n\n\n0.02\n\n\n0.02\n\n\n1.04\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.02\n\n\n0.04\n\n\n0.92\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 2, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n8\n\n\nTrees\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.24\n\n\n1.03\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.22\n\n\n1.03\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.00\n\n\n0.81\n\n\n0.13\n\n\n0.01\n\n\n0.82\n\n\n0.97\n\n\n-0.02\n\n\n0.01\n\n\n0.00\n\n\n0.58\n\n\n-0.06\n\n\n0.82\n\n\n0.13\n\n\n0.03\n\n\n0.06\n\n\n1.07\n\n\n-0.02\n\n\n0.00\n\n\n0.02\n\n\n-0.17\n\n\n0.04\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.09)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.10)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.40)\n\n\n(0.13)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.30)\n\n\n(0.07)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.08)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.82\n\n\n0.13\n\n\n0.07\n\n\n0.84\n\n\n0.60\n\n\n0.82\n\n\n0.13\n\n\n0.05\n\n\n0.53\n\n\n0.71\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n-0.32\n\n\n0.11\n\n\n0.50\n\n\n0.16\n\n\n0.01\n\n\n3.88\n\n\n0.00\n\n\n-0.32\n\n\n0.03\n\n\n-0.06\n\n\n3.04\n\n\n-0.60\n\n\n0.82\n\n\n0.13\n\n\n0.05\n\n\n0.49\n\n\n0.72\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n-0.35\n\n\n0.12\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.11)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.06)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.05)\n\n\n(-0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.14)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(-0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.07)\n\n\n(-0.03)\n\n\n\n\nXGB\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.04\n\n\n0.94\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n0.95\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.01\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n0.98\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.04\n\n\n0.83\n\n\n0.12\n\n\n0.01\n\n\n0.01\n\n\n0.99\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.06\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.01\n\n\n0.03\n\n\n1.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.82\n\n\n0.13\n\n\n0.03\n\n\n0.04\n\n\n1.08\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.84\n\n\n0.12\n\n\n0.02\n\n\n0.04\n\n\n0.92\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 2, 100 noise variables)\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n9\n\n\nTrees\n\n\n0.55\n\n\n0.24\n\n\n0.02\n\n\n1.23\n\n\n0.35\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.29\n\n\n0.36\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.05\n\n\n0.00\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.33\n\n\n0.35\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.10\n\n\n0.00\n\n\n0.52\n\n\n0.27\n\n\n0.13\n\n\n0.05\n\n\n1.00\n\n\n-0.03\n\n\n0.02\n\n\n0.11\n\n\n-1.18\n\n\n0.65\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.22)\n\n\n(0.06)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.23)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.23)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.20)\n\n\n(0.00)\n\n\n\n\nRandom Forests\n\n\n0.68\n\n\n0.22\n\n\n0.02\n\n\n0.12\n\n\n0.81\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.04\n\n\n0.92\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.08\n\n\n0.11\n\n\n0.58\n\n\n0.23\n\n\n0.01\n\n\n1.72\n\n\n0.43\n\n\n-0.10\n\n\n0.01\n\n\n-0.01\n\n\n1.60\n\n\n-0.38\n\n\n0.67\n\n\n0.22\n\n\n0.02\n\n\n0.01\n\n\n1.02\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.11\n\n\n0.21\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.08)\n\n\n(0.10)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.06)\n\n\n(-0.06)\n\n\n(0.09)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(1.58)\n\n\n(0.46)\n\n\n(0.08)\n\n\n(0.01)\n\n\n(-0.01)\n\n\n(1.50)\n\n\n(0.36)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.08)\n\n\n(-0.07)\n\n\n\n\nXGB\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.96\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.96\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.03\n\n\n0.92\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n0.02\n\n\n-0.04\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n1.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.04\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.02)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.00\n\n\n1.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n1.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 3, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n10\n\n\nTrees\n\n\n0.55\n\n\n0.24\n\n\n0.02\n\n\n1.22\n\n\n0.36\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.27\n\n\n0.35\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.06\n\n\n-0.01\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.33\n\n\n0.35\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.11\n\n\n-0.01\n\n\n0.52\n\n\n0.27\n\n\n0.13\n\n\n0.05\n\n\n1.00\n\n\n-0.03\n\n\n0.02\n\n\n0.11\n\n\n-1.17\n\n\n0.64\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.21)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.22)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.23)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.20)\n\n\n(0.00)\n\n\n\n\nRandom Forests\n\n\n0.68\n\n\n0.22\n\n\n0.03\n\n\n0.16\n\n\n0.77\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.04\n\n\n0.90\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n-0.11\n\n\n0.14\n\n\n0.58\n\n\n0.23\n\n\n0.01\n\n\n1.74\n\n\n0.42\n\n\n-0.10\n\n\n0.01\n\n\n-0.02\n\n\n1.58\n\n\n-0.35\n\n\n0.67\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.96\n\n\n-0.01\n\n\n0.00\n\n\n-0.02\n\n\n-0.15\n\n\n0.19\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.09)\n\n\n(0.10)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.08)\n\n\n(-0.06)\n\n\n(0.09)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(1.59)\n\n\n(0.45)\n\n\n(0.08)\n\n\n(0.01)\n\n\n(-0.01)\n\n\n(1.49)\n\n\n(0.36)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.09)\n\n\n(-0.07)\n\n\n\n\nXGB\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.03\n\n\n0.91\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.02\n\n\n0.92\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.01\n\n\n0.67\n\n\n0.22\n\n\n0.01\n\n\n0.04\n\n\n0.90\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n-0.01\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.00\n\n\n1.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.09\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.03)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.00\n\n\n1.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n1.03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 3, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n11\n\n\nTrees\n\n\n0.55\n\n\n0.24\n\n\n0.02\n\n\n1.22\n\n\n0.36\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.27\n\n\n0.36\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.06\n\n\n0.00\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.34\n\n\n0.35\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.12\n\n\n-0.01\n\n\n0.52\n\n\n0.27\n\n\n0.13\n\n\n0.05\n\n\n1.00\n\n\n-0.03\n\n\n0.02\n\n\n0.11\n\n\n-1.17\n\n\n0.64\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.20)\n\n\n(0.06)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.22)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.24)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.19)\n\n\n(0.00)\n\n\n\n\nRandom Forests\n\n\n0.68\n\n\n0.22\n\n\n0.04\n\n\n0.33\n\n\n0.63\n\n\n0.68\n\n\n0.22\n\n\n0.03\n\n\n0.22\n\n\n0.69\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.10\n\n\n0.06\n\n\n0.50\n\n\n0.24\n\n\n0.01\n\n\n3.20\n\n\n0.00\n\n\n-0.17\n\n\n0.02\n\n\n-0.03\n\n\n2.87\n\n\n-0.63\n\n\n0.67\n\n\n0.22\n\n\n0.03\n\n\n0.19\n\n\n0.71\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.14\n\n\n0.07\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.10)\n\n\n(0.06)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.07)\n\n\n(-0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.06)\n\n\n(-0.06)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.07)\n\n\n(-0.03)\n\n\n\n\nXGB\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.05\n\n\n0.87\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.04\n\n\n0.89\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.02\n\n\n0.67\n\n\n0.22\n\n\n0.01\n\n\n0.05\n\n\n0.89\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.02\n\n\n0.67\n\n\n0.22\n\n\n0.02\n\n\n0.00\n\n\n1.01\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.05\n\n\n0.14\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.04)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.03)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n1.03\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.67\n\n\n0.22\n\n\n0.03\n\n\n0.03\n\n\n1.11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 3, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n12\n\n\nTrees\n\n\n0.55\n\n\n0.24\n\n\n0.02\n\n\n1.24\n\n\n0.36\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.29\n\n\n0.35\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.06\n\n\n0.00\n\n\n0.55\n\n\n0.24\n\n\n0.01\n\n\n1.34\n\n\n0.35\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.10\n\n\n-0.01\n\n\n0.52\n\n\n0.27\n\n\n0.13\n\n\n0.05\n\n\n1.00\n\n\n-0.03\n\n\n0.02\n\n\n0.11\n\n\n-1.19\n\n\n0.65\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.23)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.22)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.23)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.22)\n\n\n(0.01)\n\n\n\n\nRandom Forests\n\n\n0.67\n\n\n0.23\n\n\n0.06\n\n\n0.68\n\n\n0.46\n\n\n0.67\n\n\n0.23\n\n\n0.05\n\n\n0.49\n\n\n0.53\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n-0.19\n\n\n0.07\n\n\n0.50\n\n\n0.24\n\n\n0.01\n\n\n3.20\n\n\n0.00\n\n\n-0.17\n\n\n0.02\n\n\n-0.05\n\n\n2.52\n\n\n-0.46\n\n\n0.67\n\n\n0.23\n\n\n0.05\n\n\n0.46\n\n\n0.54\n\n\n-0.01\n\n\n0.00\n\n\n-0.02\n\n\n-0.22\n\n\n0.08\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.12)\n\n\n(0.04)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.08)\n\n\n(-0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.04)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.08)\n\n\n(-0.04)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.09)\n\n\n(-0.03)\n\n\n\n\nXGB\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.06\n\n\n0.85\n\n\n0.68\n\n\n0.22\n\n\n0.01\n\n\n0.05\n\n\n0.87\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.02\n\n\n0.67\n\n\n0.22\n\n\n0.01\n\n\n0.06\n\n\n0.88\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.01\n\n\n0.03\n\n\n0.67\n\n\n0.22\n\n\n0.02\n\n\n0.00\n\n\n1.01\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.06\n\n\n0.16\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.04)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.05)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.03)\n\n\n(-0.03)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.68\n\n\n0.22\n\n\n0.02\n\n\n0.01\n\n\n1.05\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.66\n\n\n0.23\n\n\n0.05\n\n\n0.09\n\n\n1.20\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.69\n\n\n0.22\n\n\n0.01\n\n\n0.01\n\n\n0.93\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 3, 100 noise variables)\n\n\n\n\n\n\n\n\n01050100\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n13\n\n\nTrees\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.49\n\n\n0.69\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.53\n\n\n0.68\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.04\n\n\n0.00\n\n\n0.64\n\n\n0.23\n\n\n0.01\n\n\n1.23\n\n\n0.63\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n0.74\n\n\n-0.06\n\n\n0.62\n\n\n0.25\n\n\n0.11\n\n\n0.05\n\n\n1.01\n\n\n-0.04\n\n\n0.02\n\n\n0.09\n\n\n-0.44\n\n\n0.33\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.15)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.16)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.29)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.14)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.14)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.04\n\n\n0.95\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.04\n\n\n0.95\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.58\n\n\n0.24\n\n\n0.01\n\n\n2.52\n\n\n0.31\n\n\n-0.16\n\n\n0.03\n\n\n0.00\n\n\n2.48\n\n\n-0.64\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.01\n\n\n1.03\n\n\n-0.01\n\n\n0.00\n\n\n0.01\n\n\n-0.03\n\n\n0.08\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.11)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.75)\n\n\n(0.45)\n\n\n(0.11)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.73)\n\n\n(0.42)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n\n\nXGB\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.04\n\n\n0.96\n\n\n0.75\n\n\n0.20\n\n\n0.01\n\n\n0.04\n\n\n0.96\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.05\n\n\n0.94\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n-0.01\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.01\n\n\n1.03\n\n\n0.00\n\n\n0.00\n\n\n0.01\n\n\n-0.03\n\n\n0.07\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.68\n\n\n0.23\n\n\n0.01\n\n\n0.27\n\n\n0.67\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n0.08\n\n\n0.88\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.73\n\n\n0.21\n\n\n0.02\n\n\n0.14\n\n\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 4, 0 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n14\n\n\nTrees\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.48\n\n\n0.69\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.53\n\n\n0.69\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.05\n\n\n0.00\n\n\n0.64\n\n\n0.23\n\n\n0.01\n\n\n1.23\n\n\n0.63\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n0.75\n\n\n-0.06\n\n\n0.62\n\n\n0.25\n\n\n0.11\n\n\n0.05\n\n\n1.01\n\n\n-0.04\n\n\n0.02\n\n\n0.09\n\n\n-0.44\n\n\n0.33\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.14)\n\n\n(0.06)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.15)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.29)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.15)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.13)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.06\n\n\n0.93\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.05\n\n\n0.93\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.59\n\n\n0.24\n\n\n0.01\n\n\n2.45\n\n\n0.32\n\n\n-0.16\n\n\n0.03\n\n\n0.00\n\n\n2.39\n\n\n-0.60\n\n\n0.73\n\n\n0.21\n\n\n0.02\n\n\n0.01\n\n\n0.96\n\n\n-0.01\n\n\n0.00\n\n\n0.00\n\n\n-0.04\n\n\n0.03\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.11)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.77)\n\n\n(0.44)\n\n\n(0.11)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(1.75)\n\n\n(0.42)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n\n\nXGB\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.08\n\n\n0.89\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.07\n\n\n0.90\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.01\n\n\n0.02\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.06\n\n\n0.92\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.04\n\n\n0.73\n\n\n0.21\n\n\n0.03\n\n\n0.02\n\n\n1.04\n\n\n-0.01\n\n\n0.00\n\n\n0.02\n\n\n-0.07\n\n\n0.15\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(-0.01)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.68\n\n\n0.23\n\n\n0.01\n\n\n0.26\n\n\n0.67\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n0.07\n\n\n0.90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.73\n\n\n0.21\n\n\n0.02\n\n\n0.14\n\n\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 4, 10 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n15\n\n\nTrees\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.49\n\n\n0.69\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.53\n\n\n0.68\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.04\n\n\n-0.01\n\n\n0.64\n\n\n0.23\n\n\n0.01\n\n\n1.23\n\n\n0.63\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n0.74\n\n\n-0.06\n\n\n0.62\n\n\n0.25\n\n\n0.11\n\n\n0.05\n\n\n1.01\n\n\n-0.04\n\n\n0.02\n\n\n0.09\n\n\n-0.44\n\n\n0.32\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.15)\n\n\n(0.05)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.16)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.31)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.15)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.14)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.73\n\n\n0.21\n\n\n0.04\n\n\n0.34\n\n\n0.66\n\n\n0.73\n\n\n0.21\n\n\n0.04\n\n\n0.32\n\n\n0.67\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.01\n\n\n0.50\n\n\n0.25\n\n\n0.01\n\n\n3.74\n\n\n0.00\n\n\n-0.23\n\n\n0.04\n\n\n-0.04\n\n\n3.40\n\n\n-0.66\n\n\n0.73\n\n\n0.21\n\n\n0.04\n\n\n0.30\n\n\n0.67\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.04\n\n\n0.01\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.02)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(0.00)\n\n\n\n\nXGB\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.12\n\n\n0.84\n\n\n0.74\n\n\n0.21\n\n\n0.01\n\n\n0.10\n\n\n0.87\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.02\n\n\n0.02\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n0.07\n\n\n0.91\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.06\n\n\n0.07\n\n\n0.72\n\n\n0.21\n\n\n0.03\n\n\n0.02\n\n\n1.03\n\n\n-0.02\n\n\n0.01\n\n\n0.02\n\n\n-0.11\n\n\n0.19\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.03)\n\n\n(-0.02)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.67\n\n\n0.23\n\n\n0.01\n\n\n0.24\n\n\n0.69\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.72\n\n\n0.22\n\n\n0.02\n\n\n0.04\n\n\n0.94\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.73\n\n\n0.21\n\n\n0.02\n\n\n0.14\n\n\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 4, 50 noise variables)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\n\n\nBrier*\n\n\n\n\nICI*\n\n\n\n\nKL*\n\n\n\n\n\nScenario\n\n\nModel\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\nAUC\n\n\nBrier\n\n\nICI\n\n\nKL\n\n\nQuant. Ratio\n\n\nΔAUC\n\n\nΔBrier\n\n\nΔICI\n\n\nΔKL\n\n\nΔQR\n\n\n\n\n\n\n16\n\n\nTrees\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.48\n\n\n0.69\n\n\n0.65\n\n\n0.23\n\n\n0.02\n\n\n0.53\n\n\n0.68\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n0.05\n\n\n0.00\n\n\n0.64\n\n\n0.23\n\n\n0.01\n\n\n1.23\n\n\n0.63\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n0.75\n\n\n-0.05\n\n\n0.62\n\n\n0.25\n\n\n0.11\n\n\n0.05\n\n\n1.01\n\n\n-0.04\n\n\n0.02\n\n\n0.09\n\n\n-0.44\n\n\n0.33\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.15)\n\n\n(0.06)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.16)\n\n\n(0.06)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.29)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.14)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(-0.14)\n\n\n(-0.01)\n\n\n\n\nRandom Forests\n\n\n0.72\n\n\n0.22\n\n\n0.07\n\n\n0.72\n\n\n0.48\n\n\n0.72\n\n\n0.22\n\n\n0.07\n\n\n0.67\n\n\n0.49\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.05\n\n\n0.01\n\n\n0.50\n\n\n0.25\n\n\n0.01\n\n\n3.74\n\n\n0.00\n\n\n-0.21\n\n\n0.03\n\n\n-0.07\n\n\n3.02\n\n\n-0.48\n\n\n0.72\n\n\n0.22\n\n\n0.07\n\n\n0.65\n\n\n0.49\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.06\n\n\n0.01\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.05)\n\n\n(0.02)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.05)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.02)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.02)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(0.00)\n\n\n\n\nXGB\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.14\n\n\n0.82\n\n\n0.74\n\n\n0.21\n\n\n0.02\n\n\n0.11\n\n\n0.85\n\n\n0.00\n\n\n0.00\n\n\n0.00\n\n\n-0.03\n\n\n0.02\n\n\n0.73\n\n\n0.21\n\n\n0.01\n\n\n0.07\n\n\n0.90\n\n\n-0.01\n\n\n0.00\n\n\n-0.01\n\n\n-0.07\n\n\n0.08\n\n\n0.72\n\n\n0.22\n\n\n0.04\n\n\n0.02\n\n\n1.03\n\n\n-0.02\n\n\n0.01\n\n\n0.02\n\n\n-0.12\n\n\n0.21\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.04)\n\n\n(0.04)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.03)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.01)\n\n\n(-0.01)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(-0.03)\n\n\n(-0.02)\n\n\n\n\nGLM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.67\n\n\n0.23\n\n\n0.01\n\n\n0.22\n\n\n0.71\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.00)\n\n\n(0.03)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAM\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.71\n\n\n0.22\n\n\n0.04\n\n\n0.02\n\n\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGAMSEL\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.73\n\n\n0.21\n\n\n0.02\n\n\n0.14\n\n\n0.79\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(0.01)\n\n\n(0.00)\n\n\n(0.01)\n\n\n(0.02)\n\n\n(0.02)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of metrics for models chosen based on AUC, on Brier Score, on ICI, or on KL divergence (DGP 4, 100 noise variables)",
    "crumbs": [
      "Simulated Data",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Comparison of Models</span>"
    ]
  },
  {
    "objectID": "book_real_example.html",
    "href": "book_real_example.html",
    "title": "13  Priors: Illustration",
    "section": "",
    "text": "13.1 Raw Data\nTo illustrate the process, we use the spambase dataset (available on UCI Machine Learning Repository). The dataset contains 4,601 rows. The target variable, is_spam will be explained using the 57 continuous predictors.\nThe dataset can be downloaded as follows:\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = \"https://archive.ics.uci.edu/static/public/94/spambase.zip\", \n  destfile = \"data/spambase.zip\"\n)\nThe names of the columns are given in the spambase.names file in that archive.\n# This chunk is not run\ninfo_data &lt;- scan(\n  unz(\"data/spambase.zip\", \"spambase.names\"), what = \"character\", sep = \"\\n\"\n)\n# Print the names for this dataset (not very convenient...)\nstr_extract(info_data[31:length(info_data)], \"^(.*):\") |&gt; \n  str_remove(\":$\") |&gt; \n  (\\(.x) str_c('\"', .x, '\",'))() |&gt; \n  cat()\nThen, we can import the dataset:\ndataset &lt;- read_csv(\n  file = unz(\"data/spambase.zip\", \"spambase.data\"),\n  col_names = c(\n    \"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\",\n    \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\",\n    \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\",\n    \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\", \n    \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\",\n    \"word_freq_credit\", \"word_freq_your\", \"word_freq_font\", \"word_freq_000\",\n    \"word_freq_money\", \"word_freq_hp\", \"word_freq_hpl\", \"word_freq_george\",\n    \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\",\n    \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\",\n    \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\",\n    \"word_freq_direct\", \"word_freq_cs\", \"word_freq_meeting\", \n    \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \"word_freq_edu\",\n    \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\",\n    \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_#\",\n    \"capital_run_length_average\", \"capital_run_length_longest\",\n    \"capital_run_length_total\", \"is_spam\"\n  )\n)\n\nRows: 4601 Columns: 58\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (58): word_freq_make, word_freq_address, word_freq_all, word_freq_3d, wo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\nThe target variable is is_spam.\ntarget_name &lt;- \"is_spam\"",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Priors: Illustration</span>"
    ]
  },
  {
    "objectID": "book_real_example.html#data-pre-processing",
    "href": "book_real_example.html#data-pre-processing",
    "title": "13  Priors: Illustration",
    "section": "13.2 Data Pre-processing",
    "text": "13.2 Data Pre-processing\nWe define two functions to pre-process the data. The first one, split_train_test() simply split the dataset into two subsets: one for training the models (train) and another one for testing the models (test).\n\n#' Split dataset into train and test set\n#'\n#' @param data dataset\n#' @param prop_train proportion in the train test (default to .8)\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns a list with two elements: the train set, the test set\nsplit_train_test &lt;- function(data,\n                             prop_train = .8,\n                             seed = NULL) {\n  if (!is.null(seed)) set.seed(seed)\n  size_train &lt;- round(prop_train * nrow(data))\n  ind_sample &lt;- sample(1:nrow(data), replace = FALSE, size = size_train)\n\n  list(\n    train = data |&gt; dplyr::slice(ind_sample),\n    test = data |&gt; dplyr::slice(-ind_sample)\n  )\n}\n\nWith the current dataset:\n\ndata &lt;- split_train_test(data = dataset, prop_train = .8, seed = 1234)\nnames(data)\n\n[1] \"train\" \"test\" \n\n\nSome of the models we use need the data to be numerical. We thus build a function, encode_dataset() that transforms the categorical columns into sets of dummy variables. For each categorical variable, we remove one of the levels to avoid colinearity in the predictor matrix. This step is made using the convenient functions from the {recipes} package. In addition, the spline function from the {gam} package does not support variables with names that do not respect the R naming conventions. We thus rename all the variables and keep track of the changes.\nThe encode_dataset() returns a list with five elements:\n\ntrain: the train set where categorical variables have been transformed into dummy variables\ntest: the test set where categorical variables have been transformed into dummy variables\ninitial_covariate_names: vector of names of all explanatory variables\ncateg_names: vector of new names of categorical variables (if any)\ncovariate_names: vector of new names of all explanatory variables (including categorigal ones).\n\n\n#' One-hot encoding, and renaming variables to avoid naming that do not respect\n#' r old naming conventions\n#'\n#' @param data_train train set\n#' @param data_test test set\n#' @param target_name name of the target (response) variable\n#' @param intercept should a column for an intercept be added? Default to\n#'  `FALSE`\n#'\n#' @returns list with five elements:\n#'  - `train`: train set\n#'  - `test`: test set\n#'  - `initial_covariate_names`: vector of names of all explanatory variables\n#'  - `categ_names`: vector of new names of categorical variables (if any)\n#'  - `covariate_names`: vector of new names of all explanatory variables (including\n#'     categorical ones).\nencode_dataset &lt;- function(data_train,\n                           data_test,\n                           target_name,\n                           intercept = FALSE) {\n\n  col_names &lt;- colnames(data_train)\n  col_names_covariates &lt;- col_names[-which(col_names == target_name)]\n  new_names_covariates &lt;- str_c(\"X_\", 1:length(col_names_covariates))\n  data_train &lt;- data_train |&gt;\n    rename_with(.cols = all_of(col_names_covariates), .fn = ~new_names_covariates)\n  data_test &lt;- data_test |&gt;\n    rename_with(.cols = all_of(col_names_covariates), .fn = ~new_names_covariates)\n\n  data_rec &lt;- recipes::recipe(\n    formula(str_c(target_name, \" ~ .\")),\n    data = data_train\n  )\n\n  ref_cell &lt;- data_rec |&gt; recipes::step_dummy(\n    recipes::all_nominal(), -recipes::all_outcomes(),\n    one_hot = TRUE\n  ) |&gt;\n    recipes::prep(training = data_train)\n\n  X_train_dmy &lt;- recipes::bake(ref_cell, new_data = data_train)\n  X_test_dmy  &lt;- recipes::bake(ref_cell, new_data = data_test)\n\n  # Identify categorical variables\n  # Bake the recipe to apply the transformation\n  df_transformed &lt;- recipes::bake(ref_cell, new_data = NULL)\n  # Get the names of the transformed data\n  new_names &lt;- names(X_train_dmy)\n  original_vars &lt;- names(data_train)\n  categ_names &lt;- setdiff(new_names, original_vars)\n  covariate_names &lt;- colnames(X_train_dmy)\n  covariate_names &lt;- covariate_names[!covariate_names == target_name]\n  categ_names &lt;- categ_names[!categ_names == target_name]\n  list(\n    train = X_train_dmy,\n    test = X_test_dmy,\n    initial_covariate_names = col_names_covariates,\n    categ_names = categ_names,\n    covariate_names = covariate_names\n  )\n}\n\nLet us use the encode_dataset() function to rename the columns here. As there is no categorical variable among the predictors, no dummy variable will be created.\n\ndata_dmy &lt;- encode_dataset(\n  data_train = data$train,\n  data_test = data$test,\n  target_name = target_name,\n  intercept = FALSE\n)",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Priors: Illustration</span>"
    ]
  },
  {
    "objectID": "book_real_example.html#estimation-functions",
    "href": "book_real_example.html#estimation-functions",
    "title": "13  Priors: Illustration",
    "section": "13.3 Estimation Functions",
    "text": "13.3 Estimation Functions\n\n13.3.1 GLM\nLet us estimate the probability that the event occurs (the email is a spam) using a Generalized Linear Model with a logistic link function.\nWe first build the formula:\n\nform &lt;- str_c(target_name, \"~.\") |&gt; as.formula()\n\nThen, we fit the model:\n\nfit &lt;- glm(form, data = data_dmy$train, family = \"binomial\")\n\nLastly, we can get the predicted scores:\n\nscores_train &lt;- predict(fit, newdata = data_dmy$train, type = \"response\")\nscores_test &lt;- predict(fit, newdata = data_dmy$test, type = \"response\")\n\nWe encompass these steps in a helper function:\n\n#' Train a GLM-logistic model\n#'\n#' @param data_train train set\n#' @param data_test test set\n#' @param target_name name of the target (response) variable\n#' @param return_model if TRUE, the estimated model is returned\n#'\n#' @returns list with estimated scores on train set (`scores_train`) and on\n#'  test set (`scores_test`)\ntrain_glm &lt;- function(data_train,\n                      data_test,\n                      target_name,\n                      return_model = FALSE) {\n  # Encode dataset so that categorical variables become dummy variables\n  data_dmy &lt;- encode_dataset(\n    data_train = data_train,\n    data_test = data_test,\n    target_name = target_name,\n    intercept = FALSE\n  )\n  # Formula for the model\n  form &lt;- str_c(target_name, \"~.\") |&gt; as.formula()\n  # Estimation\n  fit &lt;- glm(form, data = data_dmy$train, family = \"binomial\")\n  # Scores on train and test set\n  scores_train &lt;- predict(fit, newdata = data_dmy$train, type = \"response\")\n  scores_test &lt;- predict(fit, newdata = data_dmy$test, type = \"response\")\n\n  if (return_model == TRUE) {\n    res &lt;- list(\n      scores_train = scores_train, \n      scores_test = scores_test, \n      fit = fit)\n  } else {\n    list(scores_train = scores_train, scores_test = scores_test, fit = NULL)\n  }\n}\n\nThis function can then be used in a very simple way:\n\nscores_glm &lt;- train_glm(\n    data_train = data$train, data_test = data$test, target_name = target_name\n  )\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\n\n\n13.3.2 GAM\nWe then estimate the probability that the event occurs (the email is a spam) using a Generalized Additive Model.\nWe first build the formula. Here, this is a tiny bit more complex than with the GLM. The model will contain smooth terms (for numerical variables) and linear terms (for categorical variables which, if present in the data, were encoded as dummy variables).\nWe identify the numerical variables\n\nnum_names &lt;- data_dmy$covariate_names[!data_dmy$covariate_names %in% data_dmy$categ_names]\nnum_names &lt;- num_names[!num_names %in% target_name]\n\nThen, we count the number of unique values for each variable. This step ensures that the smoothing parameter of the spline function applied to numerical variables is not larger than the number of unique values. We arbitrarily set the smoothing parameter to 6. But if the number of unique values for a variable is lower than this, then we use the number of unique values minus 1 as the smoothing parameter for that variable.\n\nspline_df &lt;- 6\nnum_nb_val &lt;- map_dbl(num_names, ~data_dmy$train |&gt; pull(.x) |&gt; unique() |&gt; length())\ndeg_num &lt;- ifelse(num_nb_val &lt; spline_df, num_nb_val, spline_df)\n\nThen, we can construct the formula object. We begin with the numerical variables:\n\nnum_term &lt;- str_c(\"s(\", num_names, \", df = \", deg_num, \")\", collapse = \" + \")\n\nNote: if there are no numerical variables, the num_term is simply set to NULL.\nIf there are categorical variables, we do not use a smoothing function for them.\n\nif (length(data_dmy$categ_names &gt; 0)) {\n  categ_terms &lt;- str_c(data_dmy$categ_names, collapse = \" + \")\n} else {\n  categ_terms &lt;- NULL\n}\n\nLastly, we can create the whole part of the formula which contains the predictors:\n\nform_terms &lt;- str_c(num_term, categ_terms, sep = \" + \")\n\nThe formula can eventually be created:\n\nform_gam &lt;- str_c(target_name, \" ~ \", form_terms) |&gt; as.formula()\nform_gam\n\nis_spam ~ s(X_1, df = 6) + s(X_2, df = 6) + s(X_3, df = 6) + \n    s(X_4, df = 6) + s(X_5, df = 6) + s(X_6, df = 6) + s(X_7, \n    df = 6) + s(X_8, df = 6) + s(X_9, df = 6) + s(X_10, df = 6) + \n    s(X_11, df = 6) + s(X_12, df = 6) + s(X_13, df = 6) + s(X_14, \n    df = 6) + s(X_15, df = 6) + s(X_16, df = 6) + s(X_17, df = 6) + \n    s(X_18, df = 6) + s(X_19, df = 6) + s(X_20, df = 6) + s(X_21, \n    df = 6) + s(X_22, df = 6) + s(X_23, df = 6) + s(X_24, df = 6) + \n    s(X_25, df = 6) + s(X_26, df = 6) + s(X_27, df = 6) + s(X_28, \n    df = 6) + s(X_29, df = 6) + s(X_30, df = 6) + s(X_31, df = 6) + \n    s(X_32, df = 6) + s(X_33, df = 6) + s(X_34, df = 6) + s(X_35, \n    df = 6) + s(X_36, df = 6) + s(X_37, df = 6) + s(X_38, df = 6) + \n    s(X_39, df = 6) + s(X_40, df = 6) + s(X_41, df = 6) + s(X_42, \n    df = 6) + s(X_43, df = 6) + s(X_44, df = 6) + s(X_45, df = 6) + \n    s(X_46, df = 6) + s(X_47, df = 6) + s(X_48, df = 6) + s(X_49, \n    df = 6) + s(X_50, df = 6) + s(X_51, df = 6) + s(X_52, df = 6) + \n    s(X_53, df = 6) + s(X_54, df = 6) + s(X_55, df = 6) + s(X_56, \n    df = 6) + s(X_57, df = 6)\n\n\nThen, we fit the model:\n\nfit &lt;- gam::gam(formula = form_gam, family = binomial, data = data_dmy$train)\n\nLastly, we can get the predicted scores:\n\nscores_train &lt;- predict(fit, newdata = data_dmy$train, type = \"response\")\nscores_test &lt;- predict(fit, newdata = data_dmy$test, type = \"response\")\n\nWe encompass these steps in a helper function:\n\n#' Train a GAM model\n#'\n#' @param data_train train set\n#' @param data_test test set\n#' @param target_name name of the target (response) variable\n#' @param spline_df degree of freedom for the splines\n#' @param return_model if TRUE, the estimated model is returned\n#'\n#' @returns list with estimated scores on train set (`scores_train`) and on\n#'  test set (`scores_test`)\ntrain_gam &lt;- function(data_train,\n                      data_test,\n                      target_name,\n                      spline_df = 5,\n                      return_model = FALSE) {\n  # Encode dataset so that categorical variables become dummy variables\n  data_dmy &lt;- encode_dataset(\n    data_train = data_train,\n    data_test = data_test,\n    target_name = target_name,\n    intercept = FALSE\n  )\n\n  # Formula for the model\n  ## Names of numerical variables\n  num_names &lt;- data_dmy$covariate_names[!data_dmy$covariate_names %in% data_dmy$categ_names]\n  num_names &lt;- num_names[!num_names %in% target_name]\n  if (length(num_names) &gt; 0) {\n    ## Number of unique values\n    num_nb_val &lt;- map_dbl(num_names, ~data_dmy$train |&gt; pull(.x) |&gt; unique() |&gt; length())\n    ## Degree for numerical variables\n    deg_num &lt;- ifelse(num_nb_val &lt; spline_df, num_nb_val, spline_df)\n    num_term &lt;- str_c(\"s(\", num_names, \", df = \", deg_num, \")\", collapse = \" + \")\n  } else {\n    num_term &lt;- NULL\n  }\n  if (length(data_dmy$categ_names &gt; 0)) {\n    categ_terms &lt;- str_c(data_dmy$categ_names, collapse = \" + \")\n  } else {\n    categ_terms &lt;- NULL\n  }\n  \n  form_terms &lt;- str_c(num_term, categ_terms, sep = \" + \")\n  \n  form_gam &lt;- str_c(target_name, \" ~ \", form_terms) |&gt; as.formula()\n  # Estimation\n  fit &lt;- gam::gam(formula = form_gam, family = binomial, data = data_dmy$train)\n  # Scores on train and test set\n  scores_train &lt;- predict(fit, newdata = data_dmy$train, type = \"response\")\n  scores_test &lt;- predict(fit, newdata = data_dmy$test, type = \"response\")\n\n  if (return_model == TRUE) {\n    res &lt;- list(\n      scores_train = scores_train,\n      scores_test = scores_test,\n      fit = fit)\n  } else {\n    list(scores_train = scores_train, scores_test = scores_test, fit = NULL)\n  }\n}\n\nThis function can then be used in a very simple way:\n\nscores_gam &lt;- train_gam(\n    data_train = data$train, data_test = data$test, target_name = target_name,\n    spline_df = 6\n)\n\n\n\n13.3.3 GAMSEL\nWe then estimate the probability that the event occurs (the email is a spam) using a Generalized Additive Model with model selection.\nFirst, we need to split the target variable and the predictors in distinct objects.\n\nX_dmy_train &lt;- data_dmy$train |&gt; dplyr::select(-!!target_name)\nX_dmy_test &lt;- data_dmy$test |&gt; dplyr::select(-!!target_name)\n\nThen, we need to make sure that all variables obtained after using the encode_dataset() function are coded as numeric: the estimation function from {gamsel} does not allow integer variables.\n\nX_dmy_train &lt;- X_dmy_train |&gt; mutate(across(everything(), as.numeric))\nX_dmy_test &lt;- X_dmy_test |&gt; mutate(across(everything(), as.numeric))\n\nThe target variable:\n\ny_train &lt;- data_dmy$train |&gt; dplyr::pull(!!target_name)\ny_test &lt;- data_dmy$test |&gt; dplyr::pull(!!target_name)\n\nThen we need to build the formula. As for the GAM, this is a bit more complex that with the GLM. We need to create a vector that gives the maximum spline basis function to use for each variable. For dummy variables, this needs to be set to 1. For other variables, let us use either 6 or the minimum number of distinct values minus 1.\n\ndegrees &lt;- 6\ndeg &lt;- rep(NA, ncol(X_dmy_train))\ncol_names_X &lt;- colnames(X_dmy_train)\nnb_val &lt;- map_dbl(\n  col_names_X, ~X_dmy_train |&gt; pull(.x) |&gt; unique() |&gt; length()\n)\nfor (i_var_name in 1:ncol(X_dmy_train)) {\n  var_name &lt;- col_names_X[i_var_name]\n  if (var_name %in% data_dmy$categ_names) {\n    deg[i_var_name] &lt;- 1\n  } else {\n    deg[i_var_name] &lt;- min(nb_val[i_var_name]-1, degrees)\n  }\n}\n\nThen, we fit the model. The penalty parameter \\(\\lambda\\) is selected by 10-fold cross validation in a first step:\n\ngamsel_cv &lt;- gamsel::cv.gamsel(\n  x = as.data.frame(X_dmy_train), y = y_train, family = \"binomial\",\n  degrees = deg\n)\n\nWe use the value of lambda which gives the minimum cross validation metric. Note that we could also use the largest value of lambda such that the error is within 1 standard error of the minimum (using lambda = gamsel_cv$lambda.1se):\n\ngamsel_out &lt;- gamsel(\n  x = as.data.frame(X_dmy_train), y = y_train, family = \"binomial\",\n  degrees = deg,\n  lambda = gamsel_cv$lambda.min\n)\n\nLastly, we can get the predicted scores:\n\nscores_train &lt;- predict(\n    gamsel_out, newdata = as.data.frame(X_dmy_train), type = \"response\")[, 1]\n  scores_test &lt;- predict(\n    gamsel_out, newdata = as.data.frame(X_dmy_test), type = \"response\")[, 1]\n\nWe encompass these steps in a helper function:\n\n#' Train a GAMSEL model\n#'\n#' @param data_train train set\n#' @param data_test test set\n#' @param target_name name of the target (response) variable\n#' @param degrees degree for the splines\n#' @param return_model if TRUE, the estimated model is returned\n#'\n#' @returns list with estimated scores on train set (`scores_train`) and on\n#'  test set (`scores_test`)\ntrain_gamsel &lt;- function(data_train,\n                         data_test,\n                         target_name,\n                         degrees = 6,\n                         return_model = FALSE) {\n  # Encode dataset so that categorical variables become dummy variables\n  data_dmy &lt;- encode_dataset(\n    data_train = data_train,\n    data_test = data_test,\n    target_name = target_name,\n    intercept = FALSE\n  )\n  # Estimation\n  X_dmy_train &lt;- data_dmy$train |&gt; dplyr::select(-!!target_name)\n  X_dmy_train &lt;- X_dmy_train |&gt; mutate(across(everything(), as.numeric))\n  X_dmy_test &lt;- data_dmy$test |&gt; dplyr::select(-!!target_name)\n  X_dmy_test &lt;- X_dmy_test |&gt; mutate(across(everything(), as.numeric))\n  y_train &lt;- data_dmy$train |&gt; dplyr::pull(!!target_name)\n  y_test &lt;- data_dmy$test |&gt; dplyr::pull(!!target_name)\n\n  deg &lt;- rep(NA, ncol(X_dmy_train))\n  col_names_X &lt;- colnames(X_dmy_train)\n  nb_val &lt;- map_dbl(\n    col_names_X, ~X_dmy_train |&gt; pull(.x) |&gt; unique() |&gt; length()\n  )\n  for (i_var_name in 1:ncol(X_dmy_train)) {\n    var_name &lt;- col_names_X[i_var_name]\n    if (var_name %in% data_dmy$categ_names) {\n      deg[i_var_name] &lt;- 1\n    } else {\n      deg[i_var_name] &lt;- min(nb_val[i_var_name]-1, degrees)\n    }\n  }\n  gamsel_cv &lt;- gamsel::cv.gamsel(\n    x = as.data.frame(X_dmy_train), y = y_train, family = \"binomial\",\n    degrees = deg\n  )\n  gamsel_out &lt;- gamsel::gamsel(\n    x = as.data.frame(X_dmy_train), y = y_train, family = \"binomial\",\n    degrees = deg,\n    lambda = gamsel_cv$lambda.min\n  )\n  # Scores on train and test set\n  scores_train &lt;- predict(\n    gamsel_out, newdata = as.data.frame(X_dmy_train), type = \"response\")[, 1]\n  scores_test &lt;- predict(\n    gamsel_out, newdata = as.data.frame(X_dmy_test), type = \"response\")[, 1]\n\n  if (return_model == TRUE) {\n    res &lt;- list(\n      scores_train = scores_train,\n      scores_test = scores_test,\n      fit = fit)\n  } else {\n    list(scores_train = scores_train, scores_test = scores_test, fit = NULL)\n  }\n}\n\nThis function can then be used in a very simple way:\n\nscores_gamsel &lt;- train_gamsel(\n    data_train = data$train, data_test = data$test, target_name = target_name,\n    degrees = 6\n  )",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Priors: Illustration</span>"
    ]
  },
  {
    "objectID": "book_real_example.html#fitting-a-beta-distribution",
    "href": "book_real_example.html#fitting-a-beta-distribution",
    "title": "13  Priors: Illustration",
    "section": "13.4 Fitting a Beta Distribution",
    "text": "13.4 Fitting a Beta Distribution\nOnce the scores from the models have been estimated, we fit a Beta distribution to them. This will provide a prior distribution of the true probabilities in the exercise.\nTo avoid crashing the ML estimation of the two parameters of the Beta distribution, let us make sure that any score is in \\((0,1)\\) and not exactly equal to 0 or 1.\n\nx_glm &lt;- (scores_glm$scores_test * (1 - 1e-6)) + 1e-6 / 2\nx_gam &lt;- (scores_gam$scores_test * (1 - 1e-6)) + 1e-6 / 2\nx_gamsel &lt;- (scores_gamsel$scores_test * (1 - 1e-6)) + 1e-6 / 2\n\nTo estimate the two parameters of the Beta distribution, we define a small function, fit_beta_scores() that calls the fitdistr() function from {MASS}.\n\n#' Maximum-likelihood fitting of Beta distribution on scores\n#'\n#' @param scores vector of estimated scores\n#' @param shape1 non-negative first parameter of the Beta distribution\n#' @param shape1 non-negative second parameter of the Beta distribution\n#'\n#' @returns An object of class `fitdistr`, a list with four components\n#'  (see: MASS::fitdistr())\n#'  - `estimate`: the parameter estimates\n#'  - `sd`: the estimated standard errors\n#'  - `vcov`: the estimated variance-covariance matrix\n#'  - `loglik`: the log-likelihood\nfit_beta_scores &lt;- function(scores, shape1 = 1, shape2 = 1) {\n  # Fit a beta distribution\n  mle_fit &lt;- MASS::fitdistr(\n    scores, \"beta\", start = list(shape1 = 1, shape2 = 1)\n  )\n  mle_fit\n}\n\n\n(mle_gam &lt;- fit_beta_scores(scores = x_gam))\n\n     shape1        shape2   \n  0.062913176   0.081751894 \n (0.002447438) (0.003470926)\n\n(mle_glm &lt;- fit_beta_scores(scores = x_glm))\n\n     shape1        shape2   \n  0.141335615   0.210571524 \n (0.005452414) (0.009260466)\n\n(mle_gamsel &lt;- fit_beta_scores(scores = x_gamsel[!is.nan(x_gamsel)]))\n\n     shape1       shape2  \n  0.42945278   0.51642775 \n (0.01755855) (0.02225033)\n\n\nLet us plot the distribution of the scores obtained with the GAMSEL model. On top of the graph, we draw the density of the Beta distribution with the parameters estimated for each model.\n\n\nCode\nval_u &lt;- seq(0, 1, length = 651)\nlayout(mat = matrix(1:2), heights = c(3,1))\n# Histogram of scores obtained with the GAMSEL, on test set\npar(mar = c(4.1, 4.1, 1, 2.1))\nhist(\n  scores_gamsel$scores_test,\n  breaks = seq(0, 1, by = .05), probability = TRUE,\n  main = \"spambase\", xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\")\n)\n# Beta dist. estimated using the scores from the GLM\nlines(\n  val_u,\n  dbeta(val_u, mle_glm$estimate[1], mle_glm$estimate[2]),\n  col = \"#D55E00\",lwd = 1.5\n)\n# Beta dist. estimated using the scores from the GAM\nlines(\n  val_u,\n  dbeta(val_u, mle_gam$estimate[1], mle_gam$estimate[2]),\n  col = \"#0072B2\",lwd = 1.5\n)\n# Beta dist. estimated using the scores from the GAM\nlines(\n  val_u,\n  dbeta(val_u, mle_gamsel$estimate[1], mle_gamsel$estimate[2]),\n  col = \"#E69F00\",lwd = 1.5\n)\npar(mar = c(0, 4.1, 0, 2.1))\nplot.new()\nlegend(\n  xpd = TRUE, ncol = 3,\n  \"center\",\n  title = \"Model\",\n  lwd = 1.5,\n  col = c(\"#D55E00\", \"#0072B2\", \"#E69F00\"),\n  legend = c(\"GLM-logistic\", \"GAM\", \"GAMSEL\")\n)\n\n\n\n\n\nFigure 13.1: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models.",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Priors: Illustration</span>"
    ]
  },
  {
    "objectID": "book_real_example.html#wrapper-functions",
    "href": "book_real_example.html#wrapper-functions",
    "title": "13  Priors: Illustration",
    "section": "13.5 Wrapper Functions",
    "text": "13.5 Wrapper Functions\nFor convenience, we build a wrapper function, get_beta_fit() that takes a dataset as an input, the name of the target variable and possibly a seet. From these arguments, the function splits the dataset into a training and a test set. It then fits the models, and fit a Beta distribution on the scores estimated in the test set. This function returns a list with 6 elements: the first three are the estimated scores of the three models, the last three are the parameters of the Beta distribution estimated using the scores of each model.\n\n\nFunction get_beta_fit()\n#' Estimation of a GLM-logistic, a GAM and a GAMSEL model on a classification\n#' task. Then, on estimated scores from the test set, fits a Beta distribution.\n#'\n#' @param dataset dataset with response variable and predictors\n#' @param target_name name of the target (response) variable\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns A list with the following elements:\n#'  - `scores_glm`: scores on train and test set (in a list) from the GLM\n#'  - `scores_gam`: scores on train and test set (in a list) from the GAM\n#'  - `scores_gamsel`: scores on train and test set (in a list) from the GAMSEL\n#'  - `mle_glm`: An object of class \"fitdistr\" for the GLM model\n#'    (see fit_beta_scores())\n#'  - `mle_gamsel`: An object of class \"fitdistr\" for the GAM model\n#'    (see fit_beta_scores())\n#'  - `mle_gamsel`: An object of class \"fitdistr\" for the GAMSEL model\n#'    (see fit_beta_scores())\nget_beta_fit &lt;- function(dataset,\n                         target_name,\n                         seed = NULL) {\n  # Split data into train/test\n  data &lt;- split_train_test(data = dataset, prop_train = .8, seed = seed)\n\n  # Train a GLM-logistic model\n  scores_glm &lt;- train_glm(\n    data_train = data$train, data_test = data$test, target_name = target_name\n  )\n  # Train a GAM model\n  scores_gam &lt;- train_gam(\n    data_train = data$train, data_test = data$test, target_name = target_name,\n    spline_df = 6\n  )\n  # Train a GAMSEL model\n  scores_gamsel &lt;- train_gamsel(\n    data_train = data$train, data_test = data$test, target_name = target_name,\n    degrees = 6\n  )\n  # Add a little noise to the estimated scores to avoid being in [0,1] and be\n  # in (0,1) instead.\n  x_glm &lt;- (scores_glm$scores_test * (1 - 1e-6)) + 1e-6 / 2\n  x_gam &lt;- (scores_gam$scores_test * (1 - 1e-6)) + 1e-6 / 2\n  x_gamsel &lt;- (scores_gamsel$scores_test * (1 - 1e-6)) + 1e-6 / 2\n  # Fit a Beta distribution on these scores\n  mle_gam &lt;- fit_beta_scores(scores = x_gam)\n  mle_glm &lt;- fit_beta_scores(scores = x_glm)\n  mle_gamsel &lt;- fit_beta_scores(scores = x_gamsel)\n\n  list(\n    scores_glm = scores_glm,\n    scores_gam = scores_gam,\n    scores_gamsel = scores_gamsel,\n    mle_glm = mle_glm,\n    mle_gam = mle_gam,\n    mle_gamsel = mle_gamsel\n  )\n}\n\n\nWe also define a function, plot_hist_scores_beta() to plot the distribution of scores obtained with the GAMSEL model and the density functions of the three Beta distributions whose parameters were estimated based on the scores of the three models.\n\n\nFunction plot_hist_scores_beta()\n#' Plots the histogram of scores estimated with GAMSEL\n#' add densities of Beta distribution for whith the parameters have been\n#' estimated using scores from the GLM, the GAM, or the GAMSEL model\n#'\n#' @param fit_resul results obtained from get_beta_fit()\n#' @param title title of the graph (e.g.: dataset name)\nplot_hist_scores_beta &lt;- function(fit_resul, title = NULL) {\n  val_u &lt;- seq(0, 1, length = 651)\n  layout(mat = matrix(1:2), heights = c(3,1))\n  \n  dbeta_val &lt;- vector(mode = \"list\", length = 3)\n  for (i_type in 1:3) {\n    type &lt;- c(\"mle_glm\", \"mle_gam\", \"mle_gamsel\")[i_type]\n    dbeta_val[[i_type]] &lt;- dbeta(\n        val_u, \n        fit_resul[[type]]$estimate[1], \n        fit_resul[[type]]$estimate[2]\n      )\n  }\n  y_lim &lt;- c(\n    0,\n    map(dbeta_val,\n        ~range(.x[!is.infinite(.x)], na.rm = TRUE)) |&gt;\n      unlist() |&gt; max(na.rm = TRUE)\n  )\n  \n  \n  # Histogram of scores obtained with the GAMSEL, on test set\n  par(mar = c(4.1, 4.1, 1, 2.1))\n  hist(\n    fit_resul$scores_gamsel$scores_test,\n    breaks = seq(0, 1, by = .05), probability = TRUE,\n    main = title, xlab = latex2exp::TeX(\"$\\\\hat{s}(x)$\"),\n    ylim = y_lim\n  )\n\n  legend_name &lt;- c(\"GLM-logistic\", \"GAM\", \"GAMSEL\")\n  colours &lt;- c(\n    \"mle_glm\" = \"#D55E00\",\n    \"mle_gam\" = \"#0072B2\",\n    \"mle_gamsel\" = \"#E69F00\"\n  )\n  for (i_type in 1:3) {\n    type &lt;- c(\"mle_glm\", \"mle_gam\", \"mle_gamsel\")[i_type]\n    lines(\n      val_u,\n      dbeta_val[[i_type]],\n      col = colours[i_type],lwd = 1.5\n    )\n  }\n  par(mar = c(0, 4.1, 0, 2.1))\n  plot.new()\n  legend(\n    xpd = TRUE, ncol = 3,\n    \"center\",\n    title = \"Model\",\n    lwd = 1.5,\n    col = colours,\n    legend = legend_name\n  )\n}\n\n\nThese two functions can be called as follows:\n\n# Chunk not evaluated\nresul &lt;- get_beta_fit(dataset = dataset, target_name = \"is_spam\", seed = 1234)\nplot_hist_scores_beta(resul, \"spambase\")",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Priors: Illustration</span>"
    ]
  },
  {
    "objectID": "book_real_beta.html",
    "href": "book_real_beta.html",
    "title": "14  Datasets and Priors",
    "section": "",
    "text": "14.1 Datasets\nAll the datasets used here are from the UCI Machine Learning Repository.",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Datasets and Priors</span>"
    ]
  },
  {
    "objectID": "book_real_beta.html#datasets",
    "href": "book_real_beta.html#datasets",
    "title": "14  Datasets and Priors",
    "section": "",
    "text": "14.1.1 Abalone\n\nURL to the data: https://archive.ics.uci.edu/dataset/1/abalone\nDescription: Predict the age of abalone from physical measurements.\nNumber of instances: 4,177\nFeatures: 8\nReference: Nash et al. (1995)\n\n\nname &lt;- \"abalone\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/1/\", name, \".zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ntb_abalone &lt;- read_csv(\n  file = unz(str_c(\"data/\", name, \".zip\"), str_c(name, \".data\")), \n  col_names = c(\n    \"Sex\", \"Length\", \"Diameter\", \"Height\", \"Whole_weight\", \n  \"Shucked_weight\", \"Viscera_weight\", \"Shell_weight\", \"Rings\"),\n  show_col_types = FALSE\n)\n\n\nThe target variable is sex. Let us turn it in a \\(\\{0,1\\}\\) variable.\n\ntb_abalone &lt;- tb_abalone |&gt; \n  mutate(Sex = ifelse(Sex == \"M\", 1, 0)) \ntarget_name &lt;- \"Sex\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_abalone &lt;- get_beta_fit(\n  dataset = tb_abalone, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_abalone, file = \"output/real-data/priors_abalone.rda\")\nsave(tb_abalone, file = \"output/real-data/tb_abalone.rda\")\n\n\nplot_hist_scores_beta(priors_abalone, \"abalone\")\n\n\n\n\nFigure 14.1: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Abalone dataset.\n\n\n\n\n\n\n\n\n\n\n14.1.2 Adult\n\nURL to the data: https://archive.ics.uci.edu/dataset/2/adult\nDescription: Predict whether income exceeds $50K/yr based on census data. Also known as “Census Income” dataset.\nNumber of instances: 48,842\nFeatures: 14\nReference: Becker and Kohavi (1996)\n\n\nname &lt;- \"adult\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/2/\", name, \".zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\ninfo_data &lt;- scan(\n  unz(str_c(\"data/\", name, \".zip\"), str_c(name, \".names\")), \n  what = \"character\", sep = \"\\n\"\n)\n# Print the names for this dataset (not very convenient...)\nstr_extract(info_data[94:length(info_data)], \"^(.*):\") |&gt; \n  str_remove(\":$\") |&gt; \n  (\\(.x) str_c('\"', .x, '\",'))() |&gt; \n  cat()\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ntb_adult &lt;- read_csv(\n  file = unz(str_c(\"data/\", name, \".zip\"), str_c(name, \".data\")), \n  col_names = c(\n    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\",\n    \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\",\n    \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\",\n    \"income\"\n  ),\n  show_col_types = FALSE\n)\n\n\nThe target variable is income. Let us turn it in a \\(\\{0,1\\}\\) variable and call it high_income.\n\ntb_adult &lt;- tb_adult |&gt; \n  mutate(high_income = ifelse(income == \"&gt;50K\", 1, 0)) |&gt; \n  dplyr::select(-income)\ntarget_name &lt;- \"high_income\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_adult &lt;- get_beta_fit(\n  dataset = tb_adult, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_adult, file = \"output/real-data/priors_adult.rda\")\nsave(tb_adult, file = \"output/real-data/tb_adult.rda\")\n\n\nplot_hist_scores_beta(priors_adult, \"adult\")\n\n\n\n\nFigure 14.2: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Adult dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.3 Bank Marketing\n\nURL to the data: https://archive.ics.uci.edu/dataset/222/bank+marketing\nDescription: The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y).\nNumber of instances: 45,211\nFeatures: 16\nReference: Moro, Rita, and Cortez (2012)\n\n\nname &lt;- \"bank\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = \"https://archive.ics.uci.edu/static/public/222/bank+marketing.zip\", \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ndir.create(\"data/bank/\")\nsystem(\"unzip data/bank.zip -d data/bank/\")\nsystem(\"unzip data/bank/bank.zip -d data/bank/\")\ntb_bank &lt;- read_csv2(\n  file = unz(str_c(\"data/bank/\", name, \".zip\"), str_c(\"bank-full.csv\")), \n  skip = 1,\n  col_names = c(\n    \"age\", \"job\", \"marital\", \"education\", \"default\", \"balance\", \"housing\", \n    \"loan\", \"contact\", \"day\", \"month\", \"duration\", \"campaign\", \"pdays\", \n    \"previous\", \"poutcome\", \"y\"\n  ),\n  show_col_types = FALSE\n)\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nCode to import the data\nsystem(\"rm -rf data/bank/\")\n\n\nThe target variable is y (whether the client will subscribe a term deposit). Let us turn it in a \\(\\{0,1\\}\\) variable.\n\ntb_bank &lt;- tb_bank |&gt; \n  mutate(y = ifelse(y == \"yes\", 1, 0)) \ntarget_name &lt;- \"y\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_bank &lt;- get_beta_fit(\n  dataset = tb_bank, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_bank, file = \"output/real-data/priors_bank.rda\")\nsave(tb_bank, file = \"output/real-data/tb_bank.rda\")\n\n\nplot_hist_scores_beta(priors_bank, \"bank\")\n\n\n\n\nFigure 14.3: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Bank Marketing dataset.\n\n\n\n\n\n\n\n\n\n\n14.1.4 Default of Credit Card Clients\n\nURL to the data: https://archive.ics.uci.edu/dataset/350/default+of+credit+card+clients\nDescription: This research aimed at the case of customers’ default payments in Taiwan and compares the predictive accuracy of probability of default among six data mining methods.\nNumber of instances: 30,000\nFeatures: 23\nReference: Yeh (2016)\n\n\nname &lt;- \"default\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/350/\",\n              \"default+of+credit+card+clients.zip\"\n  ), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ndir.create(\"data/default/\")\nsystem(\"unzip data/default.zip -d data/default/\")\ntb_default &lt;- readxl::read_excel(\n  path = \"data/default/default of credit card clients.xls\",\n  skip = 1\n) |&gt; \n  select(-ID)\nsystem(\"rm -rf data/default\")\n\n\nThe target variable is defalut (1 if default, 0 otherwise).\n\ntb_default &lt;- \n  tb_default |&gt; \n  mutate(\n    across(all_of(c(\n      \"SEX\", \"EDUCATION\", \"MARRIAGE\", \n      \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\")), as.factor)\n  ) |&gt; \n  mutate(\n    across(all_of(c(\n      \"EDUCATION\", \"PAY_0\", \"PAY_2\", \"PAY_3\", \"PAY_4\", \"PAY_5\", \"PAY_6\"\n    )), ~fct_lump(.x, prop = .05)\n    )\n  ) |&gt; \n  rename(default = `default payment next month`)\ntarget_name &lt;- \"default\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_default &lt;- get_beta_fit(\n  dataset = tb_default, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_default, file = \"output/real-data/priors_default.rda\")\nsave(tb_default, file = \"output/real-data/tb_default.rda\")\n\n\nplot_hist_scores_beta(priors_default, \"default\")\n\n\n\n\nFigure 14.4: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Default of Credit Card Clients dataset.\n\n\n\n\n\n\n\n\n\n\n14.1.5 Dry Bean\n\nURL to the data: https://archive.ics.uci.edu/dataset/602/dry+bean+dataset\nDescription: Images of 13,611 grains of 7 different registered dry beans were taken with a high-resolution camera. A total of 16 features; 12 dimensions and 4 shape forms, were obtained from the grains.\nNumber of instances: 13,611\nFeatures: 16\nReferences: “Dry Bean” (2020)\n\n\nname &lt;- \"drybean\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = \"https://archive.ics.uci.edu/static/public/602/dry+bean+dataset.zip\", \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ndir.create(\"data/drybean/\")\nsystem(\"unzip data/drybean.zip -d data/drybean/\")\ntb_drybean &lt;- readxl::read_excel(\n  path = \"data/drybean/DryBeanDataset/Dry_Bean_Dataset.xlsx\"\n)\nsystem(\"rm -rf data/drybean\")\n\n\nThe target variable is sex. Let us turn it in a \\(\\{0,1\\}\\) variable.\n\ntb_drybean &lt;- tb_drybean |&gt; \n  mutate(is_dermason = ifelse(Class == \"DERMASON\", 1, 0)) |&gt; \n  select(-Class)\ntarget_name &lt;- \"is_dermason\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_drybean &lt;- get_beta_fit(\n  dataset = tb_drybean, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_drybean, file = \"output/real-data/priors_drybean.rda\")\nsave(tb_drybean, file = \"output/real-data/tb_drybean.rda\")\n\n\nplot_hist_scores_beta(priors_drybean, \"drybean\")\n\n\n\n\nFigure 14.5: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Dry Bean dataset.\n\n\n\n\n\n\n\n\n\n\n14.1.6 In-Vehicle Coupon Recommendation\n\nURL to the data: https://archive.ics.uci.edu/dataset/603/in+vehicle+coupon+recommendation\nDescription: This data studies whether a person will accept the coupon recommended to him in different driving scenarios.\nNumber of instances: 12,684\nFeatures: 25\nReferences: “In-Vehicle Coupon Recommendation” (2020)\n\n\nname &lt;- \"coupon\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/603/\", \n              \"in+vehicle+coupon+recommendation.zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ntb_coupon &lt;- read_csv(\n  file = unz(str_c(\"data/\", name, \".zip\"), \"in-vehicle-coupon-recommendation.csv\"),\n  show_col_types = FALSE\n)\n\n\nThe target variable is y (1 if the person accepted the coupon, 0 otherwise).\n\ntb_coupon &lt;- \n  tb_coupon |&gt; \n  mutate(\n    temperature = as.factor(temperature),\n    has_children = as.factor(has_children),\n    toCoupon_GEQ15min = as.factor(toCoupon_GEQ15min),\n    toCoupon_GEQ25min = as.factor(toCoupon_GEQ25min),\n    direction_same = as.factor(direction_same)\n  ) |&gt; \n  select(-toCoupon_GEQ5min, -direction_opp, -car) |&gt; \n  rename(y = Y)\n\ntb_coupon &lt;- na.omit(tb_coupon)\n\ntarget_name &lt;- \"y\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_coupon &lt;- get_beta_fit(\n  dataset = tb_coupon, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_coupon, file = \"output/real-data/priors_coupon.rda\")\nsave(tb_coupon, file = \"output/real-data/tb_coupon.rda\")\n\n\nplot_hist_scores_beta(priors_coupon, \"coupon\")\n\n\n\n\nFigure 14.6: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the In-Vehicle Coupon Recommendation dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.7 Mushroom\n\nURL to the data: https://archive.ics.uci.edu/dataset/73/mushroom\nDescription: From Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edible.\nNumber of instances: 8,124\nFeatures: 22\nReferences: “Mushroom” (1987)\n\n\nname &lt;- \"mushroom\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/73/mushroom.zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ntb_mushroom &lt;- read_csv(\n  file = unz(str_c(\"data/\", name, \".zip\"), \"agaricus-lepiota.data\"), \n  col_names = c(\n    \"edible\",\n    \"cap_shape\", \"cap_surface\", \"cap_color\", \"bruises\", \"odor\", \n    \"gill_attachment\", \"gill_spacing\", \"gill_size\", \"gill_color\", \n    \"stalk_shape\", \"stalk_root\", \"stalk_surface_above_ring\",\n    \"stalk_surface_below_ring\", \"stalk_color_above_ring\", \n    \"stalk_color_below_ring\", \"veil_type\", \"veil_color\", \"ring_number\", \n    \"ring_type\", \"spore_print_color\", \"population\", \"habitat\"\n  ),\n  show_col_types = FALSE\n)\n\n\nThe target variable is edible. Let us turn it in a \\(\\{0,1\\}\\) variable.\n\ntb_mushroom &lt;- tb_mushroom |&gt; \n  mutate(bruises = ifelse(bruises == TRUE, \"yes\", \"no\")) |&gt; \n  mutate(edible = ifelse(edible == \"e\", 1, 0)) |&gt; \n  select(-veil_type)\ntarget_name &lt;- \"edible\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_mushroom &lt;- get_beta_fit(\n  dataset = tb_mushroom, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_mushroom, file = \"output/real-data/priors_mushroom.rda\")\nsave(tb_mushroom, file = \"output/real-data/tb_mushroom.rda\")\n\n\nplot_hist_scores_beta(priors_mushroom, \"mushroom\")\n\n\n\n\nFigure 14.7: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Mushroom dataset.\n\n\n\n\n\n\n\n\n\n\n14.1.8 Occupancy Detection\n\nURL to the data: https://archive.ics.uci.edu/dataset/357/occupancy+detection\nDescription: Predict the age of occupancy from physical measurements.\nNumber of instances: 20,560\nFeatures: 6\nReferences: Candanedo (2016)\n\n\nname &lt;- \"occupancy\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/357/\",\n              \"occupancy+detection.zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ntb_occupancy &lt;- read_csv(\n  file = unz(str_c(\"data/\", name, \".zip\"), \"datatraining.txt\"), \n  col_names = c(\n    \"id\", \"date\",\"Temperature\",\"Humidity\",\"Light\",\"CO2\",\n    \"HumidityRatio\",\"Occupancy\"\n  ),\n  show_col_types = FALSE, skip = 1\n) |&gt; \n  bind_rows(\n    read_csv(\n      file = unz(str_c(\"data/\", name, \".zip\"), \"datatest.txt\"), \n      col_names = c(\n        \"id\", \"date\",\"Temperature\",\"Humidity\",\"Light\",\"CO2\",\n        \"HumidityRatio\",\"Occupancy\"\n      ),\n      show_col_types = FALSE, skip = 1,\n    )\n  ) |&gt; \n  bind_rows(\n    read_csv(\n      file = unz(str_c(\"data/\", name, \".zip\"), \"datatest2.txt\"), \n      show_col_types = FALSE, skip = 1,\n      col_names = c(\n        \"id\", \"date\",\"Temperature\",\"Humidity\",\"Light\",\"CO2\",\n        \"HumidityRatio\",\"Occupancy\"\n      ),\n    )\n  ) |&gt; \n  select(-id)\n\n\nThe target variable is Occupancy.\n\ntb_occupancy &lt;- tb_occupancy |&gt; \n  select(-date)\ntarget_name &lt;- \"Occupancy\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_occupancy &lt;- get_beta_fit(\n  dataset = tb_occupancy, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_occupancy, file = \"output/real-data/priors_occupancy.rda\")\nsave(tb_occupancy, file = \"output/real-data/tb_occupancy.rda\")\n\n\nplot_hist_scores_beta(priors_occupancy, \"occupancy\")\n\n\n\n\nFigure 14.8: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Occupancy Detection dataset.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n14.1.9 Wine Quality\n\nURL to the data: https://archive.ics.uci.edu/dataset/186/wine+quality\nDescription: Two datasets are included, related to red and white vinho verde wine samples, from the north of Portugal. The goal is to model wine quality based on physicochemical tests (see [Cortez et al., 2009], http://www3.dsi.uminho.pt/pcortez/wine/).\nNumber of instances: 4,898\nFeatures: 11\nReferences: Cortez et al. (2009)\n\n\nname &lt;- \"winequality\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/186/\",\n              \"wine+quality.zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\nred_wine &lt;- read_csv2(\n  file = unz(str_c(\"data/\", name, \".zip\"), \"winequality-red.csv\"),\n  show_col_types = FALSE) |&gt;\n  mutate(wine_type = \"red\")\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nCode to import the data\nwhite_wine &lt;- read_csv2(\n  file = unz(str_c(\"data/\", name, \".zip\"), \"winequality-white.csv\"),\n  show_col_types = FALSE) |&gt; \n  mutate(wine_type = \"white\") |&gt; \n  mutate(`residual sugar` = as.numeric(`residual sugar`))\n\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nThe target variable is quality. Let us use it to define a \\(\\{0,1\\}\\) variable. We define the variable high_quality which equals 1 if the quality is larger or equal than 6.\n\ntb_winequality &lt;- red_wine |&gt; bind_rows(white_wine) |&gt; \n  mutate(high_quality = ifelse(quality &gt;= 6, 1, 0)) |&gt; \n  mutate(across(all_of(c(\n    \"density\", \"chlorides\", \"volatile acidity\", \"sulphates\", \"citric acid\"\n    )), ~as.numeric(.x))) |&gt; \n  select(-quality)\ntb_winequality &lt;- na.omit(tb_winequality)\ntarget_name &lt;- \"high_quality\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_winequality &lt;- get_beta_fit(\n  dataset = tb_winequality, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_winequality, file = \"output/real-data/priors_winequality.rda\")\nsave(tb_winequality, file = \"output/real-data/tb_winequality.rda\")\n\n\nplot_hist_scores_beta(priors_winequality, \"winequality\")\n\n\n\n\nFigure 14.9: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the Wine Quality dataset.\n\n\n\n\n\n\n\n\n\n\n14.1.10 Spambase\n\nURL to the data: https://archive.ics.uci.edu/dataset/94/spambase\nDescription: Classifying Email as Spam or Non-Spam\nNumber of instances: 4,601\nFeatures: 57\nReferences: Hopkins et al. (1999)\n\n\nname &lt;- \"spambase\"\n\nThe dataset needs to be download.\n\n\nCode to download the data\nif (!dir.exists(\"data\")) dir.create(\"data\")\ndownload.file(\n  url = str_c(\"https://archive.ics.uci.edu/static/public/2/\", name, \".zip\"), \n  destfile = str_c(\"data/\", name, \".zip\")\n)\n\ninfo_data &lt;- scan(\n  unz(str_c(\"data/\", name, \".zip\"), str_c(name, \".names\")), \n  what = \"character\", sep = \"\\n\"\n)\n# Print the names for this dataset (not very convenient...)\nstr_extract(info_data[94:length(info_data)], \"^(.*):\") |&gt; \n  str_remove(\":$\") |&gt; \n  (\\(.x) str_c('\"', .x, '\",'))() |&gt; \n  cat()\n\n\nThen, we can import the dataset:\n\n\nCode to import the data\ntb_spambase &lt;- read_csv(\n  file = unz(str_c(\"data/\", name, \".zip\"), str_c(name, \".data\")),\n  col_names = c(\n    \"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\",\n    \"word_freq_our\", \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\",\n    \"word_freq_order\", \"word_freq_mail\", \"word_freq_receive\", \"word_freq_will\",\n    \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\",\n    \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\",\n    \"word_freq_credit\", \"word_freq_your\", \"word_freq_font\", \"word_freq_000\",\n    \"word_freq_money\", \"word_freq_hp\", \"word_freq_hpl\", \"word_freq_george\",\n    \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\",\n    \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\",\n    \"word_freq_technology\", \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\",\n    \"word_freq_direct\", \"word_freq_cs\", \"word_freq_meeting\",\n    \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \"word_freq_edu\",\n    \"word_freq_table\", \"word_freq_conference\", \"char_freq_;\", \"char_freq_(\",\n    \"char_freq_[\", \"char_freq_!\", \"char_freq_$\", \"char_freq_#\",\n    \"capital_run_length_average\", \"capital_run_length_longest\",\n    \"capital_run_length_total\", \"is_spam\"\n  ),\n  show_col_types = FALSE\n)\n\n\nThe target variable:\n\ntarget_name &lt;- \"is_spam\"\n\nLet us call the get_beta_fit() from Chapter 13 to get our priors.\n\npriors_spambase &lt;- get_beta_fit(\n  dataset = tb_spambase, target_name = target_name, seed = 1234\n)\n\nLet us save the results and the dataset:\n\nsave(priors_spambase, file = str_c(\"output/real-data/priors_spambase.rda\"))\nsave(tb_spambase, file = \"output/real-data/tb_spambase.rda\")\n\n\nplot_hist_scores_beta(priors_spambase, \"spambase\")\n\n\n\n\nFigure 14.10: Distribution of estimated probabilities by the GAMSEL model and Beta distribution fitted to the scores of each of the three models, for the spambase dataset.",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Datasets and Priors</span>"
    ]
  },
  {
    "objectID": "book_real_beta.html#summary",
    "href": "book_real_beta.html#summary",
    "title": "14  Datasets and Priors",
    "section": "14.2 Summary",
    "text": "14.2 Summary\n\n\nCodes to get the key characteristics of the datasets\ndatasets &lt;- tribble(\n  ~name, ~target_name, ~reference,\n  \"abalone\", \"Sex\", \"@misc_abalone_1\",\n  \"adult\", \"high_income\", \"@misc_adult_2\",\n  \"bank\", \"y\", \"@misc_bank_marketing_222\",\n  \"default\", \"default\", \"@misc_default_of_credit_card_clients_350\",\n  \"drybean\", \"is_dermason\", \"@misc_dry_bean_602\",\n  \"coupon\", \"y\", \"@misc_vehicle_coupon_recommendation_603\",\n  \"mushroom\", \"edible\", \"@misc_mushroom_73\",\n  \"occupancy\", \"Occupancy\", \"@misc_occupancy_detection__357\",\n  \"winequality\", \"high_quality\", \"@misc_wine_quality_186\",\n  \"spambase\", \"is_spam\", \"@misc_spambase_94\"\n)\n\ndataset_info &lt;- vector(mode = \"list\", length = nrow(datasets))\nfor (i in 1:nrow(datasets)) {\n  name &lt;- datasets$name[i]\n  target_name &lt;- datasets$target_name[i]\n  current_data &lt;- get(str_c('tb_', name))\n  current_target &lt;- current_data |&gt; pull(!!target_name)\n  current_ref &lt;- datasets$reference[i]\n  n &lt;- nrow(current_data)\n  n_col &lt;- ncol(current_data)\n  n_numeric &lt;- current_data |&gt; select(-!!target_name) |&gt; \n    select(where(is.numeric)) |&gt; \n    ncol()\n  dataset_info[[i]] &lt;- tibble(\n    Dataset = name, \n    n = n, \n    `# features` = n_col-1,\n    `# numeric features` = n_numeric,\n    `Prop. target = 1` = round(sum(current_target == 1) / n, 2),\n    Reference = current_ref\n  )\n}\n\ndataset_info &lt;- list_rbind(dataset_info)\nknitr::kable(dataset_info, booktabs = TRUE, format.args = list(big.mark = \",\"))\n\n\n\n\nTable 14.1: Key characteristics of the datasets.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nn\n# features\n# numeric features\nProp. target = 1\nReference\n\n\n\n\nabalone\n4,177\n8\n8\n0.37\nNash et al. (1995)\n\n\nadult\n32,561\n14\n6\n0.24\nBecker and Kohavi (1996)\n\n\nbank\n45,211\n16\n7\n0.12\nMoro, Rita, and Cortez (2012)\n\n\ndefault\n30,000\n23\n14\n0.22\nYeh (2016)\n\n\ndrybean\n13,611\n16\n16\n0.26\n“Dry Bean” (2020)\n\n\ncoupon\n12,079\n22\n0\n0.57\n“In-Vehicle Coupon Recommendation” (2020)\n\n\nmushroom\n8,124\n21\n0\n0.52\n“Mushroom” (1987)\n\n\noccupancy\n20,560\n5\n5\n0.23\nCandanedo (2016)\n\n\nwinequality\n6,495\n12\n11\n0.63\nCortez et al. (2009)\n\n\nspambase\n4,601\n57\n57\n0.39\nHopkins et al. (1999)\n\n\n\n\n\n\n\n\n\n\n\n\nBecker, Barry, and Ronny Kohavi. 1996. “Adult.” UCI Machine Learning Repository.\n\n\nCandanedo, Luis. 2016. “Occupancy Detection .” UCI Machine Learning Repository.\n\n\nCortez, Paulo, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. 2009. “Wine Quality.” UCI Machine Learning Repository.\n\n\n“Dry Bean.” 2020. UCI Machine Learning Repository.\n\n\nHopkins, Mark, Erik Reeber, George Forman, and Jaap Suermondt. 1999. “Spambase.” UCI Machine Learning Repository.\n\n\n“In-Vehicle Coupon Recommendation.” 2020. UCI Machine Learning Repository.\n\n\nMoro, S., P. Rita, and P. Cortez. 2012. “Bank Marketing.” UCI Machine Learning Repository.\n\n\n“Mushroom.” 1987. UCI Machine Learning Repository.\n\n\nNash, Warwick, Tracy Sellers, Simon Talbot, Andrew Cawthorn, and Wes Ford. 1995. “Abalone.” UCI Machine Learning Repository.\n\n\nYeh, I-Cheng. 2016. “Default of Credit Card Clients.” UCI Machine Learning Repository.",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Datasets and Priors</span>"
    ]
  },
  {
    "objectID": "book_real_estimations.html",
    "href": "book_real_estimations.html",
    "title": "15  Estimations",
    "section": "",
    "text": "15.1 Functions",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Estimations</span>"
    ]
  },
  {
    "objectID": "book_real_estimations.html#functions",
    "href": "book_real_estimations.html#functions",
    "title": "15  Estimations",
    "section": "",
    "text": "15.1.1 Metrics\nLet us define the metrics function presented in Chapter 3.\n\nsource(\"functions/metrics.R\")\n\nThe functions for data pre-processing and Beta distribution fitting are stored in functions/real-data.R (see Chapter 13).\n\nsource(\"functions/real-data.R\")\n\n\n15.1.1.1 Performance and Calibration Metrics\nWe introduce a helper function, get_perf_metrics() (see Chapter 3), which serves as a wrapper for compute_metrics(). This function applies compute_metrics() to the estimated scores from both the training and testing datasets.\n\n\nFunction get_perf_metrics()\n#' Get the performance and calibration metrics for estimated scores\n#'\n#' @param scores_train vector of scores on the train test\n#' @param scores_valid vector of scores on the validation test\n#' @param scores_test vector of scores on the test test\n#' @param tb_train train set\n#' @param tb_valid valdation set\n#' @param tb_test test set\n#' @param target_name name of target variable\nget_perf_metrics &lt;- function(scores_train,\n                             scores_valid,\n                             scores_test,\n                             tb_train,\n                             tb_valid,\n                             tb_test,\n                             target_name) {\n  # We add very small noise to predicted scores\n  # otherwise the local regression may crash\n  scores_train_noise &lt;- scores_train +\n    runif(n = length(scores_train), min = 0, max = 0.01)\n  scores_train_noise[scores_train_noise &gt; 1] &lt;- 1\n  metrics_train &lt;- compute_metrics(\n    obs = tb_train |&gt; pull(!!target_name),\n    scores = scores_train_noise, true_probas = NULL\n  ) |&gt; mutate(sample = \"train\")\n\n  scores_valid_noise &lt;- scores_valid +\n    runif(n = length(scores_valid), min = 0, max = 0.01)\n  scores_valid_noise[scores_valid_noise &gt; 1] &lt;- 1\n  metrics_valid &lt;- compute_metrics(\n    obs = tb_valid |&gt; pull(!!target_name),\n    scores = scores_valid_noise, true_probas = NULL\n  ) |&gt; mutate(sample = \"validation\")\n  \n  scores_test_noise &lt;- scores_test +\n    runif(n = length(scores_test), min = 0, max = 0.01)\n  scores_test_noise[scores_test_noise &gt; 1] &lt;- 1\n  metrics_test &lt;- compute_metrics(\n    obs = tb_test |&gt; pull(!!target_name),\n    scores = scores_test_noise, true_probas = NULL\n  ) |&gt; mutate(sample = \"test\")\n\n  tb_metrics &lt;- metrics_train |&gt;\n    bind_rows(metrics_valid) |&gt; \n    bind_rows(metrics_test)\n  tb_metrics\n}\n\n\n\n\n15.1.1.2 Dispersion Metrics\nWe modify our dispersion_metrics() function (refer to Chapter 3) to replace the vector of simulated true probabilities with the parameters of a Beta distribution. This adjustment allows us to compute the divergence between the model-estimated scores and the specified Beta distribution.\n\n\nFunction dispersion_metrics_beta()\n#' Computes the dispersion and divergence metrics for a vector of scores and\n#' a Beta distribution\n#'\n#' @param shape_1 first parameter of the beta distribution\n#' @param shape_2 second parameter of the beta distribution\n#' @param scores predicted scores\n#'\n#' @returns\n#' \\itemize{\n#'   \\item \\code{inter_quantile_25_75}: Difference of inter-quantile between 25% and 75%\n#'   \\item \\code{inter_quantile_10_90}: Difference of inter-quantile between 10% and 90%\n#'   \\item \\code{KL_10_true_probas}: KL of of predicted probabilities w.r. to true probabilities with 10 bins\n#'   \\item \\code{KL_10_scores}: KL of of true probabilities w.r. to predicted probabilities with 10 bins\n#'   \\item \\code{KL_20_true_probas}: KL of of predicted probabilities w.r. to true probabilities with 20 bins\n#'   \\item \\code{KL_20_scores}: KL of of true probabilities w.r. to predicted probabilities with 20 bins\n#'   \\item \\code{ind_cov}: Difference between the variance of true probabilities and the covariance between true probabilities and predicted scores\n#' }\ndispersion_metrics_beta &lt;- function(shape_1 = 1, shape_2 = 1, scores){\n\n  # Inter-quantiles\n  inter_q_80 &lt;- diff(quantile(scores, c(.9, .1))) /\n    diff(qbeta(c(.9, .1), shape_1, shape_2))\n  inter_q_50 &lt;- diff(quantile(scores, c(.75,.25))) /\n    diff(qbeta(c(.75,.25), shape_1, shape_1))\n\n  # KL divergences\n  m &lt;- 10 # Number of bins\n  h_phat &lt;- hist(scores, breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  h_p &lt;- list(breaks = h_phat$breaks, mids = h_phat$mids)\n  h_p$density = diff(pbeta(h_p$breaks, shape_1, shape_2))\n  h_p$counts =  h_p$density*length(scores)\n\n  # Densities\n  h1 &lt;- rbind(h_phat$density / m, h_p$density / m) # Reference : true probabilities\n  h2 &lt;- rbind(h_p$density / m, h_phat$density / m) # Reference : predicted scores\n  KL_10_true_probas &lt;- distance(\n    h1, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n  KL_10_scores &lt;- distance(\n    h2, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n\n\n  m &lt;- 20 # Number of bins\n  h_phat &lt;- hist(scores, breaks = seq(0, 1, length = m + 1), plot = FALSE)\n  h_p &lt;- list(breaks = h_phat$breaks, mids = h_phat$mids)\n  h_p$density = diff(pbeta(h_p$breaks, shape_1, shape_2))\n  h_p$counts =  h_p$density * length(scores)\n  # Densities\n  h1 &lt;- rbind(h_phat$density / m, h_p$density) # Reference : true probabilities\n  h2 &lt;- rbind(h_p$density, h_phat$density / m) # Reference : predicted scores\n  KL_20_true_probas &lt;- distance(\n    h1, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n  KL_20_scores &lt;- distance(\n    h2, method = \"kullback-leibler\", unit = \"log2\", mute.message = TRUE)\n\n  # Indicator of the difference between variance and covariance\n  var_p &lt;- shape_1 * shape_2 / ((shape_1 + shape_2)^2 * (shape_1 + shape_2 + 1))\n  cov_p_phat &lt;- cov(\n    qbeta(\n      rank(scores, ties.method = \"average\") / (1 + length(scores)),\n      shape_1,\n      shape_2),\n    scores\n  )\n  ind_cov &lt;- abs(cov_p_phat - var_p)\n\n  # Collection\n  dispersion_metrics &lt;- tibble(\n    \"inter_quantile_25_75\" = as.numeric(inter_q_50),\n    \"inter_quantile_10_90\" = as.numeric(inter_q_80),\n    \"KL_10_true_probas\" = as.numeric(KL_10_true_probas),\n    \"KL_10_scores\" = as.numeric(KL_10_scores),\n    \"KL_20_true_probas\" = as.numeric(KL_20_true_probas),\n    \"KL_20_scores\" = as.numeric(KL_20_scores),\n    \"ind_cov\" = ind_cov\n  )\n\n  dispersion_metrics\n}\n\n\nWe also introduce a helper function that acts as a wrapper for dispersion_metrics_beta(), which calculates divergence metrics for three prior distributions. These distributions are Beta distributions, with shape parameters derived from scores estimated by GLM, GAM, and GAMSEL models, respectively (see Chapter 14).\n\n\nFunction disp_metrics_dataset()\n#' Computes the dispersion and divergence metrics between estimated scores and\n#' the Beta distributions whose parameters were estimated using scores estimated\n#' with a GLM-loistic, a GAM and a GAM with model selection.\n#' (helper function)\n#'\n#' @param priors priors obtained with `get_beta_fit()`\n#' @param scores estimated scores from a model\ndisp_metrics_dataset &lt;- function(priors, scores) {\n  # GLM priors\n  shape_1_glm &lt;- priors$mle_glm$estimate[\"shape1\"]\n  shape_2_glm &lt;- priors$mle_glm$estimate[\"shape2\"]\n  # GAM priors\n  shape_1_gam &lt;- priors$mle_gam$estimate[\"shape1\"]\n  shape_2_gam &lt;- priors$mle_gam$estimate[\"shape2\"]\n  # GAMSEL priors\n  shape_1_gamsel &lt;- priors$mle_gamsel$estimate[\"shape1\"]\n  shape_2_gamsel &lt;- priors$mle_gamsel$estimate[\"shape2\"]\n\n  # Divergence metrics\n  dist_prior_glm &lt;- dispersion_metrics_beta(\n    shape_1 = shape_1_glm, shape_2 = shape_2_glm, scores = scores\n  )\n  dist_prior_gam &lt;- dispersion_metrics_beta(\n    shape_1 = shape_1_gam, shape_2 = shape_2_gam, scores = scores\n  )\n  dist_prior_gamsel &lt;- dispersion_metrics_beta(\n    shape_1 = shape_1_gamsel, shape_2 = shape_2_gamsel, scores = scores\n  )\n\n  dist_prior_glm |&gt;\n    mutate(prior = \"glm\", shape_1 = shape_1_glm, shape_2 = shape_2_glm) |&gt;\n    bind_rows(\n      dist_prior_gam |&gt;\n        mutate(prior = \"gam\", shape_1 = shape_1_gam, shape_2 = shape_2_gam)\n    ) |&gt;\n    bind_rows(\n      dist_prior_gamsel |&gt;\n        mutate(\n          prior = \"gamsel\", shape_1 = shape_1_gamsel, shape_2 = shape_2_gamsel\n        )\n    )\n}\n\n\nWe also define helper functions, as detailed in Chapter 9, to generate histograms of estimated scores and to calculate \\(\\mathbb{P}(q_1 &lt; \\mathbf{s}(\\mathbb{x}) &lt; q_2)\\).\n\n\nHelper Functions\n#' Counts the number of scores in each of the 20 equal-sized bins over [0,1]\n#'\n#' @param scores_train vector of scores on the train test\n#' @param scores_valid vector of scores on the validation test\n#' @param scores_test vector of scores on the test test\nget_histogram &lt;- function(scores_train,\n                          scores_valid,\n                          scores_test) {\n  breaks &lt;- seq(0, 1, by = .05)\n  scores_train_hist &lt;- hist(scores_train, breaks = breaks, plot = FALSE)\n  scores_valid_hist &lt;- hist(scores_valid, breaks = breaks, plot = FALSE)\n  scores_test_hist &lt;- hist(scores_test, breaks = breaks, plot = FALSE)\n  scores_hist &lt;- list(\n    train = scores_train_hist,\n    valid = scores_valid_hist,\n    test = scores_test_hist\n  )\n  scores_hist\n}\n\n#' Estimation of P(q1 &lt; score &lt; q2)\n#'\n#' @param scores_train vector of scores on the train test\n#' @param scores_valid vector of scores on the validation test\n#' @param scores_test vector of scores on the test test\n#' @param q1 vector of desired values for q1 (q2 = 1-q1)\nestim_prop &lt;- function(scores_train,\n                       scores_valid,\n                       scores_test,\n                       q1 = c(.1, .2, .3, .4)) {\n  proq_scores_train &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_train, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"train\")\n  proq_scores_valid &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_valid, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"validation\")\n  proq_scores_test &lt;- map(\n    q1,\n    ~prop_btw_quantiles(s = scores_test, q1 = .x)\n  ) |&gt;\n    list_rbind() |&gt;\n    mutate(sample = \"test\")\n\n  proq_scores_train |&gt;\n    bind_rows(proq_scores_valid) |&gt; \n    bind_rows(proq_scores_test)\n}\n\n\n\n\n15.1.1.3 Wrapper Metrics Function\nFor convenience, we define a function, get_metrics_simul(), which calculates performance metrics, calibration metrics, and divergence metrics for estimated scores on both the train and test sets.\n\n\nFunction get_metrics_simul()\n#' Get the performance/calibration/dispersion/divergence metrics\n#' given estimated scores on the train, validation, and test sets\n#'\n#' @param scores_train scores estimated on train set\n#' @param scores_valid scores estimated on validation set\n#' @param scores_test scores estimated on test set\n#' @param tb_train train set\n#' @param tb_valid validation set\n#' @param tb_test test set\n#' @param target_name name of the target variable\n#' @param priors priors\n#'\n#' @returns A list with 4 elements:\n#'  - `tb_metrics`: performance / calibration metrics\n#'  - `tb_disp_metrics`: disp and div metrics\n#'  - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'  - `scores_hist`: histogram of scores\nget_metrics_simul &lt;- function(scores_train,\n                              scores_valid,\n                              scores_test,\n                              tb_train,\n                              tb_valid,\n                              tb_test,\n                              priors,\n                              target_name) {\n  ## Histogram of scores----\n  scores_hist &lt;- get_histogram(scores_train, scores_valid, scores_test)\n\n  # Performance and Calibration Metrics----\n  tb_metrics &lt;- get_perf_metrics(\n    scores_train = scores_train,\n    scores_valid = scores_valid,\n    scores_test = scores_test,\n    tb_train = tb_train,\n    tb_valid = tb_valid,\n    tb_test = tb_test,\n    target_name = target_name)\n\n  # Dispersion Metrics----\n  tb_disp_metrics &lt;-\n    disp_metrics_dataset(priors = priors, scores = scores_train) |&gt;\n    mutate(sample = \"train\") |&gt;\n    bind_rows(\n      disp_metrics_dataset(priors = priors, scores = scores_valid) |&gt;\n        mutate(sample = \"validation\")\n    ) |&gt; \n    bind_rows(\n      disp_metrics_dataset(priors = priors, scores = scores_test) |&gt;\n        mutate(sample = \"test\")\n    )\n\n  # Estimation of P(q1 &lt; score &lt; q2)----\n  tb_prop_scores &lt;- estim_prop(\n    scores_train = scores_train,\n    scores_valid = scores_valid,\n    scores_test = scores_test\n  )\n\n  list(\n    tb_metrics = tb_metrics,           # performance / calibration metrics\n    tb_disp_metrics = tb_disp_metrics, # disp and div metrics\n    tb_prop_scores = tb_prop_scores,   # table with P(q1 &lt; score &lt; q2)\n    scores_hist = scores_hist          # histogram of scores\n  )\n}\n\n\n\n\n\n15.1.2 Estimation Functions\nIn Section 15.3, we will train Random Forests and XGB models on various datasets. To accommodate multiple sets of hyperparameters for each model, we must define two functions: one that estimates a model for a single set of hyperparameters, and another that iterates this estimation across all hyperparameter sets. Additionally, for the XGB model, a third function is required to calculate metrics at each boosting iteration and a fourth one to predict the scores (this fourth function is defined because of issues arising with parallel computations and the serialization of the objects from the {xgboost} package).\n\n15.1.2.1 Random Forests\nFor a specific dataset, we train a random forest using various hyperparameter sets. We adjust the minimum number of observations per terminal leaf node (unique(round(2^seq(1, 14, by = .4)))) and the number of candidate variables considered for each split (2, 4, or 10). We fix the number of trees in the forest at 500.\nThe simul_forest_real() function estimates multiple forests for a given dataset. It relies on the simul_forest_helper() function, which trains a forest using a specific set of hyperparameters. Each forest is trained using the same training sample. Performance metrics are computed for each forest on both the training and testing samples.\n\n\nFunction simul_forest_real()\n#' Train a random forest on a dataset for a binary task for various\n#' hyperparameters and computes metrics based on scores and on a set of prior\n#' distributions of the underlying probability\n#'\n#' @param data dataset\n#' @param target_name name of the target variable\n#' @param priors priors obtained with `get_beta_fit()`\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns A list with two elements:\n#'  - `res`: results for each estimated model of the grid. Each element is a\n#'   list with the following 4 arguments:\n#'      - `tb_metrics`: performance / calibration metrics\n#'      - `tb_disp_metrics`: disp and div metrics\n#'      - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'      - `scores_hist`: histogram of scores.\n#'  - `grid`: the grid search.\nsimul_forest_real &lt;- function(data,\n                              target_name,\n                              priors,\n                              seed = NULL) {\n\n  if (!is.null(seed)) set.seed(seed)\n\n  min_bucket_values &lt;- unique(round(2^seq(1, 14, by = .4)))\n  min_bucket_values &lt;- min_bucket_values[min_bucket_values &lt;=  nrow(data)]\n  \n  mtry &lt;- c(2, 4, 10)\n  mtry &lt;- mtry[mtry &lt;= ncol(data)]\n  \n  # Grid for hyperparameters\n  grid &lt;- expand_grid(\n    mtry = mtry,\n    num_trees = 500,\n    min_node_size = min_bucket_values\n  ) |&gt;\n    mutate(ind = row_number())\n\n  # Split data into train and test set\n  data_splitted &lt;- split_train_test(data = data, prop_train = .8, seed = seed)\n  \n  data_encoded &lt;- encode_dataset(\n    data_train = data_splitted$train,\n    data_test = data_splitted$test,\n    target_name = target_name,\n    intercept = FALSE\n  )\n  \n  # Further split train intro two samples (train/valid)\n  data_splitted_train &lt;- \n    split_train_test(data = data_encoded$train, prop_train = .8, seed = seed)\n\n  progressr::with_progress({\n    p &lt;- progressr::progressor(steps = nrow(grid))\n    res_grid &lt;- furrr::future_map(\n      .x = seq_len(nrow(grid)),\n      .f = ~{\n        p()\n        simul_forest_helper(\n          data_train = data_splitted_train$train,\n          data_valid = data_splitted_train$test,\n          data_test = data_encoded$test,\n          target_name = target_name,\n          params = grid |&gt; dplyr::slice(.x),\n          priors = priors\n        )\n      },\n      .options = furrr::furrr_options(seed = NULL)\n    )\n  })\n\n  list(\n    res = res_grid,\n    grid = grid\n  )\n}\n\n\n\n\nFunction simul_forest_helper()\n#' Fit a random forest and returns metrics based on scores. The divergence\n#' metrics are obtained using the prior distributions.\n#'\n#' @param data_train train set\n#' @param data_valid validation set\n#' @param data_test test set\n#' @param target_name name of the target variable\n#' @param parms tibble with hyperparameters for the current estimation\n#' @param priors priors obtained with `get_beta_fit()`\n#'\n#' @returns A list with 4 elements:\n#'  - `tb_metrics`: performance / calibration metrics\n#'  - `tb_disp_metrics`: disp and div metrics\n#'  - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'  - `scores_hist`: histogram of scores\nsimul_forest_helper &lt;- function(data_train,\n                                data_valid,\n                                data_test,\n                                target_name,\n                                params,\n                                priors) {\n  ## Estimation----\n  fit_rf &lt;- ranger(\n    str_c(target_name, \" ~ .\"),\n    data = data_train,\n    min.bucket = params$min_node_size,\n    mtry = params$mtry,\n    num.trees = params$num_trees\n  )\n  ## Predicted scores----\n  scores_train &lt;- predict(fit_rf, data = data_train, type = \"response\")$predictions\n  scores_valid &lt;- predict(fit_rf, data = data_valid, type = \"response\")$predictions\n  scores_test &lt;- predict(fit_rf, data = data_test, type = \"response\")$predictions\n  ## Metrics----\n  metrics &lt;- get_metrics_simul(\n    scores_train = scores_train,\n    scores_valid = scores_valid,\n    scores_test = scores_test,\n    tb_train = data_train,\n    tb_valid = data_valid,\n    tb_test = data_test,\n    priors = priors,\n    target_name = target_name\n  )\n  # Add index of the grid search\n  metrics$tb_metrics &lt;- metrics$tb_metrics |&gt; mutate(ind = params$ind)\n  metrics$tb_disp_metrics &lt;- metrics$tb_disp_metrics |&gt; mutate(ind = params$ind)\n  metrics$tb_prop_scores &lt;- metrics$tb_prop_scores |&gt; mutate(ind = params$ind)\n  metrics$scores_hist$ind &lt;- params$ind\n\n  metrics\n}\n\n\n\n\n15.1.2.2 Extreme Gradient Boosting\nWe train XGB models on various datasets, varying the maximum tree depth (with values of 2, 4, or 6) and the number of boosting iterations (ranging from 2 to 500). At each iteration, we compute metrics based on scores from both the train and test samples.\nThe simul_xgb_real() function estimates all XGB models for a specific dataset, iterating over a grid of hyperparameters. For each hyperparameter set, it calls the simul_xgb_helper() function to estimate the model. During each boosting iteration, metrics are calculated using scores from the get_metrics_xgb_iter() and predict_score_iter() functions.\n\n\nFunction simul_xgb_real()\n#' Train an XGB on a dataset for a binary task for various\n#' hyperparameters and computes metrics based on scores and on a set of prior\n#' distributions of the underlying probability\n#'\n#' @param data dataset\n#' @param target_name name of the target variable\n#' @param priors priors obtained with `get_beta_fit()`\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns A list with two elements:\n#'  - `res`: results for each estimated model of the grid. Each element is a\n#'  list with the following elements:\n#'      - `tb_metrics`: performance / calibration metrics\n#'      - `tb_disp_metrics`: disp and div metrics\n#'      - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'      - `scores_hist`: histogram of scores.\n#'  - `grid`: the grid search.\nsimul_xgb_real &lt;- function(data,\n                           target_name,\n                           priors,\n                           seed = NULL) {\n\n  if (!is.null(seed)) set.seed(seed)\n\n  # Grid for hyperparameters\n  grid &lt;- expand_grid(\n    max_depth = c(2, 4, 6),\n    nb_iter_total = 500,\n    eta = 0.3\n  ) |&gt;\n    mutate(ind = row_number())\n\n  # Split data into train and test set\n  data_splitted &lt;- split_train_test(data = data, prop_train = .8, seed = seed)\n  data_encoded &lt;- encode_dataset(\n    data_train = data_splitted$train,\n    data_test = data_splitted$test,\n    target_name = target_name,\n    intercept = FALSE\n  )\n\n  # Further split train intro two samples (train/valid)\n  data_splitted_train &lt;- \n    split_train_test(data = data_encoded$train, prop_train = .8, seed = seed)\n  \n  res_grid &lt;- vector(mode = \"list\", length = nrow(grid))\n  for (i_grid in 1:nrow(grid)) {\n    res_grid[[i_grid]] &lt;- simul_xgb_helper(\n      data_train = data_splitted_train$train,\n      data_valid = data_splitted_train$test,\n      data_test = data_encoded$test,\n      target_name = target_name,\n      params = grid |&gt; dplyr::slice(i_grid),\n      priors = priors\n    )\n  }\n\n  list(\n    res = res_grid,\n    grid = grid\n  )\n}\n\n\n\n\nFunction get_metrics_xgb_iter()\n#' Get the metrics based on scores estimated at a given boosting iteration\n#'\n#' @param scores scores estimated a boosting iteration `nb_iter` (list with\n#'   train and test scores, returned by `predict_score_iter()`)\n#' @param data_train train set\n#' @param data_valid validation set\n#' @param data_test test set\n#' @param target_name name of the target variable\n#' @param ind index of the grid search\n#' @param nb_iter boosting iteration to consider\n#'\n#' @returns A list with 4 elements:\n#'  - `tb_metrics`: performance / calibration metrics\n#'  - `tb_disp_metrics`: disp and div metrics\n#'  - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'  - `scores_hist`: histogram of scores\nget_metrics_xgb_iter &lt;- function(scores,\n                                 data_train,\n                                 data_valid,\n                                 data_test,\n                                 target_name,\n                                 ind,\n                                 nb_iter) {\n\n  scores_train &lt;- scores$scores_train\n  scores_valid &lt;- scores$scores_valid\n  scores_test &lt;- scores$scores_test\n\n  ## Metrics----\n  metrics &lt;- get_metrics_simul(\n    scores_train = scores_train,\n    scores_valid = scores_valid,\n    scores_test = scores_test,\n    tb_train = data_train,\n    tb_valid = data_valid,\n    tb_test = data_test,\n    priors = priors,\n    target_name = target_name\n  )\n  # Add index of the grid search\n  metrics$tb_metrics &lt;- metrics$tb_metrics |&gt;\n    mutate(ind = ind, nb_iter = nb_iter)\n  metrics$tb_disp_metrics &lt;- metrics$tb_disp_metrics |&gt;\n    mutate(ind = ind, nb_iter = nb_iter)\n  metrics$tb_prop_scores &lt;- metrics$tb_prop_scores |&gt;\n    mutate(ind = ind, nb_iter = nb_iter)\n  metrics$scores_hist$ind &lt;- ind\n  metrics$scores_hist$nb_iter &lt;- nb_iter\n\n  metrics\n}\n\n\n\n\nFunction predict_score_iter()\n#' Predicts the scores at a given iteration of the XGB model\n#'\n#' @param fit_xgb estimated XGB model\n#' @param tb_train_xgb train set\n#' @param tb_valid_xgb validation set\n#' @param tb_test_xgb test set\n#' @param ind index of the grid search\n#' @param nb_iter boosting iteration to consider\n#'\n#' @returns A list with three elements: `scores_train`, `scores_valid`, and\n#'  `scores_train` which contain the estimated scores on the train and on the \n#'  test score, resp.\npredict_score_iter &lt;- function(fit_xgb,\n                               tb_train_xgb,\n                               tb_valid_xgb,\n                               tb_test_xgb,\n                               nb_iter) {\n\n  ## Predicted scores----\n  scores_train &lt;- predict(fit_xgb, tb_train_xgb, iterationrange = c(1, nb_iter))\n  scores_valid &lt;- predict(fit_xgb, tb_valid_xgb, iterationrange = c(1, nb_iter))\n  scores_test &lt;- predict(fit_xgb, tb_test_xgb, iterationrange = c(1, nb_iter))\n\n  list(\n    scores_train = scores_train,\n    scores_valid = scores_valid,\n    scores_test = scores_test\n  )\n}\n\n\n\n\nFunction simul_xgb_helper()\n#' Fit an XGB and returns metrics based on scores. The divergence metrics are\n#' obtained using the prior distributions.\n#'\n#' @param data_train train set\n#' @param data_valid validation set\n#' @param data_test test set\n#' @param target_name name of the target variable\n#' @param parms tibble with hyperparameters for the current estimation\n#' @param priors priors obtained with `get_beta_fit()`\n#'\n#' @returns A list with 4 elements:\n#'  - `tb_metrics`: performance / calibration metrics\n#'  - `tb_disp_metrics`: disp and div metrics\n#'  - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'  - `scores_hist`: histogram of scores\nsimul_xgb_helper &lt;- function(data_train,\n                             data_valid,\n                             data_test,\n                             target_name,\n                             params,\n                             priors) {\n\n  ## Format data for xgboost----\n  tb_train_xgb &lt;- xgb.DMatrix(\n    data = data_train |&gt; dplyr::select(-!!target_name) |&gt; as.matrix(),\n    label = data_train |&gt; dplyr::pull(!!target_name) |&gt; as.matrix()\n  )\n  tb_valid_xgb &lt;- xgb.DMatrix(\n    data = data_valid |&gt; dplyr::select(-!!target_name) |&gt; as.matrix(),\n    label = data_valid |&gt; dplyr::pull(!!target_name) |&gt; as.matrix()\n  )\n  tb_test_xgb &lt;- xgb.DMatrix(\n    data = data_test |&gt; dplyr::select(-!!target_name) |&gt; as.matrix(),\n    label = data_test |&gt; dplyr::pull(!!target_name) |&gt; as.matrix()\n  )\n  # Parameters for the algorithm\n  param &lt;- list(\n    max_depth = params$max_depth, #Note: root node is indexed 0\n    eta = params$eta,\n    nthread = 1,\n    objective = \"binary:logistic\",\n    eval_metric = \"auc\"\n  )\n  watchlist &lt;- list(train = tb_train_xgb, eval = tb_valid_xgb)\n  ## Estimation----\n  fit_xgb &lt;- xgb.train(\n    param, tb_train_xgb,\n    nrounds = params$nb_iter_total,\n    watchlist,\n    verbose = 0\n  )\n\n  # First, we estimate the scores at each boosting iteration\n  # As the xgb.Dmatrix objects cannot be easily serialised, we first estimate\n  # these scores in a classical way, without parallelism...\n  scores_iter &lt;- vector(mode = \"list\", length = params$nb_iter_total)\n  for (i_iter in 1:params$nb_iter_total) {\n    scores_iter[[i_iter]] &lt;- predict_score_iter(\n      fit_xgb = fit_xgb,\n      tb_train_xgb = tb_train_xgb,\n      tb_valid_xgb = tb_valid_xgb,\n      tb_test_xgb = tb_test_xgb,\n      nb_iter = i_iter)\n  }\n\n  # Then, to compute the metrics, as it is a bit slower, we can use parallelism\n\n  ncl &lt;- detectCores() - 1\n  (cl &lt;- makeCluster(ncl))\n  clusterEvalQ(cl, {\n    library(tidyverse)\n    library(locfit)\n    library(philentropy)\n  }) |&gt;\n    invisible()\n\n  clusterExport(cl, c(\n    \"scores_iter\", \"data_train\", \"data_valid\", \"data_test\", \"priors\", \"params\", \n    \"target_name\"\n  ), envir = environment())\n  clusterExport(cl, c(\n    \"get_metrics_xgb_iter\", \"get_metrics_simul\", \"get_histogram\",\n    \"brier_score\",\n    \"get_perf_metrics\", \"compute_metrics\",\n    \"disp_metrics_dataset\", \"dispersion_metrics_beta\", \"prop_btw_quantiles\",\n    \"estim_prop\"\n  ))\n\n  metrics_iter &lt;-\n    pbapply::pblapply(\n      X = seq_len(params$nb_iter_total),\n      FUN = function(i_iter) {\n        get_metrics_xgb_iter(\n          scores = scores_iter[[i_iter]],\n          data_train = data_train,\n          data_valid = data_valid,\n          data_test = data_test,\n          target_name = target_name,\n          ind = params$ind,\n          nb_iter = i_iter\n        )\n      },\n      cl = cl\n    )\n  stopCluster(cl)\n\n  # Merge tibbles from each iteration into a single one\n  tb_metrics &lt;-\n    map(metrics_iter, \"tb_metrics\") |&gt;\n    list_rbind()\n  tb_disp_metrics &lt;-\n    map(metrics_iter, \"tb_disp_metrics\") |&gt;\n    list_rbind()\n  tb_prop_scores &lt;-\n    map(metrics_iter, \"tb_prop_scores\") |&gt;\n    list_rbind()\n  scores_hist &lt;- map(metrics_iter, \"scores_hist\")\n\n  list(\n    tb_metrics = tb_metrics,\n    tb_disp_metrics = tb_disp_metrics,\n    tb_prop_scores = tb_prop_scores,\n    scores_hist = scores_hist\n  )\n}\n\n\n\n\n15.1.2.3 GLM\nWe define a function to train a GLM model on a dataset and compute metrics on the estimated scores.\n\n\nFunction simul_glm()\n#' Train GLM (with logistic link) on a dataset for a binary task\n#' and computes metrics based on scores and on a set of prior\n#' distributions of the underlying probability (assumed to be \"true\" probs)\n#'\n#' @param data dataset\n#' @param target_name name of the target variable\n#' @param priors priors obtained with `get_beta_fit()`\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns A list with one elements:\n#'  - `res`: results for each estimated model of the grid. Each element is a\n#'   list with the following 4 arguments:\n#'      - `tb_metrics`: performance / calibration metrics\n#'      - `tb_disp_metrics`: disp and div metrics\n#'      - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'      - `scores_hist`: histogram of scores.\nsimul_glm &lt;- function(data,\n                      target_name,\n                      priors,\n                      seed = NULL) {\n  \n  # Split data into train and test set\n  data_splitted &lt;- split_train_test(data = data, prop_train = .8, seed = seed)\n  \n  # Further split train intro two samples (train/valid)\n  # Should not be done, but we need to do it here to have comparable results\n  # with ml models\n  data_splitted_train &lt;- split_train_test(\n    data = data_splitted$train, prop_train = .8, seed = seed\n  )\n  \n  ## Estimation----\n  fit &lt;- train_glm(\n    data_train = data_splitted_train$train, \n    data_test = data_splitted$test, \n    target_name = target_name,\n    return_model = FALSE\n  )\n  \n  ## Predicted scores----\n  scores_train &lt;- fit$scores_train\n  scores_test &lt;- fit$scores_test\n  ## Metrics----\n  metrics &lt;- get_metrics_simul(\n    scores_train = scores_train,\n    scores_valid = scores_test,# will not be used, sorry it is dirty\n    scores_test = scores_test,\n    tb_train = data_splitted_train$train,\n    tb_valid = data_splitted$test,# same here, will not be used\n    tb_test = data_splitted$test,\n    priors = priors,\n    target_name = target_name\n  )\n  \n  # Remove wrong info on validation sample, since there is no validation sample\n  metrics$tb_metrics &lt;- \n    metrics$tb_metrics |&gt; filter(sample != \"validation\")\n  metrics$tb_disp_metrics &lt;- \n    metrics$tb_disp_metrics |&gt; filter(sample != \"validation\")\n  metrics$tb_prop_scores &lt;- \n    metrics$tb_prop_scores |&gt; filter(sample != \"validation\")\n  metrics$scores_hist$valid &lt;- NULL\n  metrics\n}\n\n\n\n\n15.1.2.4 GAM\nWe define a function to train a GAM model on a dataset and compute metrics on the estimated scores.\n\n\nFunction simul_gam()\n#' Train GAM on a dataset for a binary task\n#' and computes metrics based on scores and on a set of prior\n#' distributions of the underlying probability (assumed to be \"true\" probs)\n#'\n#' @param data dataset\n#' @param target_name name of the target variable\n#' @param spline_df degree of freedom for the splines\n#' @param priors priors obtained with `get_beta_fit()`\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns A list with one elements:\n#'  - `res`: results for each estimated model of the grid. Each element is a\n#'   list with the following 4 arguments:\n#'      - `tb_metrics`: performance / calibration metrics\n#'      - `tb_disp_metrics`: disp and div metrics\n#'      - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'      - `scores_hist`: histogram of scores.\nsimul_gam &lt;- function(data,\n                      target_name,\n                      spline_df = 6,\n                      priors,\n                      seed = NULL) {\n  \n  # Split data into train and test set\n  data_splitted &lt;- split_train_test(data = data, prop_train = .8, seed = seed)\n  \n  # Further split train intro two samples (train/valid)\n  # Should not be done, but we need to do it here to have comparable results\n  # with ml models\n  data_splitted_train &lt;- split_train_test(\n    data = data_splitted$train, prop_train = .8, seed = seed\n  )\n  \n  ## Estimation----\n  fit &lt;- train_gam(\n    data_train = data_splitted_train$train,\n    data_test = data_splitted$test, \n    target_name = target_name,\n    spline_df = spline_df,\n    return_model = FALSE\n  )\n  \n  ## Predicted scores----\n  scores_train &lt;- fit$scores_train\n  scores_test &lt;- fit$scores_test\n  ## Metrics----\n  metrics &lt;- get_metrics_simul(\n    scores_train = scores_train,\n    scores_valid = scores_test,# will not be used, sorry it is dirty\n    scores_test = scores_test,\n    tb_train = data_splitted_train$train,\n    tb_valid = data_splitted$test,# same here, will not be used\n    tb_test = data_splitted$test,\n    priors = priors,\n    target_name = target_name\n  )\n  \n  # Remove wrong info on validation sample, since there is no validation sample\n  metrics$tb_metrics &lt;- \n    metrics$tb_metrics |&gt; filter(sample != \"validation\")\n  metrics$tb_disp_metrics &lt;- \n    metrics$tb_disp_metrics |&gt; filter(sample != \"validation\")\n  metrics$tb_prop_scores &lt;- \n    metrics$tb_prop_scores |&gt; filter(sample != \"validation\")\n  metrics$scores_hist$valid &lt;- NULL\n  metrics\n}\n\n\n\n\n15.1.2.5 GAMSEL\nWe define a function to train a GAMSEL model on a dataset and compute metrics on the estimated scores.\n\n\nFunction simul_gamsel()\n#' Train GAMSEL on a dataset for a binary task\n#' and computes metrics based on scores and on a set of prior\n#' distributions of the underlying probability (assumed to be \"true\" probs)\n#'\n#' @param data dataset\n#' @param target_name name of the target variable\n#' @param degrees degree for the splines\n#' @param priors priors obtained with `get_beta_fit()`\n#' @param seed desired seed (default to `NULL`)\n#'\n#' @returns A list with one elements:\n#'  - `res`: results for each estimated model of the grid. Each element is a\n#'   list with the following 4 arguments:\n#'      - `tb_metrics`: performance / calibration metrics\n#'      - `tb_disp_metrics`: disp and div metrics\n#'      - `tb_prop_scores`: table with P(q1 &lt; score &lt; q2)\n#'      - `scores_hist`: histogram of scores.\nsimul_gamsel &lt;- function(data,\n                         target_name,\n                         degrees = 6,\n                         priors,\n                         seed = NULL) {\n  \n  # Split data into train and test set\n  data_splitted &lt;- split_train_test(data = data, prop_train = .8, seed = seed)\n  \n  # Further split train intro two samples (train/valid)\n  # Should not be done, but we need to do it here to have comparable results\n  # with ml models\n  data_splitted_train &lt;- split_train_test(\n    data = data_splitted$train, prop_train = .8, seed = seed\n  )\n  \n  ## Estimation----\n  fit &lt;- train_gamsel(\n    data_train = data_splitted_train$train, \n    data_test = data_splitted$test, \n    target_name = target_name,\n    degrees = degrees,\n    return_model = FALSE\n  )\n  \n  ## Predicted scores----\n  scores_train &lt;- fit$scores_train\n  scores_test &lt;- fit$scores_test\n  \n  ind_na_test &lt;- which(is.na(scores_test))\n  if (length(ind_na_test) &gt; 0) {\n    scores_test &lt;- scores_test[-ind_na_test]\n    data_splitted$test &lt;- data_splitted$test[-ind_na_test,]\n  }\n  \n  ## Metrics----\n  metrics &lt;- get_metrics_simul(\n    scores_train = scores_train,\n    scores_valid = scores_test,# will not be used, sorry it is dirty\n    scores_test = scores_test,\n    tb_train = data_splitted_train$train,\n    tb_valid = data_splitted$test,# same here, will not be used\n    tb_test = data_splitted$test,\n    priors = priors,\n    target_name = target_name\n  )\n  \n  # Remove wrong info on validation sample, since there is no validation sample\n  metrics$tb_metrics &lt;- \n    metrics$tb_metrics |&gt; filter(sample != \"validation\")\n  metrics$tb_disp_metrics &lt;- \n    metrics$tb_disp_metrics |&gt; filter(sample != \"validation\")\n  metrics$tb_prop_scores &lt;- \n    metrics$tb_prop_scores |&gt; filter(sample != \"validation\")\n  metrics$scores_hist$valid &lt;- NULL\n  metrics\n}",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Estimations</span>"
    ]
  },
  {
    "objectID": "book_real_estimations.html#data",
    "href": "book_real_estimations.html#data",
    "title": "15  Estimations",
    "section": "15.2 Data",
    "text": "15.2 Data\nIn Chapter 14, we estimated the shapes of Beta distributions using fitted scores from three models (GLM, GAM, and GAMSEL) applied to various datasets from the UCI Machine Learning Repository. We saved these estimated priors and the datasets in R data files, which can now be easily loaded.\nThe list of datasets and the name of the target variable:\n\ndatasets &lt;- tribble(\n  ~name, ~target_name,\n  \"abalone\", \"Sex\",\n  \"adult\", \"high_income\",\n  \"bank\", \"y\",\n  \"default\", \"default\",\n  \"drybean\", \"is_dermason\",\n  \"coupon\", \"y\",\n  \"mushroom\", \"edible\",\n  \"occupancy\", \"Occupancy\",\n  \"winequality\", \"high_quality\",\n  \"spambase\", \"is_spam\"\n)\n\n\nfor (name in datasets$name) {\n  # The data\n  load(str_c(\"output/real-data/tb_\", name, \".rda\"))\n  # The Prior on the distribution of the scores\n  load(str_c(\"output/real-data/priors_\", name, \".rda\"))\n}",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Estimations</span>"
    ]
  },
  {
    "objectID": "book_real_estimations.html#sec-real-estimations-estimations",
    "href": "book_real_estimations.html#sec-real-estimations-estimations",
    "title": "15  Estimations",
    "section": "15.3 Estimations",
    "text": "15.3 Estimations\nThe models are estimated in parallel. The number of available cores can be determined using the following command:\n\nlibrary(future)\nnb_cores &lt;- future::availableCores() - 1\n\nWe use the following loop to estimate all the models across each dataset:\n\nseed &lt;- 1234\nfor (name in datasets$name) {\n  current_data &lt;- get(str_c(\"tb_\", name))\n  current_priors &lt;- get(str_c(\"priors_\", name))\n  current_target_name &lt;- datasets |&gt;\n    filter(name == !!name) |&gt; pull(target_name)\n  ## Random Forests----\n  plan(multisession, workers = nb_cores)\n  rf_resul &lt;- simul_forest_real(\n    data = current_data,\n    target_name = current_target_name,\n    priors = current_priors,\n    seed = seed\n  )\n  save(rf_resul, file = str_c(\"output/real-data/rf_resul_\", name, \".rda\"))\n\n  ## Extreme Gradient Boosting----\n  xgb_resul &lt;- simul_xgb_real(\n    data = current_data,\n    target_name = current_target_name,\n    priors = current_priors,\n    seed = seed\n  )\n  save(xgb_resul, file = str_c(\"output/real-data/xgb_resul_\", name, \".rda\"))\n\n  ## GLM----\n  glm_resul &lt;- simul_glm(\n    data = current_data,\n    target_name = current_target_name,\n    priors = current_priors,\n    seed = seed\n  )\n  save(glm_resul, file = str_c(\"output/real-data/glm_resul_\", name, \".rda\"))\n  \n  ## GAM----\n  gam_resul &lt;- simul_gam(\n    data = current_data,\n    target_name = current_target_name,\n    spline_df = 6,\n    priors = current_priors,\n    seed = seed\n  )\n  save(gam_resul, file = str_c(\"output/real-data/gam_resul_\", name, \".rda\"))\n\n  ## GAMSEL----\n  gamsel_resul &lt;- simul_gamsel(\n    data = current_data,\n    target_name = current_target_name,\n    degrees = 6,\n    priors = current_priors,\n    seed = seed\n  )\n  save(gamsel_resul, file = str_c(\"output/real-data/gamsel_resul_\", name, \".rda\"))\n}",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Estimations</span>"
    ]
  },
  {
    "objectID": "book_real_results.html",
    "href": "book_real_results.html",
    "title": "16  Results",
    "section": "",
    "text": "16.1 Estimated Metrics\nWe loop over the results obtained from Chapter 15 to extract the metrics.\ndatasets &lt;- tribble(\n  ~name, ~target_name,\n  \"abalone\", \"Sex\",\n  \"adult\", \"high_income\",\n  \"bank\", \"y\",\n  \"default\", \"default\",\n  \"drybean\", \"is_dermason\",\n  \"coupon\", \"y\",\n  \"mushroom\", \"edible\",\n  \"occupancy\", \"Occupancy\",\n  \"winequality\", \"high_quality\",\n  \"spambase\", \"is_spam\"\n)\nresult_table &lt;- vector(mode = \"list\", length = nrow(datasets))\npriors &lt;- vector(mode = \"list\", length = nrow(datasets))\nnames(priors) &lt;- datasets$name\nscores_hist &lt;- list()\nfor (i_model in 1:nrow(datasets)) {\n  name &lt;- datasets$name[i_model]\n  # Load priors\n  load(str_c(\"output/real-data/priors_\", name, \".rda\"))\n  priors[[i_model]] &lt;- get(str_c(\"priors_\", name))\n  # Load results\n  load(str_c(\"output/real-data/rf_resul_\", name, \".rda\"))\n  load(str_c(\"output/real-data/xgb_resul_\", name, \".rda\"))\n  model_interest &lt;-\n    get_model_interest(resul = rf_resul, model_type = \"rf\") |&gt;\n    bind_rows(get_model_interest(resul = xgb_resul, model_type = \"xgb\"))\n  result_table_ml &lt;- get_row_table(model_interest = model_interest, name = name)\n  \n  load(str_c(\"output/real-data/glm_resul_\", name, \".rda\"))\n  load(str_c(\"output/real-data/gam_resul_\", name, \".rda\"))\n  load(str_c(\"output/real-data/gamsel_resul_\", name, \".rda\"))\n  model_glms &lt;- get_model_interest(resul = glm_resul, model_type = \"glm\") |&gt; \n    bind_rows(get_model_interest(resul = gam_resul, model_type = \"gam\")) |&gt; \n    bind_rows(get_model_interest(resul = gamsel_resul, model_type = \"gamsel\"))\n  result_table_gl &lt;- get_row_table_glm(model_glms = model_glms, name = name)\n  \n  result_table[[i_model]] &lt;- result_table_ml |&gt; bind_rows(result_table_gl)\n\n  tb_ind_model_interest &lt;- \n    model_interest |&gt; filter(sample == \"test\") |&gt; \n    select(model_interest, model_type, ind)\n  \n  # Extract histograms for model of interest\n  scores_hist_current &lt;- list()\n  for (model in c(\"rf\", \"xgb\")) {\n    scores_hist_current_model &lt;- \n      tb_ind_model_interest |&gt; \n      filter(model_type == model) |&gt; \n      pull(\"ind\") |&gt; \n      map(~rf_resul$res[[.x]]$scores_hist)\n    for (j in 1:length(scores_hist_current_model)) {\n      scores_hist_current_model[[j]]$model_interest &lt;- \n        tb_ind_model_interest |&gt; \n        filter(model_type == !!model) |&gt; \n        pull(model_interest) |&gt; pluck(j)\n      scores_hist_current_model[[j]]$model_type &lt;- model\n      scores_hist_current_model[[j]]$name &lt;- name\n    }\n    scores_hist_current &lt;- c(scores_hist_current, scores_hist_current_model)\n  }\n  scores_hist &lt;- c(scores_hist, scores_hist_current)\n}\nCodes to create result tables\nred_colours &lt;- c(\n  \"#FFD6D6\", \"#FFCCCC\", \"#FFC2C2\", \"#FFB8B8\", \"#FFADAD\", \n  \"#FFA3A3\", \"#FF9999\", \"#FF8F8F\", \"#FF8585\", \"#FF7A7A\"\n)\nred_colours_txt &lt;- c(\n  \"#333333\", \"#333333\", \"#2B2B2B\", \"#2B2B2B\", \"#232323\", \n  \"#1F1F1F\", \"#1A1A1A\", \"#141414\", \"#101010\", \"#0A0A0A\"\n)\ngreen_colours &lt;- c(\n  \"#E9F6E9\", \"#D4F2D4\", \"#BFEFBF\", \"#AADCA9\", \"#96C996\",\n  \"#81B781\", \"#6CA56C\", \"#578252\", \"#426F42\", \"#2F5D2F\"\n)\ngreen_colours_txt &lt;- c(\n  \"#1A1A1A\", \"#1A1A1A\", \"#1A1A1A\", \"#1A1A1A\", \"#1A1A1A\",\n  \"#E6E6E6\", \"#E6E6E6\", \"#E6E6E6\", \"#E6E6E6\", \"#E6E6E6\"\n)\n\naccuracy_digits &lt;- 0.01\n\nget_range_for_colours &lt;- function(variable_name, table_kb) {\n  value &lt;- table_kb |&gt; \n    # filter(value_type == \"mean\") |&gt; \n    pull(!!variable_name) |&gt; \n    range(na.rm = TRUE) |&gt; abs() |&gt; max()\n  value * c(-1, 1)\n}\n\nget_colour &lt;- function(variable, value_type, min_or_max, colour_type, table_kb) {\n  variable_string &lt;- deparse(substitute(variable))\n  if (colour_type == \"bg\") {\n    # background colour\n    if (min_or_max == \"min\") {\n      colours &lt;- rev(c(rev(red_colours), green_colours))\n    } else {\n      colours &lt;- c(rev(red_colours), rev(green_colours))\n    }\n  } else {\n    # text colour\n    if (min_or_max == \"min\") {\n      colours &lt;- rev(c(rev(red_colours_txt), green_colours_txt))\n    } else {\n      colours &lt;- c(rev(red_colours_txt), rev(green_colours_txt))\n    }\n  }\n  kableExtra::spec_color(\n    variable,\n    palette = colours,\n    scale_from = get_range_for_colours(variable_string, table_kb = table_kb),\n    na_color = \"white\"\n  )\n}\n\nprint_table &lt;- function(format, \n                        table_kb, \n                        prior_model = c(\"glm\", \"gam\", \"gamsel\")) {\n  tb_with_colours &lt;- table_kb |&gt; \n    rowwise() |&gt; \n    mutate(\n      # When min KL\n      ## Delta AUC\n      diff_auc_bgcol = get_colour(\n        !!sym(str_c(\"diff_auc_\", prior_model)), value_type, \"max\", \"bg\", table_kb\n      ),\n      diff_auc_txtcol = get_colour(\n        !!sym(str_c(\"diff_auc_\", prior_model)), value_type, \"max\", \"txt\", table_kb\n      ),\n      ## Delta Brier\n      diff_brier_bgcol = get_colour(\n        !!sym(str_c(\"diff_brier_\", prior_model)), value_type, \"min\", \"bg\", table_kb\n      ),\n      diff_brier_txtcol = get_colour(\n        !!sym(str_c(\"diff_brier_\", prior_model)), value_type, \"min\", \"txt\", table_kb\n      ),\n      ## Delta ICI\n      diff_ici_bgcol = get_colour(\n        !!sym(str_c(\"diff_ici_\", prior_model)), value_type, \"min\", \"bg\", table_kb\n      ),\n      diff_ici_txtcol = get_colour(\n        !!sym(str_c(\"diff_ici_\", prior_model)), value_type, \"min\", \"txt\", table_kb\n      ),\n      ## Delta KL\n      diff_kl_bgcol = get_colour(\n        !!sym(str_c(\"diff_kl_\", prior_model)), value_type, \"min\", \"bg\", table_kb\n      ),\n      diff_kl_txtcol = get_colour(\n        !!sym(str_c(\"diff_kl_\", prior_model)), value_type, \"min\", \"txt\", table_kb\n      ),\n    )\n  \n  table_kb |&gt; \n     mutate(\n      across(\n        where(is.numeric), \n        ~scales::number(.x, accuracy = accuracy_digits)\n      )\n    ) |&gt; \n    knitr::kable(\n      col.names = c(\n        \"Dataset\", \"Model\",\n        \"AUC\", \"brier\", \"ICI\", \"KL\", \"Quant. Ratio\", # model with max AUC\n        \"AUC\", \"brier\", \"ICI\", \"KL\", \"Quant. Ratio\", # model with min Brier\n        \"AUC\", \"brier\", \"ICI\", \"KL\", \"Quant. Ratio\", # model with min ICI\n        \"AUC\", \"brier\", \"ICI\", \"KL\", \"Quant. Ratio\", \"ΔAUC\", \"ΔBrier\", \"ΔICI\", \"ΔKL\"\n      ),\n      escape = FALSE, booktabs = T, digits = 3, format = format) |&gt;\n    ## Delta AUC\n    kableExtra::column_spec(\n      which(colnames(table_kb) == str_c(\"diff_auc_\", prior_model)),\n      background = tb_with_colours$diff_auc_bgcol,\n      color = tb_with_colours$diff_auc_txtcol\n    ) |&gt;\n    ## Delta Brier\n    kableExtra::column_spec(\n      which(colnames(table_kb) == str_c(\"diff_brier_\", prior_model)),\n      background = tb_with_colours$diff_brier_bgcol,\n      color = tb_with_colours$diff_brier_txtcol\n    ) |&gt;\n    ## Delta ICI\n    kableExtra::column_spec(\n      which(colnames(table_kb) == str_c(\"diff_ici_\", prior_model)),\n      background = tb_with_colours$diff_ici_bgcol,\n      color = tb_with_colours$diff_ici_txtcol\n    ) |&gt;\n    ## Delta KL\n    kableExtra::column_spec(\n      which(colnames(table_kb) == str_c(\"diff_kl_\", prior_model)),\n      background = tb_with_colours$diff_kl_bgcol,\n      color = tb_with_colours$diff_kl_txtcol\n    ) |&gt;\n    kableExtra::collapse_rows(columns = 1:2, valign = \"top\") |&gt;\n    kableExtra::add_header_above(\n      c(\" \" = 2,\n        \"AUC*\" = 5,\n        \"Brier*\" = 5,\n        \"ICI*\" = 5,\n        \"KL*\" = 9\n      )\n    )\n}\n\nopts &lt;- options(knitr.kable.NA = \"\")\nThe estimated metrics for the GLM, GAM, and GAMSEL:\nCodes to create the table\ntbl_kb &lt;- result_table |&gt;\n  list_rbind() |&gt;\n  filter(model_type %in% c(\"glm\", \"gam\", \"gamsel\")) |&gt; \n  select(\n    dataset, model_type,\n    AUC_glm, brier_glm, ici_glm,\n    quant_ratio_glm_glm, quant_ratio_gam_gam, quant_ratio_gamsel_gamsel,\n    KL_glm_glm, KL_gam_gam, KL_gamsel_gamsel\n  ) |&gt;\n  mutate(\n    model_type = factor(\n      model_type, \n      levels = c(\"glm\", \"gam\", \"gamsel\"), \n      labels = c(\"GLM\", \"GAM\", \"GAMSEL\")\n    )\n  ) |&gt; \n  mutate(\n    across(\n      where(is.numeric), \n      ~scales::number(.x, accuracy = accuracy_digits)\n    )\n  )\n\ncbind(\n  tbl_kb |&gt; filter(dataset %in% datasets$name[1:5]),\n  tbl_kb |&gt; filter(dataset %in% datasets$name[6:10])\n) |&gt; \n  knitr::kable(\n    col.names = c(\n      rep(c(\"Dataset\",\"Model\",\n      \"AUC\", \"brier\", \"ICI\",\n      \"QR-GLM\", \"QR-GAM\", \"QR-GAMSEL\",\n      \"KL-GLM\", \"KL-GAM\", \"KL-GAMSEL\"\n      ), 2)\n    ),\n    escape = FALSE, booktabs = T, digits = 3, format = \"markdown\") |&gt;\n  kableExtra::collapse_rows(columns = c(1, 12), valign = \"top\")\n\n\n\n\n\n\nDataset\nModel\nAUC\nbrier\nICI\nQR-GLM\nQR-GAM\nQR-GAMSEL\nKL-GLM\nKL-GAM\nKL-GAMSEL\nDataset\nModel\nAUC\nbrier\nICI\nQR-GLM\nQR-GAM\nQR-GAMSEL\nKL-GLM\nKL-GAM\nKL-GAMSEL\n\n\n\n\nabalone\nGLM\n0.70\n0.20\n0.06\n1.06\n0.81\n1.06\n0.05\n0.11\n0.05\ncoupon\nGLM\n0.75\n0.20\n0.01\n1.05\n1.05\n1.17\n0.02\n0.02\n0.06\n\n\nGAM\n0.71\n0.20\n0.02\n1.27\n0.96\n1.26\n0.32\n0.13\n0.30\nGAM\n0.75\n0.20\n0.01\n1.05\n1.05\n1.17\n0.02\n0.02\n0.06\n\n\nGAMSEL\n0.71\n0.20\n0.04\n1.09\n0.83\n1.09\n0.11\n0.17\n0.10\nGAMSEL\n0.75\n0.20\n0.02\n0.94\n0.94\n1.05\n0.05\n0.05\n0.03\n\n\nadult\nGLM\n0.90\n0.10\n0.00\n0.92\n0.86\n1.13\n0.02\n0.02\n0.16\nmushroom\nGLM\n1.00\n0.00\n0.00\n1.00\n1.00\n1.02\n0.29\n0.29\n1.40\n\n\nGAM\n0.91\n0.10\n0.01\n0.96\n0.90\n1.18\n0.05\n0.03\n0.23\nGAM\n1.00\n0.00\n0.00\n1.00\n1.00\n1.02\n0.29\n0.29\n1.40\n\n\nGAMSEL\n0.90\n0.11\n0.03\n0.81\n0.76\n1.00\n0.06\n0.10\n0.05\nGAMSEL\n1.00\n0.01\n0.04\n0.94\n0.94\n0.96\n0.61\n0.61\n0.90\n\n\nbank\nGLM\n0.91\n0.07\n0.03\n0.83\n0.84\n1.00\n0.20\n0.15\n0.32\noccupancy\nGLM\n1.00\n0.01\n0.01\n1.02\n1.01\n1.13\n0.46\n0.35\n0.85\n\n\nGAM\n0.92\n0.07\n0.02\n0.92\n0.93\n1.10\n0.20\n0.14\n0.34\nGAM\n1.00\n0.01\n0.01\n1.02\n1.02\n1.14\n0.50\n0.38\n0.92\n\n\nGAMSEL\n0.91\n0.07\n0.03\n0.78\n0.79\n0.94\n0.13\n0.10\n0.20\nGAMSEL\n0.99\n0.02\n0.04\n0.93\n0.93\n1.04\n0.41\n0.34\n0.63\n\n\ndefault\nGLM\n0.77\n0.14\n0.02\n1.09\n1.06\n1.23\n0.45\n0.45\n0.49\nwinequality\nGLM\n0.74\n0.20\n0.04\n0.97\n0.75\n1.03\n0.06\n0.22\n0.06\n\n\nGAM\n0.78\n0.13\n0.01\n1.13\n1.10\n1.27\n0.29\n0.28\n0.35\nGAM\n0.79\n0.18\n0.04\n1.22\n0.95\n1.30\n0.14\n0.02\n0.21\n\n\nGAMSEL\n0.76\n0.14\n0.03\n0.94\n0.92\n1.07\n0.73\n0.75\n0.70\nGAMSEL\n0.75\n0.20\n0.04\n0.92\n0.72\n0.99\n0.04\n0.24\n0.03\n\n\ndrybean\nGLM\n0.99\n0.03\n0.01\n1.00\n1.00\n1.16\n0.06\n0.05\n0.57\nspambase\nGLM\n0.97\n0.06\n0.02\n1.00\n1.00\n1.05\n0.02\n0.15\n0.37\n\n\nGAM\n0.99\n0.03\n0.01\n1.00\n1.00\n1.17\n0.08\n0.07\n0.64\nGAM\n0.91\n0.08\n0.07\n1.00\n1.00\n1.05\n0.67\n0.29\n1.69\n\n\nGAMSEL\n0.99\n0.04\n0.06\n0.91\n0.91\n1.06\n0.19\n0.21\n0.06\nGAMSEL\n0.96\n0.07\n0.06\n0.96\n0.96\n1.01\n0.44\n0.98\n0.18",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "book_real_results.html#estimated-metrics",
    "href": "book_real_results.html#estimated-metrics",
    "title": "16  Results",
    "section": "",
    "text": "Priors from GLMPriors from GAMPriors from GAMSEL\n\n\n\n\nCodes to create the table\nresult_table_glm &lt;- \n  result_table |&gt;\n  list_rbind() |&gt;\n  filter(model_type %in% c(\"rf\", \"xgb\")) |&gt; \n  select(\n    dataset, model_type,\n    # model with max AUC\n    AUC_max_auc, brier_max_auc, ici_max_auc, KL_glm_max_auc, quant_ratio_glm_max_auc,\n    # model with min Brier\n    AUC_min_brier, brier_min_brier, ici_min_brier, KL_glm_min_brier, quant_ratio_glm_min_brier,\n    # model with min ICI\n    AUC_min_ici, brier_min_ici, ici_min_ici, KL_glm_min_ici, quant_ratio_glm_min_ici,\n    # model with min KL distance with prior from GLM\n    AUC_glm, brier_glm, ici_glm, KL_glm_glm, quant_ratio_glm_glm,\n    diff_auc_glm, diff_brier_glm, diff_ici_glm, diff_kl_glm \n  ) |&gt;\n  mutate(\n    model_type = factor(\n      model_type, \n      levels = c(\"rf\", \"xgb\", \"glm\", \"gam\", \"gamsel\"), \n      labels = c(\"RF\", \"XGB\", \"GLM\", \"GAM\", \"GAMSEL\")\n    )\n  )\n\nprint_table(\n  format = \"markdown\", table_kb = result_table_glm, prior_model = \"glm\"\n)\n\n\n\n\nTable 16.1: Comparison of metrics for models chosen based on AUC, on AIC, or on KL divergence with a prior on the distribution of the probabilities estimated with a GLM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\nBrier*\n\n\nICI*\n\n\nKL*\n\n\n\nDataset\nModel\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nΔAUC\nΔBrier\nΔICI\nΔKL\n\n\n\n\nabalone\nRF\n0.71\n0.20\n0.03\n0.34\n1.21\n0.71\n0.20\n0.03\n0.34\n1.24\n0.51\n0.23\n0.02\n2.73\n0.00\n0.71\n0.20\n0.03\n0.33\n1.28\n0.00\n0.00\n0.00\n-0.01\n\n\nXGB\n0.69\n0.20\n0.03\n0.42\n1.45\n0.69\n0.20\n0.04\n0.56\n1.06\n0.70\n0.20\n0.04\n0.80\n1.03\n0.69\n0.21\n0.05\n0.24\n1.23\n0.00\n0.00\n0.02\n-0.18\n\n\nadult\nRF\n0.92\n0.10\n0.03\n0.03\n0.88\n0.92\n0.10\n0.03\n0.02\n0.89\n0.51\n0.18\n0.00\n4.46\n0.00\n0.92\n0.10\n0.03\n0.02\n0.89\n0.00\n0.00\n0.00\n-0.01\n\n\nXGB\n0.93\n0.09\n0.01\n0.09\n1.00\n0.93\n0.09\n0.01\n0.09\n1.00\n0.93\n0.09\n0.01\n0.09\n0.97\n0.91\n0.10\n0.02\n0.04\n0.90\n-0.01\n0.01\n0.01\n-0.05\n\n\nbank\nRF\n0.94\n0.06\n0.02\n0.19\n1.08\n0.94\n0.06\n0.02\n0.21\n1.10\n0.94\n0.06\n0.02\n0.21\n1.12\n0.92\n0.07\n0.04\n0.07\n0.82\n-0.02\n0.01\n0.02\n-0.12\n\n\nXGB\n0.93\n0.06\n0.02\n0.36\n1.17\n0.93\n0.06\n0.02\n0.28\n1.12\n0.93\n0.06\n0.02\n0.34\n1.15\n0.91\n0.07\n0.03\n0.07\n0.93\n-0.02\n0.00\n0.01\n-0.29\n\n\ndefault\nRF\n0.78\n0.13\n0.02\n0.20\n1.10\n0.78\n0.13\n0.01\n0.18\n1.12\n0.78\n0.13\n0.01\n0.16\n1.15\n0.77\n0.14\n0.02\n0.13\n1.17\n-0.02\n0.00\n0.00\n-0.07\n\n\nXGB\n0.78\n0.13\n0.01\n0.23\n1.17\n0.78\n0.13\n0.01\n0.29\n1.15\n0.78\n0.13\n0.01\n0.22\n1.19\n0.77\n0.13\n0.01\n0.19\n1.17\n-0.01\n0.00\n0.00\n-0.04\n\n\ndrybean\nRF\n0.99\n0.03\n0.01\n0.06\n1.00\n0.99\n0.03\n0.01\n0.07\n1.00\n0.99\n0.03\n0.01\n0.06\n1.00\n0.99\n0.03\n0.02\n0.02\n0.98\n0.00\n0.00\n0.01\n-0.04\n\n\nXGB\n0.99\n0.03\n0.01\n0.08\n1.00\n0.99\n0.03\n0.01\n0.09\n1.00\n0.99\n0.03\n0.01\n0.09\n1.00\n0.99\n0.03\n0.04\n0.07\n0.92\n0.00\n0.00\n0.03\n-0.02\n\n\ncoupon\nRF\n0.83\n0.17\n0.07\n0.04\n0.98\n0.83\n0.17\n0.07\n0.04\n0.98\n0.51\n0.24\n0.00\n3.60\n0.00\n0.83\n0.17\n0.07\n0.04\n0.98\n0.00\n0.00\n0.00\n0.00\n\n\nXGB\n0.84\n0.17\n0.10\n2.27\n1.74\n0.84\n0.16\n0.03\n0.81\n1.53\n0.83\n0.16\n0.02\n0.37\n1.39\n0.78\n0.19\n0.03\n0.04\n1.03\n-0.06\n0.02\n-0.07\n-2.23\n\n\nmushroom\nRF\n1.00\n0.01\n0.05\n0.23\n0.96\n1.00\n0.00\n0.01\n0.22\n1.00\n1.00\n0.00\n0.01\n0.22\n1.00\n1.00\n0.01\n0.04\n0.11\n0.99\n0.00\n0.00\n-0.02\n-0.12\n\n\nXGB\n1.00\n0.00\n0.00\n0.28\n1.00\n1.00\n0.00\n0.00\n0.29\n1.00\n1.00\n0.00\n0.00\n0.28\n1.00\n1.00\n0.01\n0.04\n0.13\n0.97\n0.00\n0.01\n0.03\n-0.15\n\n\noccupancy\nRF\n1.00\n0.01\n0.00\n0.56\n1.04\n1.00\n0.01\n0.00\n0.57\n1.04\n1.00\n0.01\n0.00\n0.57\n1.04\n1.00\n0.01\n0.04\n0.31\n0.97\n0.00\n0.01\n0.03\n-0.25\n\n\nXGB\n1.00\n0.01\n0.01\n0.60\n1.04\n1.00\n0.01\n0.01\n0.66\n1.04\n1.00\n0.01\n0.00\n0.54\n1.03\n1.00\n0.01\n0.04\n0.47\n0.95\n0.00\n0.00\n0.04\n-0.13\n\n\nwinequality\nRF\n0.89\n0.14\n0.07\n0.32\n1.42\n0.89\n0.13\n0.03\n0.69\n1.58\n0.51\n0.24\n0.03\n3.43\n0.00\n0.84\n0.17\n0.08\n0.05\n1.07\n-0.05\n0.03\n0.01\n-0.27\n\n\nXGB\n0.87\n0.15\n0.12\n4.06\n1.97\n0.86\n0.14\n0.04\n1.63\n1.75\n0.83\n0.17\n0.03\n0.35\n1.39\n0.80\n0.18\n0.04\n0.11\n1.12\n-0.07\n0.03\n-0.08\n-3.96\n\n\nspambase\nRF\n0.99\n0.05\n0.06\n0.21\n0.96\n0.99\n0.04\n0.04\n0.10\n0.98\n0.51\n0.24\n0.01\n6.08\n0.00\n0.99\n0.04\n0.04\n0.10\n0.98\n0.00\n0.00\n-0.02\n-0.11\n\n\nXGB\n0.98\n0.04\n0.01\n0.23\n1.00\n0.99\n0.04\n0.01\n0.17\n1.00\n0.99\n0.04\n0.01\n0.17\n1.00\n0.98\n0.04\n0.01\n0.10\n0.99\n0.00\n0.01\n0.00\n-0.13\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the table\nresult_table_gam &lt;- \n  result_table |&gt;\n  list_rbind() |&gt;\n  filter(model_type %in% c(\"rf\", \"xgb\")) |&gt; \n  select(\n    dataset, model_type,\n    # model with max AUC\n    AUC_max_auc, brier_max_auc, ici_max_auc, KL_gam_max_auc, quant_ratio_gam_max_auc,\n    # model with min Brier\n    AUC_min_brier, brier_min_brier, ici_min_brier, quant_ratio_gam_min_brier, KL_gam_min_brier,\n    # model with min ICI\n    AUC_min_ici, brier_min_ici, ici_min_ici, KL_gam_min_ici, quant_ratio_gam_min_ici,\n    # model with min KL distance with prior from GAM\n    AUC_gam, brier_gam, ici_gam, KL_gam_gam, quant_ratio_gam_gam,\n    diff_auc_gam, diff_brier_gam, diff_ici_gam, diff_kl_gam \n  ) |&gt;\n  mutate(\n    model_type = factor(\n      model_type, \n      levels = c(\"rf\", \"xgb\", \"glm\", \"gam\", \"gamsel\"), \n      labels = c(\"RF\", \"XGB\", \"GLM\", \"GAM\", \"GAMSEL\")\n    )\n  )\n\n\nprint_table(\n  format = \"markdown\", table_kb = result_table_gam, prior_model = \"gam\"\n)\n\n\n\n\nTable 16.2: Comparison of metrics for models chosen based on AUC, on AIC, or on KL divergence with a prior on the distribution of the probabilities estimated with a GAM.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\nBrier*\n\n\nICI*\n\n\nKL*\n\n\n\nDataset\nModel\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nΔAUC\nΔBrier\nΔICI\nΔKL\n\n\n\n\nabalone\nRF\n0.71\n0.20\n0.03\n0.24\n0.92\n0.71\n0.20\n0.03\n0.94\n0.21\n0.51\n0.23\n0.02\n3.18\n0.00\n0.70\n0.20\n0.04\n0.13\n1.07\n-0.01\n0.00\n0.01\n-0.11\n\n\nXGB\n0.69\n0.20\n0.03\n0.12\n1.11\n0.69\n0.20\n0.04\n0.80\n0.58\n0.70\n0.20\n0.04\n0.92\n0.78\n0.69\n0.21\n0.04\n0.14\n1.26\n0.00\n0.00\n0.01\n0.02\n\n\nadult\nRF\n0.92\n0.10\n0.03\n0.06\n0.83\n0.92\n0.10\n0.03\n0.83\n0.04\n0.51\n0.18\n0.00\n4.63\n0.00\n0.92\n0.10\n0.03\n0.04\n0.83\n0.00\n0.00\n0.00\n-0.01\n\n\nXGB\n0.93\n0.09\n0.01\n0.06\n0.93\n0.93\n0.09\n0.01\n0.93\n0.06\n0.93\n0.09\n0.01\n0.06\n0.91\n0.92\n0.09\n0.01\n0.05\n0.88\n-0.01\n0.00\n0.01\n-0.02\n\n\nbank\nRF\n0.94\n0.06\n0.02\n0.14\n1.09\n0.94\n0.06\n0.02\n1.11\n0.15\n0.94\n0.06\n0.02\n0.15\n1.13\n0.92\n0.07\n0.04\n0.05\n0.87\n-0.01\n0.01\n0.02\n-0.08\n\n\nXGB\n0.93\n0.06\n0.02\n0.28\n1.18\n0.93\n0.06\n0.02\n1.13\n0.21\n0.93\n0.06\n0.02\n0.26\n1.16\n0.91\n0.07\n0.03\n0.05\n0.96\n-0.02\n0.00\n0.01\n-0.23\n\n\ndefault\nRF\n0.78\n0.13\n0.02\n0.20\n1.07\n0.78\n0.13\n0.01\n1.09\n0.17\n0.78\n0.13\n0.01\n0.15\n1.12\n0.77\n0.14\n0.02\n0.12\n1.14\n-0.02\n0.00\n0.00\n-0.08\n\n\nXGB\n0.78\n0.13\n0.01\n0.22\n1.14\n0.78\n0.13\n0.01\n1.12\n0.29\n0.78\n0.13\n0.01\n0.20\n1.16\n0.77\n0.13\n0.01\n0.17\n1.14\n-0.01\n0.00\n0.00\n-0.05\n\n\ndrybean\nRF\n0.99\n0.03\n0.01\n0.05\n1.00\n0.99\n0.03\n0.01\n1.00\n0.06\n0.99\n0.03\n0.01\n0.05\n1.00\n0.99\n0.03\n0.02\n0.02\n0.98\n0.00\n0.00\n0.01\n-0.03\n\n\nXGB\n0.99\n0.03\n0.01\n0.07\n1.00\n0.99\n0.03\n0.01\n1.00\n0.08\n0.99\n0.03\n0.01\n0.08\n1.00\n0.99\n0.03\n0.02\n0.05\n0.97\n0.00\n0.00\n0.01\n-0.02\n\n\ncoupon\nRF\n0.83\n0.17\n0.07\n0.04\n0.98\n0.83\n0.17\n0.07\n0.98\n0.04\n0.51\n0.24\n0.00\n3.60\n0.00\n0.83\n0.17\n0.07\n0.04\n0.98\n0.00\n0.00\n0.00\n0.00\n\n\nXGB\n0.84\n0.17\n0.10\n2.27\n1.74\n0.84\n0.16\n0.03\n1.53\n0.81\n0.83\n0.16\n0.02\n0.37\n1.39\n0.78\n0.19\n0.03\n0.04\n1.03\n-0.06\n0.02\n-0.07\n-2.23\n\n\nmushroom\nRF\n1.00\n0.01\n0.05\n0.23\n0.96\n1.00\n0.00\n0.01\n1.00\n0.22\n1.00\n0.00\n0.01\n0.22\n1.00\n1.00\n0.01\n0.04\n0.11\n0.99\n0.00\n0.00\n-0.02\n-0.12\n\n\nXGB\n1.00\n0.00\n0.00\n0.28\n1.00\n1.00\n0.00\n0.00\n1.00\n0.29\n1.00\n0.00\n0.00\n0.28\n1.00\n1.00\n0.01\n0.04\n0.13\n0.97\n0.00\n0.01\n0.03\n-0.15\n\n\noccupancy\nRF\n1.00\n0.01\n0.00\n0.43\n1.03\n1.00\n0.01\n0.00\n1.03\n0.44\n1.00\n0.01\n0.00\n0.44\n1.03\n1.00\n0.01\n0.02\n0.26\n0.99\n0.00\n0.00\n0.02\n-0.17\n\n\nXGB\n1.00\n0.01\n0.01\n0.47\n1.03\n1.00\n0.01\n0.01\n1.03\n0.52\n1.00\n0.01\n0.00\n0.41\n1.02\n1.00\n0.01\n0.04\n0.37\n0.94\n0.00\n0.00\n0.04\n-0.10\n\n\nwinequality\nRF\n0.89\n0.14\n0.07\n0.04\n1.10\n0.89\n0.13\n0.03\n1.23\n0.12\n0.51\n0.24\n0.03\n3.95\n0.00\n0.86\n0.15\n0.06\n0.03\n1.02\n-0.03\n0.02\n-0.01\n-0.01\n\n\nXGB\n0.87\n0.15\n0.12\n1.91\n1.53\n0.86\n0.14\n0.04\n1.36\n0.53\n0.83\n0.17\n0.03\n0.04\n1.08\n0.82\n0.17\n0.03\n0.04\n1.00\n-0.06\n0.02\n-0.08\n-1.87\n\n\nspambase\nRF\n0.99\n0.05\n0.06\n0.63\n0.96\n0.99\n0.04\n0.04\n0.98\n0.37\n0.51\n0.24\n0.01\n7.17\n0.00\n0.99\n0.04\n0.04\n0.37\n0.98\n0.00\n0.00\n-0.02\n-0.26\n\n\nXGB\n0.98\n0.04\n0.01\n0.03\n1.00\n0.99\n0.04\n0.01\n1.00\n0.03\n0.99\n0.04\n0.01\n0.03\n1.00\n0.98\n0.04\n0.02\n0.04\n1.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodes to create the table\nresult_table_gamsel &lt;- \n  result_table |&gt;\n  list_rbind() |&gt;\n  filter(model_type %in% c(\"rf\", \"xgb\")) |&gt; \n  select(\n    dataset, model_type,\n    # model with max AUC\n    AUC_max_auc, brier_max_auc, ici_max_auc, KL_gamsel_max_auc, quant_ratio_gamsel_max_auc,\n    # model with min Brier\n    AUC_min_brier, brier_min_brier, ici_min_brier, KL_gamsel_min_brier, quant_ratio_gamsel_min_brier,\n    # model with min ICI\n    AUC_min_ici, brier_min_ici, ici_min_ici, KL_gamsel_min_ici, quant_ratio_gamsel_min_ici,\n    # model with min KL distance with prior from GAMSEL\n    AUC_gamsel, brier_gamsel, ici_gamsel, KL_gamsel_gamsel, quant_ratio_gamsel_gamsel,\n    diff_auc_gamsel, diff_brier_gamsel, diff_ici_gamsel, diff_kl_gamsel \n  ) |&gt;\n  mutate(\n    model_type = factor(\n      model_type, \n      levels = c(\"rf\", \"xgb\", \"glm\", \"gam\", \"gamsel\"), \n      labels = c(\"RF\", \"XGB\", \"GLM\", \"GAM\", \"GAMSEL\")\n    )\n  )\n\n\nprint_table(\n  format = \"markdown\", table_kb = result_table_gamsel, prior_model = \"gamsel\"\n)\n\n\n\n\nTable 16.3: Comparison of metrics for models chosen based on AUC, on AIC, or on KL divergence with a prior on the distribution of the probabilities estimated with a GAMSEL.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAUC*\n\n\nBrier*\n\n\nICI*\n\n\nKL*\n\n\n\nDataset\nModel\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nAUC\nbrier\nICI\nKL\nQuant. Ratio\nΔAUC\nΔBrier\nΔICI\nΔKL\n\n\n\n\nabalone\nRF\n0.71\n0.20\n0.03\n0.33\n1.21\n0.71\n0.20\n0.03\n0.33\n1.23\n0.51\n0.23\n0.02\n2.74\n0.00\n0.71\n0.20\n0.03\n0.32\n1.28\n0.00\n0.00\n0.00\n-0.01\n\n\nXGB\n0.69\n0.20\n0.03\n0.40\n1.45\n0.69\n0.20\n0.04\n0.56\n1.06\n0.70\n0.20\n0.04\n0.80\n1.02\n0.69\n0.21\n0.05\n0.24\n1.23\n0.00\n0.00\n0.02\n-0.16\n\n\nadult\nRF\n0.92\n0.10\n0.03\n0.08\n1.09\n0.92\n0.10\n0.03\n0.09\n1.10\n0.51\n0.18\n0.00\n3.96\n0.00\n0.91\n0.10\n0.05\n0.04\n0.98\n-0.01\n0.01\n0.02\n-0.04\n\n\nXGB\n0.93\n0.09\n0.01\n0.35\n1.23\n0.93\n0.09\n0.01\n0.35\n1.23\n0.93\n0.09\n0.01\n0.34\n1.20\n0.91\n0.10\n0.03\n0.09\n1.04\n-0.02\n0.01\n0.02\n-0.26\n\n\nbank\nRF\n0.94\n0.06\n0.02\n0.31\n1.30\n0.94\n0.06\n0.02\n0.34\n1.32\n0.94\n0.06\n0.02\n0.35\n1.34\n0.91\n0.07\n0.05\n0.06\n0.87\n-0.03\n0.01\n0.03\n-0.25\n\n\nXGB\n0.93\n0.06\n0.02\n0.57\n1.40\n0.93\n0.06\n0.02\n0.46\n1.34\n0.93\n0.06\n0.02\n0.54\n1.38\n0.89\n0.07\n0.04\n0.07\n0.80\n-0.04\n0.01\n0.02\n-0.50\n\n\ndefault\nRF\n0.78\n0.13\n0.02\n0.22\n1.24\n0.78\n0.13\n0.01\n0.23\n1.27\n0.78\n0.13\n0.01\n0.24\n1.30\n0.78\n0.14\n0.03\n0.20\n1.07\n0.00\n0.00\n0.01\n-0.02\n\n\nXGB\n0.78\n0.13\n0.01\n0.34\n1.32\n0.78\n0.13\n0.01\n0.36\n1.30\n0.78\n0.13\n0.01\n0.35\n1.35\n0.79\n0.13\n0.01\n0.34\n1.28\n0.00\n0.00\n0.00\n0.00\n\n\ndrybean\nRF\n0.99\n0.03\n0.01\n0.56\n1.17\n0.99\n0.03\n0.01\n0.59\n1.17\n0.99\n0.03\n0.01\n0.57\n1.17\n0.99\n0.04\n0.05\n0.12\n1.08\n0.00\n0.01\n0.04\n-0.44\n\n\nXGB\n0.99\n0.03\n0.01\n0.62\n1.16\n0.99\n0.03\n0.01\n0.63\n1.17\n0.99\n0.03\n0.01\n0.65\n1.17\n0.99\n0.03\n0.03\n0.37\n1.09\n0.00\n0.00\n0.02\n-0.25\n\n\ncoupon\nRF\n0.83\n0.17\n0.07\n0.04\n1.10\n0.83\n0.17\n0.07\n0.04\n1.10\n0.51\n0.24\n0.00\n3.40\n0.00\n0.82\n0.18\n0.07\n0.03\n1.02\n-0.01\n0.01\n0.00\n-0.01\n\n\nXGB\n0.84\n0.17\n0.10\n3.15\n1.94\n0.84\n0.16\n0.03\n1.27\n1.72\n0.83\n0.16\n0.02\n0.66\n1.55\n0.77\n0.19\n0.03\n0.05\n1.07\n-0.07\n0.02\n-0.07\n-3.10\n\n\nmushroom\nRF\n1.00\n0.01\n0.05\n0.65\n0.98\n1.00\n0.00\n0.01\n1.28\n1.02\n1.00\n0.00\n0.01\n1.28\n1.02\n1.00\n0.03\n0.07\n0.41\n0.97\n0.00\n0.02\n0.02\n-0.24\n\n\nXGB\n1.00\n0.00\n0.00\n1.40\n1.02\n1.00\n0.00\n0.00\n1.40\n1.02\n1.00\n0.00\n0.00\n1.40\n1.02\n1.00\n0.02\n0.05\n0.57\n0.95\n0.00\n0.02\n0.05\n-0.83\n\n\noccupancy\nRF\n1.00\n0.01\n0.00\n1.02\n1.15\n1.00\n0.01\n0.00\n1.02\n1.15\n1.00\n0.01\n0.00\n1.02\n1.15\n1.00\n0.02\n0.07\n0.37\n1.02\n0.00\n0.02\n0.07\n-0.65\n\n\nXGB\n1.00\n0.01\n0.01\n1.07\n1.15\n1.00\n0.01\n0.01\n1.14\n1.15\n1.00\n0.01\n0.00\n0.97\n1.14\n1.00\n0.01\n0.04\n0.82\n1.05\n0.00\n0.00\n0.04\n-0.24\n\n\nwinequality\nRF\n0.89\n0.14\n0.07\n0.44\n1.51\n0.89\n0.13\n0.03\n0.88\n1.68\n0.51\n0.24\n0.03\n3.35\n0.00\n0.83\n0.17\n0.08\n0.05\n1.05\n-0.06\n0.04\n0.01\n-0.38\n\n\nXGB\n0.87\n0.15\n0.12\n4.66\n2.10\n0.86\n0.14\n0.04\n1.95\n1.86\n0.83\n0.17\n0.03\n0.47\n1.48\n0.80\n0.18\n0.04\n0.13\n1.12\n-0.08\n0.03\n-0.07\n-4.53\n\n\nspambase\nRF\n0.99\n0.05\n0.06\n0.17\n1.00\n0.99\n0.04\n0.04\n0.26\n1.03\n0.51\n0.24\n0.01\n4.96\n0.00\n0.97\n0.07\n0.08\n0.07\n0.95\n-0.01\n0.02\n0.02\n-0.10\n\n\nXGB\n0.98\n0.04\n0.01\n1.01\n1.05\n0.99\n0.04\n0.01\n0.88\n1.05\n0.99\n0.04\n0.01\n0.87\n1.05\n0.98\n0.05\n0.04\n0.27\n1.00\n-0.01\n0.02\n0.02\n-0.75",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "book_real_results.html#distribution-of-scores",
    "href": "book_real_results.html#distribution-of-scores",
    "title": "16  Results",
    "section": "16.2 Distribution of Scores",
    "text": "16.2 Distribution of Scores\nLet us construct a tibble with the information to extract the histograms for models of interest:\n\nscores_ref_tibble &lt;- \n  map(scores_hist, ~tibble(\n    ind = .x$ind,\n    model_interest = .x$model_interest,\n    model_type = .x$model_type,\n    name = .x$name\n  )) |&gt; \n  list_rbind() |&gt; \n  mutate(ind_list = row_number())\n\nSome colours for the priors:\n\nprior_model_names &lt;- tribble(\n  ~name, ~label, ~colour,\n  \"glm\", \"GLM\", \"#D55E00\",\n  \"gam\", \"GAM\", \"#0072B2\",\n  \"gamsel\", \"GAMSEL\", \"#E69F00\"\n)\n\nWe define a (too long) function to create the plots. The left panel displays the score distribution estimated using a Generalized Linear Model. The middle panel presents scores estimated by the Random Forest and XGB models when maximizing the AUC. The right panel illustrates scores estimated by the Random Forest and XGB models when minimizing the KL divergence relative to the assumed probability distribution (a Beta distribution with shape parameters estimated from the scores in the left panel, see Chapter 14).\n\n\nDisplay the too long plot function\nprint_plot &lt;- function(prior_model, names) {\n  prior_name &lt;- prior_model_names |&gt; filter(name == !!prior_model) |&gt; \n    pull(\"label\")\n  col_titles &lt;- c(prior_name, \"AUC*\", \"KL*\")\n  layout(\n    matrix(\n      data = c(\n        1:3,\n        4:(length(names)*3+3),\n        rep(length(names)*3+4, 3)\n      ),\n      ncol = 3, byrow = TRUE\n    ), \n    heights = c(.5, rep(3, length(names)), .75)\n  )\n  \n  # layout(matrix(c(1:6), ncol=3, byrow=T),heights = c(.5,3))\n  par(mar = c(0, 4.1, 0, 2.1))\n  for (i in 1:3) {\n    plot(c(0, 1), c(0, 1), ann = F, bty = 'n', type = 'n', xaxt = 'n', yaxt = 'n')\n    text(x = 0.5, y = 0.5, col_titles[i], cex = 1.6, col = \"black\")\n  }\n  \n  colour_rf &lt;- \"#009E73\"\n  colour_xgb &lt;- \"#CC79A7\"\n  \n  for (name in names) {\n    # Get the histogram of scores estimated with the generalized linear model\n    scores_prior &lt;- priors[[name]][[str_c(\"scores_\", prior_model)]]$scores_test\n    priors_shapes &lt;- priors[[name]][[str_c(\"mle_\", prior_model)]]\n    colour_prior &lt;- prior_model_names |&gt; filter(name == !!prior_model) |&gt; \n      pull(\"colour\")\n    \n    \n    par(mar = c(4.1, 4.1, 1.1, 1.1))\n    breaks &lt;- seq(0, 1, by = .05)\n    p_scores_prior &lt;- hist(\n      scores_prior, \n      breaks = breaks,\n      plot = FALSE\n    )\n    val_u &lt;- seq(0, 1, length = 651)\n    dens_prior &lt;- \n      dbeta(val_u, priors_shapes$estimate[1], priors_shapes$estimate[2])\n    # Scores estimates with RF and XBG, maximizing AUC\n    ind_score_hist_rf_auc &lt;- \n      scores_ref_tibble |&gt; \n      filter(model_interest == \"max_auc\", model_type == \"rf\", name == !!name) |&gt; \n      pull(\"ind_list\")\n    ind_score_hist_xgb_auc &lt;- \n      scores_ref_tibble |&gt; \n      filter(model_interest == \"max_auc\", model_type == \"xgb\", name == !!name) |&gt; \n      pull(\"ind_list\")\n    # Scores estimates with RF and XBG, minimizing KL\n    ind_score_hist_rf_kl &lt;- \n      scores_ref_tibble |&gt; \n      filter(model_interest == !!prior_model, model_type == \"rf\", name == !!name) |&gt; \n      pull(\"ind_list\")\n    ind_score_hist_xgb_kl &lt;- \n      scores_ref_tibble |&gt; \n      filter(model_interest == !!prior_model, model_type == \"xgb\", name == !!name) |&gt; \n      pull(\"ind_list\")\n    \n    p_max_auc_rf &lt;- scores_hist[[ind_score_hist_rf_auc]]$test\n    p_max_auc_xgb &lt;- scores_hist[[ind_score_hist_xgb_auc]]$test\n    p_min_kl_rf &lt;- scores_hist[[ind_score_hist_rf_kl]]$test\n    p_min_kl_xgb &lt;- scores_hist[[ind_score_hist_xgb_kl]]$test\n    \n    y_lim &lt;- c(\n      range(dens_prior[!is.infinite(dens_prior)]),\n      range(p_scores_prior$density),\n      range(p_max_auc_rf$density),\n      range(p_max_auc_xgb$density),\n      range(p_min_kl_rf$density),\n      range(p_min_kl_xgb$density)\n    ) |&gt; range()\n    \n    x_lab &lt;- latex2exp::TeX(\"$\\\\hat{s}(x)$\")\n    plot(\n      p_scores_prior,\n      main = \"\",\n      xlab = x_lab,\n      ylab = \"\",\n      freq = FALSE,\n      ylim = y_lim,\n      col = adjustcolor(colour_prior, alpha.f = .5)\n    )\n    lines(val_u, dens_prior, col = colour_prior, lwd = 1.5)\n    # mtext(text = substitute(paste(bold(name))), side = 2, \n    #       line = 3, cex = 1, las = 0)\n    mtext(text = name, side = 2, line = 3, cex = 1.1, las = 0)\n    \n    # Plot for max AUC\n    plot(\n      p_max_auc_rf,\n      # main = \"AUC*\",\n      main = \"\",\n      xlab = x_lab,\n      ylab = \"\",\n      freq = FALSE,\n      col = adjustcolor(colour_rf, alpha.f = .5),\n      ylim = y_lim\n    )\n    plot(\n      p_max_auc_xgb,\n      add = TRUE,\n      freq = FALSE,\n      col = adjustcolor(colour_xgb, alpha.f = .5),\n      y_lim = y_lim\n    )\n    lines(val_u, dens_prior, col = colour_prior, lwd = 1.5)\n    \n    # Plot for min KL\n    plot(\n      p_min_kl_rf,\n      # main = \"KL*\",\n      main = \"\",\n      xlab = x_lab,\n      ylab = \"\",\n      freq = FALSE,\n      col = adjustcolor(colour_rf, alpha.f = .5),\n      ylim = y_lim\n    )\n    plot(\n      p_min_kl_xgb,\n      add = TRUE,\n      freq = FALSE,\n      col = adjustcolor(colour_xgb, alpha.f = .5),\n      ylim = y_lim\n    )\n    lines(val_u, dens_prior, col = colour_prior, lwd = 1.5)\n  }\n  \n  \n  par(mar = c(0, 4.1, 0, 1.1))\n  plot.new()\n  legend(\n    xpd = TRUE, ncol = 4,\n    \"center\",\n    lwd = c(1.5, rep(NA, 3)),\n    col = c(colour_prior, rep(NA, 3)),\n    fill = c(0, colour_prior, colour_rf, colour_xgb),\n    legend = c(str_c(\"Prior distribution (\", prior_name,\")\"), prior_name, \"Random forest\", \"Extreme Gradient Boosting\"),\n    border=c(NA, \"black\",\"black\",\"black\")\n  )\n}\n\n\n\nPrior from GLMPrior from GAMPrior from GAMSEL\n\n\n\nDatasets 1–5Datasets 6–10\n\n\n\nprint_plot(prior_model = \"glm\", names = datasets$name[1:5])\n\n\n\nEstimated scores on the first five datasets: GLM (left), models selected by AUC maximization (middle), and KL divergence minimization relative to prior assumptions (right).\n\n\n\n\n\n\n\n\nprint_plot(prior_model = \"glm\", names = datasets$name[6:10])\n\n\n\nEstimated scores on the first last datasets: GLM (left), models selected by AUC maximization (middle), and KL divergence minimization relative to prior assumptions (right).\n\n\n\n\n\n\n\n\n\n\n\nDatasets 1–5Datasets 6–10\n\n\n\nprint_plot(prior_model = \"gam\", names = datasets$name[1:5])\n\n\n\nEstimated scores on the first five datasets: GAM (left), models selected by AUC maximization (middle), and KL divergence minimization relative to prior assumptions (right).\n\n\n\n\n\n\n\n\nprint_plot(prior_model = \"gam\", names = datasets$name[6:10])\n\n\n\nEstimated scores on the first five datasets: GAM (left), models selected by AUC maximization (middle), and KL divergence minimization relative to prior assumptions (right).\n\n\n\n\n\n\n\n\n\n\n\nDatasets 1–5Datasets 6–10\n\n\n\nprint_plot(prior_model = \"gamsel\", names = datasets$name[1:5])\n\n\n\nEstimated scores on the first five datasets: GAMSEL (left), models selected by AUC maximization (middle), and KL divergence minimization relative to prior assumptions (right).\n\n\n\n\n\n\n\n\nprint_plot(prior_model = \"gamsel\", names = datasets$name[6:10])\n\n\n\nEstimated scores on the first five datasets: GAMSEL (left), models selected by AUC maximization (middle), and KL divergence minimization relative to prior assumptions (right).",
    "crumbs": [
      "Real-world Data",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Austin, Peter C., and Ewout W. Steyerberg. 2019. “The Integrated\nCalibration Index (ICI) and Related Metrics for Quantifying the\nCalibration of Logistic Regression Models.” Statistics in\nMedicine 38 (21): 4051–65. https://doi.org/10.1002/sim.8281.\n\n\nBecker, Barry, and Ronny Kohavi. 1996.\n“Adult.” UCI Machine Learning Repository.\n\n\nBrier, Glenn W. 1950. “Verification of Forecasts Expressed in\nTerms of Probability.” Monthly Weather Review 78 (1):\n1–3.\n\n\nCaffo, Brian S, James G Booth, and AC Davison. 2002. “Empirical\nSupremum Rejection Sampling.” Biometrika 89 (4): 745–54.\n\n\nCandanedo, Luis. 2016. “Occupancy Detection .”\nUCI Machine Learning Repository.\n\n\nChen, Song Xi. 1999. “Beta Kernel Estimators for Density\nFunctions.” Computational Statistics & Data Analysis\n31 (2): 131–45.\n\n\nChouldechova, Alexandra, and Trevor Hastie. 2015. “Generalized\nAdditive Model Selection.” https://arxiv.org/abs/1506.03850.\n\n\nCortez, Paulo, A. Cerdeira, F. Almeida, T. Matos, and J. Reis. 2009.\n“Wine Quality.” UCI Machine Learning\nRepository.\n\n\n“Dry Bean.” 2020. UCI Machine Learning\nRepository.\n\n\nHopkins, Mark, Erik Reeber, George Forman, and Jaap Suermondt. 1999.\n“Spambase.” UCI Machine Learning Repository.\n\n\n“In-Vehicle Coupon Recommendation.” 2020. UCI\nMachine Learning Repository.\n\n\nKullback, S., and R. A. Leibler. 1951. “On Information and\nSufficiency.” The Annals of Mathematical Statistics 22\n(1): 79–86. https://doi.org/10.1214/aoms/1177729694.\n\n\nMoro, S., P. Rita, and P. Cortez. 2012. “Bank\nMarketing.” UCI Machine Learning Repository.\n\n\n“Mushroom.” 1987. UCI Machine Learning\nRepository.\n\n\nNash, Warwick, Tracy Sellers, Simon Talbot, Andrew Cawthorn, and Wes\nFord. 1995. “Abalone.” UCI Machine Learning\nRepository.\n\n\nOjeda, Francisco M., Max L. Jansen, Alexandre Thiéry, Stefan\nBlankenberg, Christian Weimar, Matthias Schmid, and Andreas Ziegler.\n2023. “Calibrating Machine Learning Approaches for Probability\nEstimation: A Comprehensive Comparison.” Statistics in\nMedicine 42 (29): 5451–78. https://doi.org/10.1002/sim.9921.\n\n\nRumbell, Timothy, Jaimit Parikh, James Kozloski, and Viatcheslav Gurev.\n2023. “Novel and Flexible Parameter Estimation Methods for\nData-Consistent Inversion in Mechanistic Modelling.” Royal\nSociety Open Science 10 (11): 230668.\n\n\nYeh, I-Cheng. 2016. “Default of Credit Card\nClients.” UCI Machine Learning Repository.",
    "crumbs": [
      "References"
    ]
  }
]